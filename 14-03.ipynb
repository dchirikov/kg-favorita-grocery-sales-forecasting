{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import hyperdash as hd\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'store_nbr', 'n_city', 'n_state', 'n_type', 'cluster', 'item_nbr', 'n_family', 'class', 'perishable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_mean, unit_std = pd.read_csv('data/mean_std.csv', index_col=0).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stores = pd.read_csv(\n",
    "    'data/num_stores.csv.gz',\n",
    "     dtype={\n",
    "         'store_nbr': np.uint8,\n",
    "         'n_city': np.uint8,\n",
    "         'n_state': np.uint8,\n",
    "         'n_type': np.uint8,\n",
    "         'cluster': np.uint8\n",
    "     }\n",
    "\n",
    ")\n",
    "df_items = pd.read_csv(\n",
    "    'data/num_items.csv.gz',\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'n_family': np.uint8,\n",
    "        'class': np.int16,\n",
    "        'perishable': np.int8,\n",
    "    }\n",
    ")\n",
    "\n",
    "for stores_col in ['n_city', 'n_state', 'n_type', 'cluster']:\n",
    "    df_stores[stores_col] = df_stores[stores_col] - df_stores[stores_col].min()\n",
    "    \n",
    "for items_col in ['n_family', 'class', 'perishable']:\n",
    "    df_items[items_col] = df_items[items_col] - df_items[items_col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 38s, sys: 12.2 s, total: 6min 51s\n",
      "Wall time: 6min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    'data/ts.csv.gz',\n",
    "    parse_dates=[0],\n",
    "    #nrows=1000000,\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'store_nbr': np.int8,\n",
    "        'unit_sales_scaled': np.float32,\n",
    "        'onpromotion': np.int8,\n",
    "        'holiday': np.int8,\n",
    "        'weekend': np.int8,\n",
    "        'waged_day': np.int8,\n",
    "        'dow_0': np.int8,\n",
    "        'dow_1': np.int8,\n",
    "        'dow_2': np.int8,\n",
    "        'dow_3': np.int8,\n",
    "        'dow_4': np.int8,\n",
    "        'dow_5': np.int8,\n",
    "        'dow_6': np.int8,\n",
    "    }\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212277456 entries, 0 to 212277455\n",
      "Data columns (total 15 columns):\n",
      "date                 datetime64[ns]\n",
      "store_nbr            int8\n",
      "item_nbr             int32\n",
      "unit_sales_scaled    float32\n",
      "onpromotion          int8\n",
      "holiday              int8\n",
      "weekend              int8\n",
      "waged_day            int8\n",
      "dow_0                int8\n",
      "dow_1                int8\n",
      "dow_2                int8\n",
      "dow_3                int8\n",
      "dow_4                int8\n",
      "dow_5                int8\n",
      "dow_6                int8\n",
      "dtypes: datetime64[ns](1), float32(1), int32(1), int8(12)\n",
      "memory usage: 5.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179149968 entries, 152 to 212277455\n",
      "Data columns (total 15 columns):\n",
      "date                 datetime64[ns]\n",
      "store_nbr            int8\n",
      "item_nbr             int32\n",
      "unit_sales_scaled    float32\n",
      "onpromotion          int8\n",
      "holiday              int8\n",
      "weekend              int8\n",
      "waged_day            int8\n",
      "dow_0                int8\n",
      "dow_1                int8\n",
      "dow_2                int8\n",
      "dow_3                int8\n",
      "dow_4                int8\n",
      "dow_5                int8\n",
      "dow_6                int8\n",
      "dtypes: datetime64[ns](1), float32(1), int32(1), int8(12)\n",
      "memory usage: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "df = df[\n",
    "    df['date'] > '2015-06-01'\n",
    "]\n",
    "gc.collect()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 8s, sys: 2min 44s, total: 15min 53s\n",
      "Wall time: 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_columns = df.columns[3:]\n",
    "      \n",
    "attr_cols = [\n",
    "    'store_nbr', 'n_city', 'n_state', 'n_type', 'cluster',\n",
    "    'item_nbr', 'n_family', 'class',\n",
    "    'perishable'\n",
    "]\n",
    "\n",
    "df_pivot = df.pivot_table(\n",
    "    index=['store_nbr', 'item_nbr'],\n",
    "    columns=['date'],\n",
    "    values=ts_columns\n",
    ").reset_index()\n",
    "\n",
    "df_pivot = df_pivot.merge(df_items, on='item_nbr')\n",
    "df_pivot['store_nbr'] = df_pivot[('store_nbr', '')]\n",
    "df_pivot = df_pivot.merge(df_stores, on='store_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 217944 entries, 0 to 217943\n",
      "Columns: 9875 entries, item_nbr to cluster\n",
      "dtypes: float32(822), int16(1), int64(4), int8(9043), uint8(5)\n",
      "memory usage: 2.5 GB\n"
     ]
    }
   ],
   "source": [
    "df_pivot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217944, 240)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date_cols(date, history=20, skip=0, predict_days=1, ts_columns=ts_columns):\n",
    "                  #date, days=1, attr_cols=attr_columns_wo_means, ts_cols=ts_columns, attr=True):\n",
    "    \n",
    "    if type(date) != pd.Timestamp:\n",
    "        date = pd.to_datetime(date)\n",
    "        \n",
    "    X_start_date = date - pd.Timedelta('{} days'.format(history-1))\n",
    "    #X_end_date = date\n",
    "    y_start_date = date + pd.Timedelta('{} days'.format(predict_day))\n",
    "    #y_end_date = date + pd.Timedelta('{} days'.format(predict_days))\n",
    "\n",
    "    X_cols, y_cols, y_day_attr_cols = [], [], []\n",
    "    \n",
    "    for d in pd.date_range(X_start_date, periods=history, freq='D'):\n",
    "        for elem in ts_columns:\n",
    "            X_cols.append((elem, d))\n",
    "            \n",
    "    for d in pd.date_range(y_start_date, periods=1, freq='D'):\n",
    "        y_cols.append(('unit_sales_scaled', d))\n",
    "        for elem in ts_columns[1:]:\n",
    "            y_day_attr_cols.append((elem, d))\n",
    "            \n",
    "    return X_cols, y_cols, y_day_attr_cols\n",
    "\n",
    "\n",
    "\n",
    "X_cols, y_cols, y_day_attr_cols = get_date_cols('2017-08-15', predict_day=3)\n",
    "    \n",
    "df_pivot.loc[:, X_cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 12) (11,) (1,) ()\n"
     ]
    }
   ],
   "source": [
    "def get_random_train_test(df_pivot,\n",
    "        date, window=3, size=2000, history=1, predict_day=1, epochs=2, freq=1\n",
    "        shuffle_dates=True, shuffle_indexes=True, attr_cols=attr_cols, ts_columns=ts_columns):\n",
    "    \n",
    "    num_items = df_pivot.shape[0]\n",
    "    \n",
    "    date = pd.to_datetime(date)\n",
    "    start_window =  date - pd.Timedelta('{} days'.format(window*freq))\n",
    "    end_date = date\n",
    "    \n",
    "    dates = pd.date_range(start_window, end_date, freq='D'.format(freq))\n",
    "    \n",
    "    patches = []\n",
    "    #end_X_date = end_date - pd.Timedelta('{} days'.format(label_dates))\n",
    "    if shuffle_dates and shuffle_indexes:\n",
    "        permutated_dates = np.random.permutation(dates)\n",
    "        permutated_indx = np.random.permutation(num_items)   \n",
    "        for epoch in range(epochs):\n",
    "            for i in range(num_items//size+1):\n",
    "                s = size * i\n",
    "                e = size * (i+1)\n",
    "                indexes = permutated_indx[s:e]\n",
    "\n",
    "                for date in permutated_dates:\n",
    "                    patches.append([indexes, date])\n",
    "\n",
    "        patches = np.random.permutation(patches)\n",
    "        \n",
    "    elif not shuffle_dates and shuffle_indexes:\n",
    "        permutated_indx = np.random.permutation(num_items)\n",
    "        for date in dates:\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(num_items//size+1):\n",
    "                    s = size * i\n",
    "                    e = size * (i+1)\n",
    "                    indexes = permutated_indx[s:e]\n",
    "                    patches.append([indexes, date])\n",
    "\n",
    "    for indexes, date in patches:\n",
    "        df_pivot_slice = df_pivot.iloc[indexes]\n",
    "        X_cols, y_cols, y_day_attr_cols = get_date_cols(\n",
    "            date, history=history, predict_day=predict_day, ts_columns=ts_columns\n",
    "        )\n",
    "\n",
    "        X = np.array(\n",
    "            df_pivot_slice.loc[:, X_cols]\n",
    "        ).reshape([-1, history, len(ts_columns)])\n",
    "\n",
    "        y_day_attr = np.array(\n",
    "            df_pivot_slice.loc[:, y_day_attr_cols]\n",
    "        )\n",
    "        \n",
    "        y = np.array(df_pivot_slice.loc[:, y_cols])\n",
    "        features = [X, y_day_attr, y]\n",
    "        for feature in attr_cols:\n",
    "            features.append(\n",
    "                np.array(df_pivot_slice.loc[:, feature])\n",
    "            )\n",
    "        for i in range(len(indexes)):\n",
    "            yield tuple([elem[i] for elem in features])\n",
    "\n",
    "tmp = get_random_train_test(df_pivot, '2017-07-15', window=0, history=90, predict_day=5)\n",
    "tmp1 = next(tmp)\n",
    "print(tmp1[0].shape, tmp1[1].shape, tmp1[2].shape, tmp1[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  1.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          1.        ,  0.        ]]), array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int8), array([-0.71689729, -0.71689729, -0.71689729, -0.71689729, -0.71689729]), 36, 11, 6, 4, 9, 1960806, 30, 106)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210654, 90, 12) (210654, 11) (210654, 1) (210654,)\n"
     ]
    }
   ],
   "source": [
    "def get_validation(df_pivot,\n",
    "        date, history=1, predict_day=1, attr_cols=attr_cols, ts_columns=ts_columns):\n",
    "    \n",
    "    X_cols, y_cols, y_day_attr_cols = get_date_cols(\n",
    "        date, history=history, predict_day=predict_day, ts_columns=ts_columns\n",
    "    )\n",
    "\n",
    "    X = np.array(\n",
    "        df_pivot.loc[:, X_cols]\n",
    "    ).reshape([-1, history, len(ts_columns)])\n",
    "    \n",
    "    y_day_attr = np.array(\n",
    "        df_pivot.loc[:, y_day_attr_cols]\n",
    "    )\n",
    "\n",
    "    y = np.array(df_pivot.loc[:, y_cols])\n",
    "    features = [X, y_day_attr, y]\n",
    "    for feature in attr_cols:\n",
    "        features.append(\n",
    "            np.array(df_pivot.loc[:, feature])\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "tmp = get_validation(df_pivot, '2017-07-15', history=90, predict_day=5)\n",
    "print(tmp[0].shape, tmp[1].shape, tmp[2].shape, tmp[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-16 00:00:00\n",
      "1\n",
      "g_step: 100 loss std/mean: 17.086471557617188 7.704306125640869\n",
      "| Loss std:  17.086472 |\n",
      "| Loss mean:   7.704306 |\n",
      "g_step: 200 loss std/mean: 0.5421836376190186 4.720633506774902\n",
      "| Loss std:   0.542184 |\n",
      "| Loss mean:   4.720634 |\n",
      "g_step: 300 loss std/mean: 0.4817917048931122 4.4661478996276855\n",
      "| Loss std:   0.481792 |\n",
      "| Loss mean:   4.466148 |\n",
      "g_step: 400 loss std/mean: 0.5824440121650696 4.5725016593933105\n",
      "| Loss std:   0.582444 |\n",
      "| Loss mean:   4.572502 |\n",
      "g_step: 500 loss std/mean: 0.4691454768180847 4.491879463195801\n",
      "| Loss std:   0.469145 |\n",
      "| Loss mean:   4.491879 |\n",
      "g_step: 600 loss std/mean: 0.5033274292945862 4.711548328399658\n",
      "| Loss std:   0.503327 |\n",
      "| Loss mean:   4.711548 |\n",
      "g_step: 700 loss std/mean: 0.4511660933494568 4.478338241577148\n",
      "| Loss std:   0.451166 |\n",
      "| Loss mean:   4.478338 |\n",
      "g_step: 800 loss std/mean: 0.5127571821212769 4.584293365478516\n",
      "| Loss std:   0.512757 |\n",
      "| Loss mean:   4.584293 |\n",
      "g_step: 900 loss std/mean: 0.5348780751228333 4.545324325561523\n",
      "| Loss std:   0.534878 |\n",
      "| Loss mean:   4.545324 |\n",
      "g_step: 1000 loss std/mean: 0.6172728538513184 4.6594557762146\n",
      "| Loss std:   0.617273 |\n",
      "| Loss mean:   4.659456 |\n",
      "\tValidation NWRMSLE  : 2.18117973437\n",
      "| Validation NWRMSLE:   2.181180 |\n",
      "g_step: 1100 loss std/mean: 0.3829890191555023 4.584437370300293\n",
      "| Loss std:   0.382989 |\n",
      "| Loss mean:   4.584437 |\n",
      "g_step: 1200 loss std/mean: 0.4882931709289551 4.631503105163574\n",
      "| Loss std:   0.488293 |\n",
      "| Loss mean:   4.631503 |\n",
      "Ctrl+C\n",
      "This run of RNN fav 2 ran for 0:09:17 and logs are available locally at: /home/dmitry/.hyperdash/logs/rnn-fav-2/rnn-fav-2_2017-12-23t22-48-31-943740.log\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "history = 200\n",
    "day_to_predict = 1\n",
    "\n",
    "last_day_train = '2017-07-15'\n",
    "window=21\n",
    "epochs = 100\n",
    "validation_day = pd.to_datetime(last_day_train) + pd.Timedelta('{} days'.format(day_to_predict))\n",
    "batch_size = 2000\n",
    "sum_W = 3574368.0/16\n",
    "\n",
    "print(validation_day)\n",
    "\n",
    "batch_gen = get_random_train_test(\n",
    "    df_pivot,\n",
    "    last_day_train,\n",
    "    window=window,\n",
    "    history=history,\n",
    "    size=batch_size,\n",
    "    predict_day=day_to_predict,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "val_set = get_validation(df_pivot, validation_day, history=history, predict_day=day_to_predict)\n",
    "\n",
    "from model import RNNModel\n",
    "\n",
    "m = RNNModel(\n",
    "    history=history,\n",
    "    #n_days_predict=time_to_predict,\n",
    "    clip_gradients=10.,\n",
    "    starter_learning_rate=0.001,\n",
    "    #starter_learning_rate=0.0005,\n",
    "    n_layers_rnn=1,\n",
    "    rnn_size_encoder=100,\n",
    "    rnn_size_decoder=100,\n",
    ")\n",
    "print(1)\n",
    "m.build_graph(batch_gen)\n",
    "\n",
    "\n",
    "try:\n",
    "    hd_exp.end()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "hd_exp = hd.Experiment('RNN fav 2')\n",
    "\n",
    "m.train(val_set, coef=unit_std, sum_W=sum_W,\n",
    "        report_every=100, validate_every=1000,\n",
    "        hd_exp=hd_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
