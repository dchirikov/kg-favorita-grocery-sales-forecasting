{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_mean, unit_std = pd.read_csv('../RNN/data/mean_std.csv', index_col=0).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\n",
    "    '../input/train.csv',\n",
    "    skiprows=122100000,\n",
    "    dtype={\n",
    "        'id': np.int64,\n",
    "        'store_nbr': np.int64,\n",
    "        'item_nbr': np.int64,\n",
    "        'onpromotion': np.bool\n",
    "    },\n",
    "    converters={\n",
    "        'unit_sales': lambda x: float(x) if float(x) > 0 else 0,\n",
    "    },\n",
    "    parse_dates=[1]\n",
    ")\n",
    "train_csv.columns = ['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales_real', 'onpromotion']\n",
    "train_csv['unit_sales_real'] = train_csv['unit_sales_real'].apply(lambda x : x if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    '../input/test.csv',\n",
    "    parse_dates=[1],\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'store_nbr': np.int8,\n",
    "        'unit_sales': np.float32,\n",
    "    },\n",
    "    converters={\n",
    "        'onpromotion': lambda x: 1 if x == 'True' else 0\n",
    "    }\n",
    ")\n",
    "\n",
    "df_stores = pd.read_csv(\n",
    "    '../RNN/data/num_stores.csv.gz',\n",
    "     dtype={\n",
    "         'store_nbr': np.uint8,\n",
    "         'n_city': np.uint32,\n",
    "         'n_state': np.uint32,\n",
    "         'n_type': np.uint32,\n",
    "         'cluster': np.uint32\n",
    "     }\n",
    "\n",
    ")\n",
    "df_items = pd.read_csv(\n",
    "    '../RNN/data/num_items.csv.gz',\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'n_family': np.int32,\n",
    "        'class': np.int32,\n",
    "        'perishable': np.int8,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_items['weight'] = df_items['perishable'] * 0.25 + 1\n",
    "\n",
    "for stores_col in ['n_city', 'n_state', 'n_type', 'cluster']:\n",
    "    df_stores[stores_col] = df_stores[stores_col] - df_stores[stores_col].min()\n",
    "    \n",
    "for items_col in ['n_family', 'class', 'perishable']:\n",
    "    df_items[items_col] = df_items[items_col] - df_items[items_col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 49s, sys: 11.6 s, total: 7min\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    '../RNN/data/ts.csv.gz',\n",
    "    parse_dates=[0],\n",
    "    #nrows=1000000,\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'store_nbr': np.int8,\n",
    "        'unit_sales': np.float32,\n",
    "        'onpromotion': np.int8,\n",
    "        'holiday': np.int8,\n",
    "        'weekend': np.int8,\n",
    "        'waged_day': np.int8,\n",
    "        'dow_0': np.int8,\n",
    "        'dow_1': np.int8,\n",
    "        'dow_2': np.int8,\n",
    "        'dow_3': np.int8,\n",
    "        'dow_4': np.int8,\n",
    "        'dow_5': np.int8,\n",
    "        'dow_6': np.int8,\n",
    "    }\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132509952 entries, 366 to 212277455\n",
      "Data columns (total 15 columns):\n",
      "date                 datetime64[ns]\n",
      "store_nbr            int8\n",
      "item_nbr             int32\n",
      "unit_sales_scaled    float64\n",
      "onpromotion          int8\n",
      "holiday              int8\n",
      "weekend              int8\n",
      "waged_day            int8\n",
      "dow_0                int8\n",
      "dow_1                int8\n",
      "dow_2                int8\n",
      "dow_3                int8\n",
      "dow_4                int8\n",
      "dow_5                int8\n",
      "dow_6                int8\n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int8(12)\n",
      "memory usage: 4.9 GB\n"
     ]
    }
   ],
   "source": [
    "df = df[\n",
    "    df['date'] > '2016-01-01'\n",
    "]\n",
    "gc.collect()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales_scaled</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>waged_day</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169590656</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>54</td>\n",
       "      <td>2113343</td>\n",
       "      <td>-0.716897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  store_nbr  item_nbr  unit_sales_scaled  onpromotion  \\\n",
       "169590656 2017-08-16         54   2113343          -0.716897            0   \n",
       "\n",
       "           holiday  weekend  waged_day  dow_0  dow_1  dow_2  dow_3  dow_4  \\\n",
       "169590656        0        0          0      0      0      1      0      0   \n",
       "\n",
       "           dow_5  dow_6  \n",
       "169590656      0      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\n",
    "    (df['date'] == '2017-08-16') &\n",
    "    (df['store_nbr'] == 54) &\n",
    "    #(df['item_nbr'] == 108797)\n",
    "    (df['item_nbr'] == 2113343)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 6s, sys: 2min 11s, total: 12min 17s\n",
      "Wall time: 9min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_columns = df.columns[3:]\n",
    "      \n",
    "attr_cols = [\n",
    "    'store_nbr', 'n_city', 'n_state', 'n_type', 'cluster',\n",
    "    'item_nbr', 'n_family', 'class',\n",
    "    'weight',\n",
    "    #'perishable'\n",
    "]\n",
    "\n",
    "df_pivot = df.pivot_table(\n",
    "    index=['store_nbr', 'item_nbr'],\n",
    "    columns=['date'],\n",
    "    values=ts_columns\n",
    ").reset_index()\n",
    "\n",
    "df_pivot = df_pivot.merge(df_items, on='item_nbr')\n",
    "df_pivot['store_nbr'] = df_pivot[('store_nbr', '')]\n",
    "df_pivot = df_pivot.merge(df_stores, on='store_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(unit_sales_scaled, 2017-08-16 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-17 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-18 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-19 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-20 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-21 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-22 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-23 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-24 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-25 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-26 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-27 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-28 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-29 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-30 00:00:00)</th>\n",
       "      <th>(unit_sales_scaled, 2017-08-31 00:00:00)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "      <td>-0.69471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (unit_sales_scaled, 2017-08-16 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-17 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-18 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-19 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-20 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-21 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-22 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-23 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-24 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-25 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-26 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-27 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-28 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-29 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-30 00:00:00)  \\\n",
       "0                                  -0.69471   \n",
       "1                                  -0.69471   \n",
       "2                                  -0.69471   \n",
       "3                                  -0.69471   \n",
       "4                                  -0.69471   \n",
       "\n",
       "   (unit_sales_scaled, 2017-08-31 00:00:00)  \n",
       "0                                  -0.69471  \n",
       "1                                  -0.69471  \n",
       "2                                  -0.69471  \n",
       "3                                  -0.69471  \n",
       "4                                  -0.69471  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date_cols(date, history=20, predict_days=16, ts_columns=ts_columns, skip=0):\n",
    "                  #date, days=1, attr_cols=attr_columns_wo_means, ts_cols=ts_columns, attr=True):\n",
    "    \n",
    "    if type(date) != pd.Timestamp:\n",
    "        date = pd.to_datetime(date)\n",
    "        \n",
    "    X_start_date = date - pd.Timedelta('{} days'.format(history-1))\n",
    "    #X_end_date = date\n",
    "    y_start_date = date + pd.Timedelta('{} days'.format(skip+1))\n",
    "    #y_end_date = date + pd.Timedelta('{} days'.format(predict_days))\n",
    "\n",
    "    X_cols, y_cols, y_day_attr_cols = [], [], []\n",
    "    \n",
    "    for d in pd.date_range(X_start_date, periods=history, freq='D'):\n",
    "        for elem in ts_columns:\n",
    "            X_cols.append((elem, d))\n",
    "            \n",
    "    for d in pd.date_range(y_start_date, periods=predict_days, freq='D'):\n",
    "        y_cols.append(('unit_sales_scaled', d))\n",
    "        for elem in ts_columns[1:]:\n",
    "            y_day_attr_cols.append((elem, d))\n",
    "            \n",
    "    return X_cols, y_cols, y_day_attr_cols\n",
    "\n",
    "\n",
    "\n",
    "X_cols, y_cols, y_day_attr_cols = get_date_cols('2017-08-15', predict_days=16)\n",
    "    \n",
    "df_pivot.head().loc[:, y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(217944, 90, 12) (217944, 5, 11) (217944, 5) (217944,)\n"
     ]
    }
   ],
   "source": [
    "def get_validation(df_pivot,\n",
    "        date, history=1, predict_days=16, attr_cols=attr_cols, ts_columns=ts_columns, skip=0):\n",
    "    \n",
    "    X_cols, y_cols, y_day_attr_cols = get_date_cols(\n",
    "        date, history=history, predict_days=predict_days, ts_columns=ts_columns, skip=skip\n",
    "    )\n",
    "\n",
    "    X = np.array(\n",
    "        df_pivot.loc[:, X_cols]\n",
    "    ).reshape([-1, history, len(ts_columns)])\n",
    "    \n",
    "    y_day_attr = np.array(\n",
    "        df_pivot.loc[:, y_day_attr_cols]\n",
    "    ).reshape([-1, predict_days, len(ts_columns)-1])\n",
    "\n",
    "    y = np.array(df_pivot.loc[:, y_cols])\n",
    "    features = [X, y_day_attr, y]\n",
    "    for feature in attr_cols:\n",
    "        features.append(\n",
    "            np.array(df_pivot.loc[:, feature])\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "tmp = get_validation(df_pivot, '2017-08-15', history=90, predict_days=5)\n",
    "print(len(tmp))\n",
    "print(tmp[0].shape, tmp[1].shape, tmp[2].shape, tmp[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../RNN/log/2018-01-03_20-05-17/model.ckpt-48000\n",
      "1.19380524622\n",
      "1.26183324342\n",
      "CPU times: user 4min 28s, sys: 1min 7s, total: 5min 35s\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def compute_predictions(val_date, ckpt_dir, step=None):\n",
    "    \n",
    "    if step is None:\n",
    "        checkpoint = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    else:\n",
    "        checkpoint = ckpt_dir + '/model.ckpt-' + str(step)\n",
    "\n",
    "    test_set = get_validation(df_pivot, val_date, history=400, predict_days=16)\n",
    "    \n",
    "    (                                                           \n",
    "        b_X, b_y_day_attr, b_y,\n",
    "        b_store_nbr, b_n_city, b_n_state, b_n_type,\n",
    "        b_cluster, b_item_nbr, b_n_family, b_class,\n",
    "        b_weights\n",
    "    ) = test_set\n",
    "\n",
    "    graph_path = checkpoint + '.meta'\n",
    "\n",
    "    loaded_graph = tf.Graph()\n",
    "    with loaded_graph.as_default():\n",
    "        #with tf.Session(graph=loaded_graph) as sess:\n",
    "        sess = tf.Session(graph=loaded_graph)\n",
    "        saver = tf.train.import_meta_graph(graph_path)\n",
    "\n",
    "        #saver.restore(sess, tf.train.latest_checkpoint(checkpoint))\n",
    "        saver.restore(sess, checkpoint)\n",
    "\n",
    "\n",
    "        t_X = loaded_graph.get_tensor_by_name('inputs/X:0')\n",
    "        t_y_day_attr = loaded_graph.get_tensor_by_name('inputs/y_day_attr:0')\n",
    "        t_y = loaded_graph.get_tensor_by_name('inputs/y:0')\n",
    "        t_feat_store_nbr = loaded_graph.get_tensor_by_name('inputs/feat_store_nbr:0')\n",
    "        t_feat_n_city = loaded_graph.get_tensor_by_name('inputs/feat_n_city:0')\n",
    "        t_feat_n_state = loaded_graph.get_tensor_by_name('inputs/feat_n_state:0')\n",
    "        t_feat_n_type = loaded_graph.get_tensor_by_name('inputs/feat_n_type:0')\n",
    "        t_feat_cluster = loaded_graph.get_tensor_by_name('inputs/feat_cluster:0')\n",
    "        t_feat_item_nbr = loaded_graph.get_tensor_by_name('inputs/feat_item_nbr:0')\n",
    "        t_feat_n_family = loaded_graph.get_tensor_by_name('inputs/feat_n_family:0')\n",
    "        t_feat_class = loaded_graph.get_tensor_by_name('inputs/feat_class:0')\n",
    "        t_weights = loaded_graph.get_tensor_by_name('inputs/weights:0')\n",
    "        t_encoder_dropout_kp = loaded_graph.get_tensor_by_name('enc_dropout:0')\n",
    "        t_decoder_dropout_kp = loaded_graph.get_tensor_by_name('dec_dropout:0')\n",
    "        t_conv_dropout_kp = loaded_graph.get_tensor_by_name('conv_dropout:0')\n",
    "        t_predictions = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                t_X,\n",
    "                t_y_day_attr,\n",
    "                t_y,\n",
    "                t_feat_store_nbr,\n",
    "                t_feat_n_city,\n",
    "                t_feat_n_state,\n",
    "                t_feat_n_type,\n",
    "                t_feat_cluster,\n",
    "                t_feat_item_nbr,\n",
    "                t_feat_n_family,\n",
    "                t_feat_class,\n",
    "                t_weights\n",
    "            )\n",
    "        )\n",
    "        dataset = dataset.prefetch(512*420)\n",
    "        dataset = dataset.batch(512*20)\n",
    "\n",
    "        iterator = tf.data.Iterator(\n",
    "            loaded_graph.get_tensor_by_name('Iterator:0'),\n",
    "            loaded_graph.get_operation_by_name('Iterator'),\n",
    "            dataset.output_types,\n",
    "            dataset.output_shapes\n",
    "        )\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        iterator = iterator.make_initializer(dataset)\n",
    "\n",
    "\n",
    "        feed_dict = {\n",
    "            t_X: b_X,\n",
    "            t_y_day_attr: b_y_day_attr,\n",
    "            t_y: b_y,\n",
    "            t_feat_store_nbr: b_store_nbr,\n",
    "            t_feat_n_city: b_n_city,\n",
    "            t_feat_n_state: b_n_state,\n",
    "            t_feat_n_type: b_n_type,\n",
    "            t_feat_cluster: b_cluster,\n",
    "            t_feat_item_nbr: b_item_nbr,\n",
    "            t_feat_n_family: b_n_family,\n",
    "            t_feat_class: b_class,\n",
    "            t_weights: b_weights,\n",
    "            t_encoder_dropout_kp: 1.,\n",
    "            t_decoder_dropout_kp: 1.,\n",
    "            t_conv_dropout_kp: 1.,\n",
    "        }\n",
    "        #sess.run(iterator)\n",
    "        sess.run(iterator, feed_dict=feed_dict)\n",
    "        #print(dir(tmp))\n",
    "        predictions = []\n",
    "        real_unit_sales = b_y\n",
    "\n",
    "\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                predictions.append(\n",
    "                    sess.run(\n",
    "                        t_predictions,\n",
    "                        feed_dict=feed_dict\n",
    "                    )\n",
    "                )\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Ctrl+C\")\n",
    "                break\n",
    "\n",
    "        predicted_val = np.vstack(predictions)\n",
    "\n",
    "        NWRMSLE = np.sqrt(mean_squared_error(\n",
    "            (unit_std*predicted_val.reshape(-1,1) + unit_mean),\n",
    "            (unit_std*real_unit_sales.reshape(-1,1) + unit_mean),\n",
    "            np.tile((np.expand_dims(b_weights+.25+1, -1)), 16).reshape(-1,1)\n",
    "        ))\n",
    "        print(NWRMSLE)\n",
    "\n",
    "        NWRMSLE_5 = np.sqrt(mean_squared_error(\n",
    "            (unit_std*predicted_val[:,:5].reshape(-1,1) + unit_mean),\n",
    "            (unit_std*real_unit_sales[:,:5].reshape(-1,1) + unit_mean),\n",
    "            np.tile((np.expand_dims(b_weights+.25+1, -1)), 5).reshape(-1,1)\n",
    "        ))\n",
    "\n",
    "        print(NWRMSLE_5)\n",
    "        #tmp = sess.run(t_predictions, feed_dict=feed_dict)\n",
    "        \n",
    "    return predicted_val\n",
    "\n",
    "    \n",
    "val_date = '2017-07-30'\n",
    "val_date = '2017-08-15'\n",
    "\n",
    "ckpt_dir = '../RNN/log/2018-01-03_20-05-17'\n",
    "predicted_val = compute_predictions(val_date, ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 8000 - 0.525397366651 - 0.515445371994\n",
    "16000 - 0.518722911751 - 0.509224939791\n",
    "44000 - 0.511786064374 - 0.503474613307\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range('2017-07-31', '2017-08-15')\n",
    "date_range = pd.date_range('2017-08-16', '2017-08-31')\n",
    "\n",
    "df_prognosis = pd.DataFrame(\n",
    "    predicted_val,\n",
    "    columns=date_range\n",
    ")\n",
    "\n",
    "df_prognosis['item_nbr'] = df_pivot['item_nbr']\n",
    "\n",
    "df_prognosis['store_nbr'] = df_pivot['store_nbr']\n",
    "\n",
    "df_prognosis = df_prognosis.melt(\n",
    "    id_vars=['item_nbr', 'store_nbr'],\n",
    "    value_vars=date_range\n",
    ")\n",
    "\n",
    "df_prognosis = df_prognosis.merge(\n",
    "    df_items[['item_nbr', 'perishable']],\n",
    "    on='item_nbr'\n",
    ")\n",
    "\n",
    "df_prognosis.rename(\n",
    "    columns={'variable':'date', 'value': 'unit_sales_scaled'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "#df_prognosis['perishable'] = df_pivot['perishable']\n",
    "#df_prognosis['W'] = df_prognosis['perishable'].apply(lambda x: 1.25 if x else 1)\n",
    "\n",
    "df_prognosis['unit_sales'] = np.expm1(\n",
    "    (df_prognosis['unit_sales_scaled'] * unit_std) + unit_mean\n",
    ")\n",
    "\n",
    "#df_prognosis['unit_sales'] = df_prognosis['unit_sales'].apply(lambda x: x if x>=0 else 0)\n",
    "\n",
    "out = df_test.merge(\n",
    "    df_prognosis,\n",
    "    on=['date', 'item_nbr', 'store_nbr'],\n",
    "    how='left'\n",
    ")[['id', 'unit_sales']]\n",
    "out.fillna(0, inplace=True)\n",
    "#out.to_csv('14-03-06.csv.gz', compression='gzip', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! kg submit 14-03-02.csv.gz -m 'val 5d 0.511119'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = df_prognosis.merge(\n",
    "    train_csv[['date', 'store_nbr', 'item_nbr','unit_sales_real']],\n",
    "    on=['date', 'item_nbr', 'store_nbr'],\n",
    "    how='left'\n",
    ")\n",
    "tmp = tmp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3487104, 7), (3487104, 6))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape, df_prognosis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th>unit_sales_scaled</th>\n",
       "      <th>perishable</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>unit_sales_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96995</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>-0.588287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114318</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96995</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>-0.503795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96995</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>-0.427555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96995</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>-0.578194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96995</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>-0.416889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_nbr  store_nbr       date  unit_sales_scaled  perishable  unit_sales  \\\n",
       "0     96995          1 2017-07-31          -0.588287           0    0.114318   \n",
       "1     96995          2 2017-07-31          -0.503795           0    0.214313   \n",
       "2     96995          3 2017-07-31          -0.427555           0    0.312223   \n",
       "3     96995          4 2017-07-31          -0.578194           0    0.125815   \n",
       "4     96995          5 2017-07-31          -0.416889           0    0.326536   \n",
       "\n",
       "   unit_sales_real  \n",
       "0              2.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51119741740289248"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(\n",
    "    np.log1p(tmp['unit_sales']),\n",
    "    np.log1p(tmp['unit_sales_real']),\n",
    "    tmp['perishable']*.25 + 1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'W'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e31170572980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     (\n\u001b[1;32m      3\u001b[0m         np.sum(\n\u001b[0;32m----> 4\u001b[0;31m             np.square(tmp['W']) * np.square(\n\u001b[0m\u001b[1;32m      5\u001b[0m                  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_sales_real'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             )\n",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'W'"
     ]
    }
   ],
   "source": [
    "np.sqrt(\n",
    "    (\n",
    "        np.sum(\n",
    "            np.square(tmp['W']) * np.square(\n",
    "                 np.log1p(tmp['unit_sales']) - np.log1p(tmp['unit_sales_real'])\n",
    "            )\n",
    "        )\n",
    "    )/(    \n",
    "        tmp['W'].sum() \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1 = tmp[\n",
    "    tmp['date'] < '2017-08-05'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52558896751809192"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(\n",
    "    (\n",
    "        np.sum(\n",
    "            tmp1['W'] * np.square(\n",
    "                 np.log1p(tmp1['unit_sales']) - np.log1p(tmp1['unit_sales_real'])\n",
    "            )\n",
    "        )\n",
    "    )/(    \n",
    "        tmp1['W'].sum() \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2247448713915889"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50259588274380929"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(\n",
    "    metrics.mean_squared_error(\n",
    "        np.log1p(tmp['unit_sales']),\n",
    "        np.log1p(tmp['unit_sales_real']),\n",
    "        tmp['W']\n",
    "    )*tmp.shape[0] / tmp['W'].sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290669.19014115859"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    tmp1['W'] * np.square(\n",
    "         np.log1p(tmp1['unit_sales']) - np.log1p(tmp1['unit_sales_real'])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50873586678231009"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y     = np.log1p(tmp1['unit_sales_real'])\n",
    "y_hat = np.log1p(tmp1['unit_sales'])\n",
    "w     = tmp1['W']\n",
    "\n",
    "np.sqrt(metrics.mean_squared_error(y, y_hat, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957517.42717758799"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(\n",
    "    np.log1p(tmp['unit_sales']),\n",
    "    np.log1p(tmp['unit_sales_real']),\n",
    "    tmp['W']\n",
    ")*tmp['W'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064999999999999752"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y     = np.array([1,   2,   3,   4,   5  ])\n",
    "y_hat = np.array([1.1, 2.1, 3.1, 4.1, 5.1])\n",
    "w     = np.array([.5,   1,   1,   2,   2  ])\n",
    "\n",
    "metrics.mean_squared_error(y, y_hat, w)*w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064999999999999752"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.square(y - y_hat)*w).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
