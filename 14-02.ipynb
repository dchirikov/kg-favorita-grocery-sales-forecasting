{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import hyperdash as hd\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'store_nbr', 'n_city', 'n_state', 'n_type', 'cluster', 'item_nbr', 'n_family', 'class', 'perishable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_mean, unit_std = pd.read_csv('data/mean_std.csv', index_col=0).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items['class'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4100 entries, 0 to 4099\n",
      "Data columns (total 4 columns):\n",
      "item_nbr      4100 non-null int32\n",
      "n_family      4100 non-null uint32\n",
      "class         4100 non-null int32\n",
      "perishable    4100 non-null int8\n",
      "dtypes: int32(2), int8(1), uint32(1)\n",
      "memory usage: 52.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stores = pd.read_csv(\n",
    "    'data/num_stores.csv.gz',\n",
    "     dtype={\n",
    "         'store_nbr': np.uint8,\n",
    "         'n_city': np.uint32,\n",
    "         'n_state': np.uint32,\n",
    "         'n_type': np.uint32,\n",
    "         'cluster': np.uint32\n",
    "     }\n",
    "\n",
    ")\n",
    "df_items = pd.read_csv(\n",
    "    'data/num_items.csv.gz',\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'n_family': np.int32,\n",
    "        'class': np.int32,\n",
    "        'perishable': np.int8,\n",
    "    }\n",
    ")\n",
    "for stores_col in ['n_city', 'n_state', 'n_type', 'cluster']:\n",
    "    df_stores[stores_col] = df_stores[stores_col] - df_stores[stores_col].min()\n",
    "    \n",
    "for items_col in ['n_family', 'class', 'perishable']:\n",
    "    df_items[items_col] = df_items[items_col] - df_items[items_col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 34s, sys: 18.3 s, total: 5min 52s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\n",
    "    'data/ts.csv.gz',\n",
    "    parse_dates=[0],\n",
    "    #nrows=1000000,\n",
    "    dtype={\n",
    "        'item_nbr': np.int32,\n",
    "        'store_nbr': np.int8,\n",
    "        'unit_sales': np.float32,\n",
    "        'onpromotion': np.int8,\n",
    "        'holiday': np.int8,\n",
    "        'weekend': np.int8,\n",
    "        'waged_day': np.int8,\n",
    "        'dow_0': np.int8,\n",
    "        'dow_1': np.int8,\n",
    "        'dow_2': np.int8,\n",
    "        'dow_3': np.int8,\n",
    "        'dow_4': np.int8,\n",
    "        'dow_5': np.int8,\n",
    "        'dow_6': np.int8,\n",
    "    }\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/miniconda3/envs/tf_intel/lib/python3.5/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (2 levels on the left, 1 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 49s, sys: 2min 43s, total: 15min 32s\n",
      "Wall time: 12min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_columns = df.columns[3:]\n",
    "      \n",
    "attr_cols = [\n",
    "    'store_nbr', 'n_city', 'n_state', 'n_type', 'cluster',\n",
    "    'item_nbr', 'n_family', 'class',\n",
    "    #'perishable'\n",
    "]\n",
    "\n",
    "df_pivot = df.pivot_table(\n",
    "    index=['store_nbr', 'item_nbr'],\n",
    "    columns=['date'],\n",
    "    values=ts_columns\n",
    ").reset_index()\n",
    "\n",
    "df_pivot = df_pivot.merge(df_items, on='item_nbr')\n",
    "df_pivot['store_nbr'] = df_pivot[('store_nbr', '')]\n",
    "df_pivot = df_pivot.merge(df_stores, on='store_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 210654 entries, 0 to 210653\n",
      "Columns: 9887 entries, item_nbr to cluster\n",
      "dtypes: float64(823), int32(1), int64(4), int8(9054), uint32(5)\n",
      "memory usage: 3.1 GB\n"
     ]
    }
   ],
   "source": [
    "df_pivot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(onpromotion, 2017-08-16 00:00:00)</th>\n",
       "      <th>(holiday, 2017-08-16 00:00:00)</th>\n",
       "      <th>(weekend, 2017-08-16 00:00:00)</th>\n",
       "      <th>(waged_day, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_0, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_1, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_2, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_3, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_4, 2017-08-16 00:00:00)</th>\n",
       "      <th>(dow_5, 2017-08-16 00:00:00)</th>\n",
       "      <th>...</th>\n",
       "      <th>(holiday, 2017-08-20 00:00:00)</th>\n",
       "      <th>(weekend, 2017-08-20 00:00:00)</th>\n",
       "      <th>(waged_day, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_0, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_1, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_2, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_3, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_4, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_5, 2017-08-20 00:00:00)</th>\n",
       "      <th>(dow_6, 2017-08-20 00:00:00)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (onpromotion, 2017-08-16 00:00:00)  (holiday, 2017-08-16 00:00:00)  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "\n",
       "   (weekend, 2017-08-16 00:00:00)  (waged_day, 2017-08-16 00:00:00)  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "2                               0                                 0   \n",
       "3                               0                                 0   \n",
       "4                               0                                 0   \n",
       "\n",
       "   (dow_0, 2017-08-16 00:00:00)  (dow_1, 2017-08-16 00:00:00)  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   (dow_2, 2017-08-16 00:00:00)  (dow_3, 2017-08-16 00:00:00)  \\\n",
       "0                             1                             0   \n",
       "1                             1                             0   \n",
       "2                             1                             0   \n",
       "3                             1                             0   \n",
       "4                             1                             0   \n",
       "\n",
       "   (dow_4, 2017-08-16 00:00:00)  (dow_5, 2017-08-16 00:00:00)  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "               ...               (holiday, 2017-08-20 00:00:00)  \\\n",
       "0              ...                                            0   \n",
       "1              ...                                            0   \n",
       "2              ...                                            0   \n",
       "3              ...                                            0   \n",
       "4              ...                                            0   \n",
       "\n",
       "   (weekend, 2017-08-20 00:00:00)  (waged_day, 2017-08-20 00:00:00)  \\\n",
       "0                               1                                 0   \n",
       "1                               1                                 0   \n",
       "2                               1                                 0   \n",
       "3                               1                                 0   \n",
       "4                               1                                 0   \n",
       "\n",
       "   (dow_0, 2017-08-20 00:00:00)  (dow_1, 2017-08-20 00:00:00)  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   (dow_2, 2017-08-20 00:00:00)  (dow_3, 2017-08-20 00:00:00)  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   (dow_4, 2017-08-20 00:00:00)  (dow_5, 2017-08-20 00:00:00)  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   (dow_6, 2017-08-20 00:00:00)  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date_cols(date, history=20, predict_days=16, ts_columns=ts_columns, skip=0):\n",
    "                  #date, days=1, attr_cols=attr_columns_wo_means, ts_cols=ts_columns, attr=True):\n",
    "    \n",
    "    if type(date) != pd.Timestamp:\n",
    "        date = pd.to_datetime(date)\n",
    "        \n",
    "    X_start_date = date - pd.Timedelta('{} days'.format(history-1))\n",
    "    #X_end_date = date\n",
    "    y_start_date = date + pd.Timedelta('{} days'.format(skip+1))\n",
    "    #y_end_date = date + pd.Timedelta('{} days'.format(predict_days))\n",
    "\n",
    "    X_cols, y_cols, y_day_attr_cols = [], [], []\n",
    "    \n",
    "    for d in pd.date_range(X_start_date, periods=history, freq='D'):\n",
    "        for elem in ts_columns:\n",
    "            X_cols.append((elem, d))\n",
    "            \n",
    "    for d in pd.date_range(y_start_date, periods=predict_days, freq='D'):\n",
    "        y_cols.append(('unit_sales_scaled', d))\n",
    "        for elem in ts_columns[1:]:\n",
    "            y_day_attr_cols.append((elem, d))\n",
    "            \n",
    "    return X_cols, y_cols, y_day_attr_cols\n",
    "\n",
    "\n",
    "\n",
    "X_cols, y_cols, y_day_attr_cols = get_date_cols('2017-08-15', predict_days=5)\n",
    "    \n",
    "df_pivot.head().loc[:, y_day_attr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2017-07-01', '2017-07-08', '2017-07-15'], dtype='datetime64[ns]', freq='7D')\n",
      "(90, 12) (5, 11) (5,) ()\n"
     ]
    }
   ],
   "source": [
    "def get_random_train_test(df_pivot,\n",
    "        date, window=21, freq=7, size=2000, history=1, predict_days=16, epochs=2, \n",
    "        shuffle_dates=True, shuffle_indexes=True, attr_cols=attr_cols, ts_columns=ts_columns, skip=0):\n",
    "    \n",
    "    \n",
    "    window = freq * (window//freq)\n",
    "    num_items = df_pivot.shape[0]\n",
    "    \n",
    "    date = pd.to_datetime(date)\n",
    "    start_window =  date - pd.Timedelta('{} days'.format(window))\n",
    "    end_date = date\n",
    "    \n",
    "    dates = pd.date_range(start=start_window, end=end_date)\n",
    "    dates = dates[::freq]\n",
    "    \n",
    "    print(dates)\n",
    "    \n",
    "    patches = []\n",
    "    #end_X_date = end_date - pd.Timedelta('{} days'.format(label_dates))\n",
    "    if shuffle_dates and shuffle_indexes:\n",
    "        permutated_dates = np.random.permutation(dates)\n",
    "        permutated_indx = np.random.permutation(num_items)   \n",
    "        for epoch in range(epochs):\n",
    "            for i in range(num_items//size+1):\n",
    "                s = size * i\n",
    "                e = size * (i+1)\n",
    "                indexes = permutated_indx[s:e]\n",
    "\n",
    "                for date in permutated_dates:\n",
    "                    patches.append([indexes, date])\n",
    "\n",
    "        patches = np.random.permutation(patches)\n",
    "        \n",
    "    elif not shuffle_dates and shuffle_indexes:\n",
    "        permutated_indx = np.random.permutation(num_items)\n",
    "        for date in dates:\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(num_items//size+1):\n",
    "                    s = size * i\n",
    "                    e = size * (i+1)\n",
    "                    indexes = permutated_indx[s:e]\n",
    "                    patches.append([indexes, date])\n",
    "\n",
    "    for indexes, date in patches:\n",
    "        df_pivot_slice = df_pivot.iloc[indexes]\n",
    "        X_cols, y_cols, y_day_attr_cols = get_date_cols(\n",
    "            date, history=history, predict_days=predict_days, ts_columns=ts_columns, skip=skip\n",
    "        )\n",
    "\n",
    "        X = np.array(\n",
    "            df_pivot_slice.loc[:, X_cols]\n",
    "        ).reshape([-1, history, len(ts_columns)])\n",
    "\n",
    "        y_day_attr = np.array(\n",
    "            df_pivot_slice.loc[:, y_day_attr_cols]\n",
    "        ).reshape([-1, predict_days, len(ts_columns)-1])\n",
    "        \n",
    "        y = np.array(df_pivot_slice.loc[:, y_cols])\n",
    "        features = [X, y_day_attr, y]\n",
    "        for feature in attr_cols:\n",
    "            features.append(\n",
    "                np.array(df_pivot_slice.loc[:, feature])\n",
    "            )\n",
    "        for i in range(len(indexes)):\n",
    "            yield tuple([elem[i] for elem in features])\n",
    "\n",
    "tmp = get_random_train_test(df_pivot, '2017-07-15', window=20, history=90, predict_days=5)\n",
    "tmp1 = next(tmp)\n",
    "print(tmp1[0].shape, tmp1[1].shape, tmp1[2].shape, tmp1[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  1.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.71689729,  0.        ,  0.        , ...,  0.        ,\n",
       "          1.        ,  0.        ]]), array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int8), array([-0.71689729, -0.71689729, -0.71689729, -0.71689729, -0.71689729]), 36, 11, 6, 4, 9, 1960806, 30, 106)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210654, 90, 12) (210654, 5, 11) (210654, 5) (210654,)\n"
     ]
    }
   ],
   "source": [
    "def get_validation(df_pivot,\n",
    "        date, history=1, predict_days=16, attr_cols=attr_cols, ts_columns=ts_columns, skip=0):\n",
    "    \n",
    "    X_cols, y_cols, y_day_attr_cols = get_date_cols(\n",
    "        date, history=history, predict_days=predict_days, ts_columns=ts_columns, skip=skip\n",
    "    )\n",
    "\n",
    "    X = np.array(\n",
    "        df_pivot.loc[:, X_cols]\n",
    "    ).reshape([-1, history, len(ts_columns)])\n",
    "    \n",
    "    y_day_attr = np.array(\n",
    "        df_pivot.loc[:, y_day_attr_cols]\n",
    "    ).reshape([-1, predict_days, len(ts_columns)-1])\n",
    "\n",
    "    y = np.array(df_pivot.loc[:, y_cols])\n",
    "    features = [X, y_day_attr, y]\n",
    "    for feature in attr_cols:\n",
    "        features.append(\n",
    "            np.array(df_pivot.loc[:, feature])\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "tmp = get_validation(df_pivot, '2017-07-15', history=90, predict_days=5)\n",
    "print(tmp[0].shape, tmp[1].shape, tmp[2].shape, tmp[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-30 00:00:00\n",
      "1\n",
      "DatetimeIndex(['2016-09-17', '2016-09-18', '2016-09-19', '2016-09-20',\n",
      "               '2016-09-21', '2016-09-22', '2016-09-23', '2016-09-24',\n",
      "               '2016-09-25', '2016-09-26',\n",
      "               ...\n",
      "               '2017-07-05', '2017-07-06', '2017-07-07', '2017-07-08',\n",
      "               '2017-07-09', '2017-07-10', '2017-07-11', '2017-07-12',\n",
      "               '2017-07-13', '2017-07-14'],\n",
      "              dtype='datetime64[ns]', length=301, freq='D')\n",
      "g_step: 100 loss std/mean: 0.1579766720533371 0.4370148181915283\n",
      "| Loss std:   0.157977 |\n",
      "| Loss mean:   0.437015 |\n",
      "g_step: 200 loss std/mean: 0.04570454731583595 0.3249939978122711\n",
      "| Loss std:   0.045705 |\n",
      "| Loss mean:   0.324994 |\n",
      "g_step: 300 loss std/mean: 0.040676068514585495 0.31800219416618347\n",
      "| Loss std:   0.040676 |\n",
      "| Loss mean:   0.318002 |\n",
      "g_step: 400 loss std/mean: 0.04791926592588425 0.30429837107658386\n",
      "| Loss std:   0.047919 |\n",
      "| Loss mean:   0.304298 |\n",
      "g_step: 500 loss std/mean: 0.049862090498209 0.3090531826019287\n",
      "| Loss std:   0.049862 |\n",
      "| Loss mean:   0.309053 |\n",
      "g_step: 600 loss std/mean: 0.05640321597456932 0.3172600567340851\n",
      "| Loss std:   0.056403 |\n",
      "| Loss mean:   0.317260 |\n",
      "g_step: 700 loss std/mean: 0.04988197982311249 0.301723450422287\n",
      "| Loss std:   0.049882 |\n",
      "| Loss mean:   0.301723 |\n",
      "g_step: 800 loss std/mean: 0.05784085765480995 0.3101707696914673\n",
      "| Loss std:   0.057841 |\n",
      "| Loss mean:   0.310171 |\n",
      "g_step: 900 loss std/mean: 0.056519437581300735 0.30434972047805786\n",
      "| Loss std:   0.056519 |\n",
      "| Loss mean:   0.304350 |\n",
      "g_step: 1000 loss std/mean: 0.0584997721016407 0.3055291175842285\n",
      "| Loss std:   0.058500 |\n",
      "| Loss mean:   0.305529 |\n",
      "g_step: 1100 loss std/mean: 0.03669363632798195 0.2903692126274109\n",
      "| Loss std:   0.036694 |\n",
      "| Loss mean:   0.290369 |\n",
      "g_step: 1200 loss std/mean: 0.05647670477628708 0.3090384602546692\n",
      "| Loss std:   0.056477 |\n",
      "| Loss mean:   0.309038 |\n",
      "g_step: 1300 loss std/mean: 0.04379018396139145 0.29296618700027466\n",
      "| Loss std:   0.043790 |\n",
      "| Loss mean:   0.292966 |\n",
      "g_step: 1400 loss std/mean: 0.05016634613275528 0.2899019122123718\n",
      "| Loss std:   0.050166 |\n",
      "| Loss mean:   0.289902 |\n",
      "g_step: 1500 loss std/mean: 0.04393615946173668 0.28892460465431213\n",
      "| Loss std:   0.043936 |\n",
      "| Loss mean:   0.288925 |\n",
      "g_step: 1600 loss std/mean: 0.04063226282596588 0.2835489511489868\n",
      "| Loss std:   0.040632 |\n",
      "| Loss mean:   0.283549 |\n",
      "g_step: 1700 loss std/mean: 0.04489066079258919 0.28956520557403564\n",
      "| Loss std:   0.044891 |\n",
      "| Loss mean:   0.289565 |\n",
      "g_step: 1800 loss std/mean: 0.05392669141292572 0.29100775718688965\n",
      "| Loss std:   0.053927 |\n",
      "| Loss mean:   0.291008 |\n",
      "g_step: 1900 loss std/mean: 0.05051707848906517 0.2870687246322632\n",
      "| Loss std:   0.050517 |\n",
      "| Loss mean:   0.287069 |\n",
      "g_step: 2000 loss std/mean: 0.0507730096578598 0.2854076623916626\n",
      "| Loss std:   0.050773 |\n",
      "| Loss mean:   0.285408 |\n",
      "g_step: 2100 loss std/mean: 0.0644511952996254 0.3022030293941498\n",
      "| Loss std:   0.064451 |\n",
      "| Loss mean:   0.302203 |\n",
      "g_step: 2200 loss std/mean: 0.048976268619298935 0.2910168170928955\n",
      "| Loss std:   0.048976 |\n",
      "| Loss mean:   0.291017 |\n",
      "g_step: 2300 loss std/mean: 0.04250599443912506 0.28763750195503235\n",
      "| Loss std:   0.042506 |\n",
      "| Loss mean:   0.287638 |\n",
      "g_step: 2400 loss std/mean: 0.037136200815439224 0.2769404649734497\n",
      "| Loss std:   0.037136 |\n",
      "| Loss mean:   0.276940 |\n",
      "g_step: 2500 loss std/mean: 0.03820536285638809 0.2878822088241577\n",
      "| Loss std:   0.038205 |\n",
      "| Loss mean:   0.287882 |\n",
      "g_step: 2600 loss std/mean: 0.04655405879020691 0.2771035134792328\n",
      "| Loss std:   0.046554 |\n",
      "| Loss mean:   0.277104 |\n",
      "g_step: 2700 loss std/mean: 0.027403276413679123 0.2679637670516968\n",
      "| Loss std:   0.027403 |\n",
      "| Loss mean:   0.267964 |\n",
      "g_step: 2800 loss std/mean: 0.04195457324385643 0.27924758195877075\n",
      "| Loss std:   0.041955 |\n",
      "| Loss mean:   0.279248 |\n",
      "g_step: 2900 loss std/mean: 0.044125791639089584 0.28894293308258057\n",
      "| Loss std:   0.044126 |\n",
      "| Loss mean:   0.288943 |\n",
      "g_step: 3000 loss std/mean: 0.041774194687604904 0.28043806552886963\n",
      "| Loss std:   0.041774 |\n",
      "| Loss mean:   0.280438 |\n",
      "g_step: 3100 loss std/mean: 0.06099443510174751 0.30250218510627747\n",
      "| Loss std:   0.060994 |\n",
      "| Loss mean:   0.302502 |\n",
      "g_step: 3200 loss std/mean: 0.06157859042286873 0.2948339581489563\n",
      "| Loss std:   0.061579 |\n",
      "| Loss mean:   0.294834 |\n",
      "g_step: 3300 loss std/mean: 0.04526620730757713 0.28156086802482605\n",
      "| Loss std:   0.045266 |\n",
      "| Loss mean:   0.281561 |\n",
      "g_step: 3400 loss std/mean: 0.042416516691446304 0.2789531648159027\n",
      "| Loss std:   0.042417 |\n",
      "| Loss mean:   0.278953 |\n",
      "g_step: 3500 loss std/mean: 0.045694563537836075 0.2841273844242096\n",
      "| Loss std:   0.045695 |\n",
      "| Loss mean:   0.284127 |\n",
      "g_step: 3600 loss std/mean: 0.050255149602890015 0.2880597412586212\n",
      "| Loss std:   0.050255 |\n",
      "| Loss mean:   0.288060 |\n",
      "g_step: 3700 loss std/mean: 0.04420376569032669 0.2910233438014984\n",
      "| Loss std:   0.044204 |\n",
      "| Loss mean:   0.291023 |\n",
      "g_step: 3800 loss std/mean: 0.03651944547891617 0.2728247344493866\n",
      "| Loss std:   0.036519 |\n",
      "| Loss mean:   0.272825 |\n",
      "g_step: 3900 loss std/mean: 0.04649777710437775 0.27841344475746155\n",
      "| Loss std:   0.046498 |\n",
      "| Loss mean:   0.278413 |\n",
      "g_step: 4000 loss std/mean: 0.03707871586084366 0.26962509751319885\n",
      "| Loss std:   0.037079 |\n",
      "| Loss mean:   0.269625 |\n",
      "g_step: 4100 loss std/mean: 0.0535837821662426 0.2933383882045746\n",
      "| Loss std:   0.053584 |\n",
      "| Loss mean:   0.293338 |\n",
      "g_step: 4200 loss std/mean: 0.04760965332388878 0.28103286027908325\n",
      "| Loss std:   0.047610 |\n",
      "| Loss mean:   0.281033 |\n",
      "g_step: 4300 loss std/mean: 0.053402211517095566 0.2825152277946472\n",
      "| Loss std:   0.053402 |\n",
      "| Loss mean:   0.282515 |\n",
      "g_step: 4400 loss std/mean: 0.03846069797873497 0.27595412731170654\n",
      "| Loss std:   0.038461 |\n",
      "| Loss mean:   0.275954 |\n",
      "g_step: 4500 loss std/mean: 0.04319455847144127 0.2800777554512024\n",
      "| Loss std:   0.043195 |\n",
      "| Loss mean:   0.280078 |\n",
      "g_step: 4600 loss std/mean: 0.028689825907349586 0.2659458816051483\n",
      "| Loss std:   0.028690 |\n",
      "| Loss mean:   0.265946 |\n",
      "g_step: 4700 loss std/mean: 0.04743465781211853 0.2905839681625366\n",
      "| Loss std:   0.047435 |\n",
      "| Loss mean:   0.290584 |\n",
      "g_step: 4800 loss std/mean: 0.029239840805530548 0.2803749442100525\n",
      "| Loss std:   0.029240 |\n",
      "| Loss mean:   0.280375 |\n",
      "g_step: 4900 loss std/mean: 0.043133411556482315 0.2896878123283386\n",
      "| Loss std:   0.043133 |\n",
      "| Loss mean:   0.289688 |\n",
      "g_step: 5000 loss std/mean: 0.046477045863866806 0.2750670909881592\n",
      "| Loss std:   0.046477 |\n",
      "| Loss mean:   0.275067 |\n",
      "\tValidation NWRMSLE  : 0.541880820463\n",
      "| Validation NWRMSLE:   0.541881 |\n",
      "\tValidation NWRMSLE_5: 0.534570740826\n",
      "| Validation NWRMSLE_5:   0.534571 |\n",
      "g_step: 5100 loss std/mean: 0.0413847379386425 0.27756911516189575\n",
      "| Loss std:   0.041385 |\n",
      "| Loss mean:   0.277569 |\n",
      "g_step: 5200 loss std/mean: 0.04359179362654686 0.27634352445602417\n",
      "| Loss std:   0.043592 |\n",
      "| Loss mean:   0.276344 |\n",
      "g_step: 5300 loss std/mean: 0.03049747459590435 0.26760953664779663\n",
      "| Loss std:   0.030497 |\n",
      "| Loss mean:   0.267610 |\n",
      "g_step: 5400 loss std/mean: 0.03374948725104332 0.27930840849876404\n",
      "| Loss std:   0.033749 |\n",
      "| Loss mean:   0.279308 |\n",
      "g_step: 5500 loss std/mean: 0.03362853452563286 0.27342480421066284\n",
      "| Loss std:   0.033629 |\n",
      "| Loss mean:   0.273425 |\n",
      "g_step: 5600 loss std/mean: 0.037620317190885544 0.272032767534256\n",
      "| Loss std:   0.037620 |\n",
      "| Loss mean:   0.272033 |\n",
      "g_step: 5700 loss std/mean: 0.03686308488249779 0.2705634832382202\n",
      "| Loss std:   0.036863 |\n",
      "| Loss mean:   0.270563 |\n",
      "g_step: 5800 loss std/mean: 0.037524085491895676 0.28126370906829834\n",
      "| Loss std:   0.037524 |\n",
      "| Loss mean:   0.281264 |\n",
      "g_step: 5900 loss std/mean: 0.03382767364382744 0.270785927772522\n",
      "| Loss std:   0.033828 |\n",
      "| Loss mean:   0.270786 |\n",
      "g_step: 6000 loss std/mean: 0.045978251844644547 0.28907260298728943\n",
      "| Loss std:   0.045978 |\n",
      "| Loss mean:   0.289073 |\n",
      "g_step: 6100 loss std/mean: 0.04309218376874924 0.27949440479278564\n",
      "| Loss std:   0.043092 |\n",
      "| Loss mean:   0.279494 |\n",
      "g_step: 6200 loss std/mean: 0.03876640647649765 0.2731282114982605\n",
      "| Loss std:   0.038766 |\n",
      "| Loss mean:   0.273128 |\n",
      "g_step: 6300 loss std/mean: 0.04011612758040428 0.2753252685070038\n",
      "| Loss std:   0.040116 |\n",
      "| Loss mean:   0.275325 |\n",
      "g_step: 6400 loss std/mean: 0.04013600945472717 0.27229762077331543\n",
      "| Loss std:   0.040136 |\n",
      "| Loss mean:   0.272298 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 6500 loss std/mean: 0.041622646152973175 0.2753021717071533\n",
      "| Loss std:   0.041623 |\n",
      "| Loss mean:   0.275302 |\n",
      "g_step: 6600 loss std/mean: 0.03317376226186752 0.276874840259552\n",
      "| Loss std:   0.033174 |\n",
      "| Loss mean:   0.276875 |\n",
      "g_step: 6700 loss std/mean: 0.04397613927721977 0.2714592218399048\n",
      "| Loss std:   0.043976 |\n",
      "| Loss mean:   0.271459 |\n",
      "g_step: 6800 loss std/mean: 0.03457670286297798 0.2617335617542267\n",
      "| Loss std:   0.034577 |\n",
      "| Loss mean:   0.261734 |\n",
      "g_step: 6900 loss std/mean: 0.036569323390722275 0.2724702060222626\n",
      "| Loss std:   0.036569 |\n",
      "| Loss mean:   0.272470 |\n",
      "g_step: 7000 loss std/mean: 0.03355363756418228 0.2732163369655609\n",
      "| Loss std:   0.033554 |\n",
      "| Loss mean:   0.273216 |\n",
      "g_step: 7100 loss std/mean: 0.031359199434518814 0.27818459272384644\n",
      "| Loss std:   0.031359 |\n",
      "| Loss mean:   0.278185 |\n",
      "g_step: 7200 loss std/mean: 0.02797783724963665 0.2699315547943115\n",
      "| Loss std:   0.027978 |\n",
      "| Loss mean:   0.269932 |\n",
      "g_step: 7300 loss std/mean: 0.03592121973633766 0.2651994228363037\n",
      "| Loss std:   0.035921 |\n",
      "| Loss mean:   0.265199 |\n",
      "g_step: 7400 loss std/mean: 0.0405910350382328 0.2811223268508911\n",
      "| Loss std:   0.040591 |\n",
      "| Loss mean:   0.281122 |\n",
      "g_step: 7500 loss std/mean: 0.03220589831471443 0.2711171805858612\n",
      "| Loss std:   0.032206 |\n",
      "| Loss mean:   0.271117 |\n",
      "g_step: 7600 loss std/mean: 0.03583672270178795 0.27551501989364624\n",
      "| Loss std:   0.035837 |\n",
      "| Loss mean:   0.275515 |\n",
      "g_step: 7700 loss std/mean: 0.03261887654662132 0.2737540006637573\n",
      "| Loss std:   0.032619 |\n",
      "| Loss mean:   0.273754 |\n",
      "g_step: 7800 loss std/mean: 0.029580270871520042 0.26860445737838745\n",
      "| Loss std:   0.029580 |\n",
      "| Loss mean:   0.268604 |\n",
      "g_step: 7900 loss std/mean: 0.03119070455431938 0.2685900628566742\n",
      "| Loss std:   0.031191 |\n",
      "| Loss mean:   0.268590 |\n",
      "g_step: 8000 loss std/mean: 0.025090185925364494 0.26023268699645996\n",
      "| Loss std:   0.025090 |\n",
      "| Loss mean:   0.260233 |\n",
      "g_step: 8100 loss std/mean: 0.02357240952551365 0.26849839091300964\n",
      "| Loss std:   0.023572 |\n",
      "| Loss mean:   0.268498 |\n",
      "g_step: 8200 loss std/mean: 0.024866396561264992 0.2641199231147766\n",
      "| Loss std:   0.024866 |\n",
      "| Loss mean:   0.264120 |\n",
      "g_step: 8300 loss std/mean: 0.03140515834093094 0.2642136812210083\n",
      "| Loss std:   0.031405 |\n",
      "| Loss mean:   0.264214 |\n",
      "g_step: 8400 loss std/mean: 0.026236683130264282 0.2693483829498291\n",
      "| Loss std:   0.026237 |\n",
      "| Loss mean:   0.269348 |\n",
      "g_step: 8500 loss std/mean: 0.025019600987434387 0.2696482539176941\n",
      "| Loss std:   0.025020 |\n",
      "| Loss mean:   0.269648 |\n",
      "g_step: 8600 loss std/mean: 0.038493551313877106 0.2714901268482208\n",
      "| Loss std:   0.038494 |\n",
      "| Loss mean:   0.271490 |\n",
      "g_step: 8700 loss std/mean: 0.02592572383582592 0.2589264214038849\n",
      "| Loss std:   0.025926 |\n",
      "| Loss mean:   0.258926 |\n",
      "g_step: 8800 loss std/mean: 0.03336915746331215 0.2664716839790344\n",
      "| Loss std:   0.033369 |\n",
      "| Loss mean:   0.266472 |\n",
      "g_step: 8900 loss std/mean: 0.034750375896692276 0.26203453540802\n",
      "| Loss std:   0.034750 |\n",
      "| Loss mean:   0.262035 |\n",
      "g_step: 9000 loss std/mean: 0.03567374497652054 0.27700111269950867\n",
      "| Loss std:   0.035674 |\n",
      "| Loss mean:   0.277001 |\n",
      "g_step: 9100 loss std/mean: 0.02958737313747406 0.2741532623767853\n",
      "| Loss std:   0.029587 |\n",
      "| Loss mean:   0.274153 |\n",
      "g_step: 9200 loss std/mean: 0.028983747586607933 0.2735562026500702\n",
      "| Loss std:   0.028984 |\n",
      "| Loss mean:   0.273556 |\n",
      "g_step: 9300 loss std/mean: 0.03517237678170204 0.27021217346191406\n",
      "| Loss std:   0.035172 |\n",
      "| Loss mean:   0.270212 |\n",
      "g_step: 9400 loss std/mean: 0.030992494896054268 0.2628972828388214\n",
      "| Loss std:   0.030992 |\n",
      "| Loss mean:   0.262897 |\n",
      "g_step: 9500 loss std/mean: 0.028285661712288857 0.27134591341018677\n",
      "| Loss std:   0.028286 |\n",
      "| Loss mean:   0.271346 |\n",
      "g_step: 9600 loss std/mean: 0.02748895436525345 0.26636019349098206\n",
      "| Loss std:   0.027489 |\n",
      "| Loss mean:   0.266360 |\n",
      "g_step: 9700 loss std/mean: 0.03320949152112007 0.2649165689945221\n",
      "| Loss std:   0.033209 |\n",
      "| Loss mean:   0.264917 |\n",
      "g_step: 9800 loss std/mean: 0.027682632207870483 0.2665599584579468\n",
      "| Loss std:   0.027683 |\n",
      "| Loss mean:   0.266560 |\n",
      "g_step: 9900 loss std/mean: 0.032356008887290955 0.2672896385192871\n",
      "| Loss std:   0.032356 |\n",
      "| Loss mean:   0.267290 |\n",
      "g_step: 10000 loss std/mean: 0.026656167581677437 0.25917816162109375\n",
      "| Loss std:   0.026656 |\n",
      "| Loss mean:   0.259178 |\n",
      "\tValidation NWRMSLE  : 0.539032981412\n",
      "| Validation NWRMSLE:   0.539033 |\n",
      "\tValidation NWRMSLE_5: 0.530503726155\n",
      "| Validation NWRMSLE_5:   0.530504 |\n",
      "g_step: 10100 loss std/mean: 0.031441595405340195 0.2646876275539398\n",
      "| Loss std:   0.031442 |\n",
      "| Loss mean:   0.264688 |\n",
      "g_step: 10200 loss std/mean: 0.03192126750946045 0.2672286927700043\n",
      "| Loss std:   0.031921 |\n",
      "| Loss mean:   0.267229 |\n",
      "g_step: 10300 loss std/mean: 0.03257220238447189 0.25994521379470825\n",
      "| Loss std:   0.032572 |\n",
      "| Loss mean:   0.259945 |\n",
      "g_step: 10400 loss std/mean: 0.02898920699954033 0.2697915732860565\n",
      "| Loss std:   0.028989 |\n",
      "| Loss mean:   0.269792 |\n",
      "g_step: 10500 loss std/mean: 0.03183494135737419 0.2640690505504608\n",
      "| Loss std:   0.031835 |\n",
      "| Loss mean:   0.264069 |\n",
      "g_step: 10600 loss std/mean: 0.019914250820875168 0.26391205191612244\n",
      "| Loss std:   0.019914 |\n",
      "| Loss mean:   0.263912 |\n",
      "g_step: 10700 loss std/mean: 0.0262586772441864 0.2711237370967865\n",
      "| Loss std:   0.026259 |\n",
      "| Loss mean:   0.271124 |\n",
      "g_step: 10800 loss std/mean: 0.030386529862880707 0.2682695984840393\n",
      "| Loss std:   0.030387 |\n",
      "| Loss mean:   0.268270 |\n",
      "g_step: 10900 loss std/mean: 0.02685103937983513 0.2637777626514435\n",
      "| Loss std:   0.026851 |\n",
      "| Loss mean:   0.263778 |\n",
      "g_step: 11000 loss std/mean: 0.02681209146976471 0.25958338379859924\n",
      "| Loss std:   0.026812 |\n",
      "| Loss mean:   0.259583 |\n",
      "g_step: 11100 loss std/mean: 0.029115989804267883 0.2637719511985779\n",
      "| Loss std:   0.029116 |\n",
      "| Loss mean:   0.263772 |\n",
      "g_step: 11200 loss std/mean: 0.027332304045557976 0.2677260637283325\n",
      "| Loss std:   0.027332 |\n",
      "| Loss mean:   0.267726 |\n",
      "g_step: 11300 loss std/mean: 0.026210978627204895 0.26291733980178833\n",
      "| Loss std:   0.026211 |\n",
      "| Loss mean:   0.262917 |\n",
      "g_step: 11400 loss std/mean: 0.024849217385053635 0.26137295365333557\n",
      "| Loss std:   0.024849 |\n",
      "| Loss mean:   0.261373 |\n",
      "g_step: 11500 loss std/mean: 0.024843722581863403 0.25915631651878357\n",
      "| Loss std:   0.024844 |\n",
      "| Loss mean:   0.259156 |\n",
      "g_step: 11600 loss std/mean: 0.027023836970329285 0.2617068588733673\n",
      "| Loss std:   0.027024 |\n",
      "| Loss mean:   0.261707 |\n",
      "g_step: 11700 loss std/mean: 0.0291256383061409 0.2566283047199249\n",
      "| Loss std:   0.029126 |\n",
      "| Loss mean:   0.256628 |\n",
      "g_step: 11800 loss std/mean: 0.029064344242215157 0.2663067877292633\n",
      "| Loss std:   0.029064 |\n",
      "| Loss mean:   0.266307 |\n",
      "g_step: 11900 loss std/mean: 0.024965865537524223 0.26745325326919556\n",
      "| Loss std:   0.024966 |\n",
      "| Loss mean:   0.267453 |\n",
      "g_step: 12000 loss std/mean: 0.027057170867919922 0.26152506470680237\n",
      "| Loss std:   0.027057 |\n",
      "| Loss mean:   0.261525 |\n",
      "g_step: 12100 loss std/mean: 0.021897315979003906 0.262284517288208\n",
      "| Loss std:   0.021897 |\n",
      "| Loss mean:   0.262285 |\n",
      "g_step: 12200 loss std/mean: 0.02751825749874115 0.2632911801338196\n",
      "| Loss std:   0.027518 |\n",
      "| Loss mean:   0.263291 |\n",
      "g_step: 12300 loss std/mean: 0.026387391611933708 0.2614227533340454\n",
      "| Loss std:   0.026387 |\n",
      "| Loss mean:   0.261423 |\n",
      "g_step: 12400 loss std/mean: 0.023630358278751373 0.2668403685092926\n",
      "| Loss std:   0.023630 |\n",
      "| Loss mean:   0.266840 |\n",
      "g_step: 12500 loss std/mean: 0.0284066591411829 0.261961966753006\n",
      "| Loss std:   0.028407 |\n",
      "| Loss mean:   0.261962 |\n",
      "g_step: 12600 loss std/mean: 0.02325129508972168 0.26799267530441284\n",
      "| Loss std:   0.023251 |\n",
      "| Loss mean:   0.267993 |\n",
      "g_step: 12700 loss std/mean: 0.023254282772541046 0.2593478262424469\n",
      "| Loss std:   0.023254 |\n",
      "| Loss mean:   0.259348 |\n",
      "g_step: 12800 loss std/mean: 0.023260608315467834 0.26666831970214844\n",
      "| Loss std:   0.023261 |\n",
      "| Loss mean:   0.266668 |\n",
      "g_step: 12900 loss std/mean: 0.02548941783607006 0.26281487941741943\n",
      "| Loss std:   0.025489 |\n",
      "| Loss mean:   0.262815 |\n",
      "g_step: 13000 loss std/mean: 0.025952499359846115 0.26355433464050293\n",
      "| Loss std:   0.025952 |\n",
      "| Loss mean:   0.263554 |\n",
      "g_step: 13100 loss std/mean: 0.028166228905320168 0.25764259696006775\n",
      "| Loss std:   0.028166 |\n",
      "| Loss mean:   0.257643 |\n",
      "g_step: 13200 loss std/mean: 0.023555127903819084 0.26782864332199097\n",
      "| Loss std:   0.023555 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.267829 |\n",
      "g_step: 13300 loss std/mean: 0.0294482558965683 0.25652235746383667\n",
      "| Loss std:   0.029448 |\n",
      "| Loss mean:   0.256522 |\n",
      "g_step: 13400 loss std/mean: 0.03435644507408142 0.2571505308151245\n",
      "| Loss std:   0.034356 |\n",
      "| Loss mean:   0.257151 |\n",
      "g_step: 13500 loss std/mean: 0.031202297657728195 0.2664894759654999\n",
      "| Loss std:   0.031202 |\n",
      "| Loss mean:   0.266489 |\n",
      "g_step: 13600 loss std/mean: 0.026705248281359673 0.2690742611885071\n",
      "| Loss std:   0.026705 |\n",
      "| Loss mean:   0.269074 |\n",
      "g_step: 13700 loss std/mean: 0.02668011374771595 0.2613024115562439\n",
      "| Loss std:   0.026680 |\n",
      "| Loss mean:   0.261302 |\n",
      "g_step: 13800 loss std/mean: 0.02744857594370842 0.2662462294101715\n",
      "| Loss std:   0.027449 |\n",
      "| Loss mean:   0.266246 |\n",
      "g_step: 13900 loss std/mean: 0.02704527974128723 0.26076042652130127\n",
      "| Loss std:   0.027045 |\n",
      "| Loss mean:   0.260760 |\n",
      "g_step: 14000 loss std/mean: 0.0253080315887928 0.26612958312034607\n",
      "| Loss std:   0.025308 |\n",
      "| Loss mean:   0.266130 |\n",
      "g_step: 14100 loss std/mean: 0.030315887182950974 0.2651714086532593\n",
      "| Loss std:   0.030316 |\n",
      "| Loss mean:   0.265171 |\n",
      "g_step: 14200 loss std/mean: 0.03231858089566231 0.2638278901576996\n",
      "| Loss std:   0.032319 |\n",
      "| Loss mean:   0.263828 |\n",
      "g_step: 14300 loss std/mean: 0.0263467226177454 0.25965383648872375\n",
      "| Loss std:   0.026347 |\n",
      "| Loss mean:   0.259654 |\n",
      "g_step: 14400 loss std/mean: 0.024132030084729195 0.2556624114513397\n",
      "| Loss std:   0.024132 |\n",
      "| Loss mean:   0.255662 |\n",
      "g_step: 14500 loss std/mean: 0.02724006585776806 0.25906115770339966\n",
      "| Loss std:   0.027240 |\n",
      "| Loss mean:   0.259061 |\n",
      "g_step: 14600 loss std/mean: 0.028872253373265266 0.26592326164245605\n",
      "| Loss std:   0.028872 |\n",
      "| Loss mean:   0.265923 |\n",
      "g_step: 14700 loss std/mean: 0.030999168753623962 0.26542067527770996\n",
      "| Loss std:   0.030999 |\n",
      "| Loss mean:   0.265421 |\n",
      "g_step: 14800 loss std/mean: 0.028089772909879684 0.2601461410522461\n",
      "| Loss std:   0.028090 |\n",
      "| Loss mean:   0.260146 |\n",
      "g_step: 14900 loss std/mean: 0.02567281201481819 0.260761022567749\n",
      "| Loss std:   0.025673 |\n",
      "| Loss mean:   0.260761 |\n",
      "g_step: 15000 loss std/mean: 0.029226839542388916 0.2628672420978546\n",
      "| Loss std:   0.029227 |\n",
      "| Loss mean:   0.262867 |\n",
      "\tValidation NWRMSLE  : 0.53450582417\n",
      "| Validation NWRMSLE:   0.534506 |\n",
      "\tValidation NWRMSLE_5: 0.526640372653\n",
      "| Validation NWRMSLE_5:   0.526640 |\n",
      "g_step: 15100 loss std/mean: 0.02855345420539379 0.25447922945022583\n",
      "| Loss std:   0.028553 |\n",
      "| Loss mean:   0.254479 |\n",
      "g_step: 15200 loss std/mean: 0.031145446002483368 0.2591625452041626\n",
      "| Loss std:   0.031145 |\n",
      "| Loss mean:   0.259163 |\n",
      "g_step: 15300 loss std/mean: 0.027912849560379982 0.2569540739059448\n",
      "| Loss std:   0.027913 |\n",
      "| Loss mean:   0.256954 |\n",
      "g_step: 15400 loss std/mean: 0.03111455589532852 0.25667399168014526\n",
      "| Loss std:   0.031115 |\n",
      "| Loss mean:   0.256674 |\n",
      "g_step: 15500 loss std/mean: 0.02616613358259201 0.26748210191726685\n",
      "| Loss std:   0.026166 |\n",
      "| Loss mean:   0.267482 |\n",
      "g_step: 15600 loss std/mean: 0.022951513528823853 0.26343342661857605\n",
      "| Loss std:   0.022952 |\n",
      "| Loss mean:   0.263433 |\n",
      "g_step: 15700 loss std/mean: 0.0271519273519516 0.2545987665653229\n",
      "| Loss std:   0.027152 |\n",
      "| Loss mean:   0.254599 |\n",
      "g_step: 15800 loss std/mean: 0.023338284343481064 0.2562623918056488\n",
      "| Loss std:   0.023338 |\n",
      "| Loss mean:   0.256262 |\n",
      "g_step: 15900 loss std/mean: 0.0271732360124588 0.2611885368824005\n",
      "| Loss std:   0.027173 |\n",
      "| Loss mean:   0.261189 |\n",
      "g_step: 16000 loss std/mean: 0.026281440630555153 0.25750166177749634\n",
      "| Loss std:   0.026281 |\n",
      "| Loss mean:   0.257502 |\n",
      "g_step: 16100 loss std/mean: 0.026826908811926842 0.25815674662590027\n",
      "| Loss std:   0.026827 |\n",
      "| Loss mean:   0.258157 |\n",
      "g_step: 16200 loss std/mean: 0.026926925405859947 0.2577410042285919\n",
      "| Loss std:   0.026927 |\n",
      "| Loss mean:   0.257741 |\n",
      "g_step: 16300 loss std/mean: 0.029044626280665398 0.26225945353507996\n",
      "| Loss std:   0.029045 |\n",
      "| Loss mean:   0.262259 |\n",
      "g_step: 16400 loss std/mean: 0.025469815358519554 0.252392053604126\n",
      "| Loss std:   0.025470 |\n",
      "| Loss mean:   0.252392 |\n",
      "g_step: 16500 loss std/mean: 0.02517559938132763 0.25684434175491333\n",
      "| Loss std:   0.025176 |\n",
      "| Loss mean:   0.256844 |\n",
      "g_step: 16600 loss std/mean: 0.024054178968071938 0.2574826776981354\n",
      "| Loss std:   0.024054 |\n",
      "| Loss mean:   0.257483 |\n",
      "g_step: 16700 loss std/mean: 0.027827931568026543 0.2526203989982605\n",
      "| Loss std:   0.027828 |\n",
      "| Loss mean:   0.252620 |\n",
      "g_step: 16800 loss std/mean: 0.02987498603761196 0.25431057810783386\n",
      "| Loss std:   0.029875 |\n",
      "| Loss mean:   0.254311 |\n",
      "g_step: 16900 loss std/mean: 0.02921879291534424 0.26150208711624146\n",
      "| Loss std:   0.029219 |\n",
      "| Loss mean:   0.261502 |\n",
      "g_step: 17000 loss std/mean: 0.026793086901307106 0.2607717216014862\n",
      "| Loss std:   0.026793 |\n",
      "| Loss mean:   0.260772 |\n",
      "g_step: 17100 loss std/mean: 0.024521153420209885 0.2551584541797638\n",
      "| Loss std:   0.024521 |\n",
      "| Loss mean:   0.255158 |\n",
      "g_step: 17200 loss std/mean: 0.02343476563692093 0.2623439431190491\n",
      "| Loss std:   0.023435 |\n",
      "| Loss mean:   0.262344 |\n",
      "g_step: 17300 loss std/mean: 0.02415533736348152 0.2640499174594879\n",
      "| Loss std:   0.024155 |\n",
      "| Loss mean:   0.264050 |\n",
      "g_step: 17400 loss std/mean: 0.02075299248099327 0.2581160366535187\n",
      "| Loss std:   0.020753 |\n",
      "| Loss mean:   0.258116 |\n",
      "g_step: 17500 loss std/mean: 0.027603276073932648 0.2531353235244751\n",
      "| Loss std:   0.027603 |\n",
      "| Loss mean:   0.253135 |\n",
      "g_step: 17600 loss std/mean: 0.025928471237421036 0.2596237063407898\n",
      "| Loss std:   0.025928 |\n",
      "| Loss mean:   0.259624 |\n",
      "g_step: 17700 loss std/mean: 0.027162814512848854 0.2604290843009949\n",
      "| Loss std:   0.027163 |\n",
      "| Loss mean:   0.260429 |\n",
      "g_step: 17800 loss std/mean: 0.022959232330322266 0.2538544237613678\n",
      "| Loss std:   0.022959 |\n",
      "| Loss mean:   0.253854 |\n",
      "g_step: 17900 loss std/mean: 0.030103182420134544 0.25500211119651794\n",
      "| Loss std:   0.030103 |\n",
      "| Loss mean:   0.255002 |\n",
      "g_step: 18000 loss std/mean: 0.02429252117872238 0.2542855739593506\n",
      "| Loss std:   0.024293 |\n",
      "| Loss mean:   0.254286 |\n",
      "g_step: 18100 loss std/mean: 0.025290852412581444 0.2523980438709259\n",
      "| Loss std:   0.025291 |\n",
      "| Loss mean:   0.252398 |\n",
      "g_step: 18200 loss std/mean: 0.02959362231194973 0.2579191327095032\n",
      "| Loss std:   0.029594 |\n",
      "| Loss mean:   0.257919 |\n",
      "g_step: 18300 loss std/mean: 0.02582411654293537 0.2589612305164337\n",
      "| Loss std:   0.025824 |\n",
      "| Loss mean:   0.258961 |\n",
      "g_step: 18400 loss std/mean: 0.027622992172837257 0.2538934051990509\n",
      "| Loss std:   0.027623 |\n",
      "| Loss mean:   0.253893 |\n",
      "g_step: 18500 loss std/mean: 0.021963104605674744 0.2605842053890228\n",
      "| Loss std:   0.021963 |\n",
      "| Loss mean:   0.260584 |\n",
      "g_step: 18600 loss std/mean: 0.02751629799604416 0.2626335918903351\n",
      "| Loss std:   0.027516 |\n",
      "| Loss mean:   0.262634 |\n",
      "g_step: 18700 loss std/mean: 0.02781938947737217 0.2534995377063751\n",
      "| Loss std:   0.027819 |\n",
      "| Loss mean:   0.253500 |\n",
      "g_step: 18800 loss std/mean: 0.028378121554851532 0.260622501373291\n",
      "| Loss std:   0.028378 |\n",
      "| Loss mean:   0.260623 |\n",
      "g_step: 18900 loss std/mean: 0.02125091478228569 0.2597200274467468\n",
      "| Loss std:   0.021251 |\n",
      "| Loss mean:   0.259720 |\n",
      "g_step: 19000 loss std/mean: 0.02238035947084427 0.2577510178089142\n",
      "| Loss std:   0.022380 |\n",
      "| Loss mean:   0.257751 |\n",
      "g_step: 19100 loss std/mean: 0.028659185394644737 0.2529235780239105\n",
      "| Loss std:   0.028659 |\n",
      "| Loss mean:   0.252924 |\n",
      "g_step: 19200 loss std/mean: 0.024261509999632835 0.2507517635822296\n",
      "| Loss std:   0.024262 |\n",
      "| Loss mean:   0.250752 |\n",
      "g_step: 19300 loss std/mean: 0.027221763506531715 0.2599744200706482\n",
      "| Loss std:   0.027222 |\n",
      "| Loss mean:   0.259974 |\n",
      "g_step: 19400 loss std/mean: 0.023823708295822144 0.25507622957229614\n",
      "| Loss std:   0.023824 |\n",
      "| Loss mean:   0.255076 |\n",
      "g_step: 19500 loss std/mean: 0.02051744982600212 0.25813743472099304\n",
      "| Loss std:   0.020517 |\n",
      "| Loss mean:   0.258137 |\n",
      "g_step: 19600 loss std/mean: 0.025790099054574966 0.2546948194503784\n",
      "| Loss std:   0.025790 |\n",
      "| Loss mean:   0.254695 |\n",
      "g_step: 19700 loss std/mean: 0.028393074870109558 0.2617770731449127\n",
      "| Loss std:   0.028393 |\n",
      "| Loss mean:   0.261777 |\n",
      "g_step: 19800 loss std/mean: 0.026206497102975845 0.25871527194976807\n",
      "| Loss std:   0.026206 |\n",
      "| Loss mean:   0.258715 |\n",
      "g_step: 19900 loss std/mean: 0.028450699523091316 0.25158917903900146\n",
      "| Loss std:   0.028451 |\n",
      "| Loss mean:   0.251589 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 20000 loss std/mean: 0.025669679045677185 0.25130757689476013\n",
      "| Loss std:   0.025670 |\n",
      "| Loss mean:   0.251308 |\n",
      "\tValidation NWRMSLE  : 0.53310310255\n",
      "| Validation NWRMSLE:   0.533103 |\n",
      "\tValidation NWRMSLE_5: 0.525374662044\n",
      "| Validation NWRMSLE_5:   0.525375 |\n",
      "g_step: 20100 loss std/mean: 0.023248976096510887 0.25464722514152527\n",
      "| Loss std:   0.023249 |\n",
      "| Loss mean:   0.254647 |\n",
      "g_step: 20200 loss std/mean: 0.02545763924717903 0.2555767297744751\n",
      "| Loss std:   0.025458 |\n",
      "| Loss mean:   0.255577 |\n",
      "g_step: 20300 loss std/mean: 0.023554623126983643 0.2564777731895447\n",
      "| Loss std:   0.023555 |\n",
      "| Loss mean:   0.256478 |\n",
      "g_step: 20400 loss std/mean: 0.023549240082502365 0.25736692547798157\n",
      "| Loss std:   0.023549 |\n",
      "| Loss mean:   0.257367 |\n",
      "g_step: 20500 loss std/mean: 0.020828647539019585 0.25658121705055237\n",
      "| Loss std:   0.020829 |\n",
      "| Loss mean:   0.256581 |\n",
      "g_step: 20600 loss std/mean: 0.025560157373547554 0.2576771676540375\n",
      "| Loss std:   0.025560 |\n",
      "| Loss mean:   0.257677 |\n",
      "g_step: 20700 loss std/mean: 0.021899981424212456 0.25752004981040955\n",
      "| Loss std:   0.021900 |\n",
      "| Loss mean:   0.257520 |\n",
      "g_step: 20800 loss std/mean: 0.020578477531671524 0.2597562372684479\n",
      "| Loss std:   0.020578 |\n",
      "| Loss mean:   0.259756 |\n",
      "g_step: 20900 loss std/mean: 0.025963613763451576 0.25583669543266296\n",
      "| Loss std:   0.025964 |\n",
      "| Loss mean:   0.255837 |\n",
      "g_step: 21000 loss std/mean: 0.02738669514656067 0.25493133068084717\n",
      "| Loss std:   0.027387 |\n",
      "| Loss mean:   0.254931 |\n",
      "g_step: 21100 loss std/mean: 0.028280265629291534 0.25935935974121094\n",
      "| Loss std:   0.028280 |\n",
      "| Loss mean:   0.259359 |\n",
      "g_step: 21200 loss std/mean: 0.025013478472828865 0.26026055216789246\n",
      "| Loss std:   0.025013 |\n",
      "| Loss mean:   0.260261 |\n",
      "g_step: 21300 loss std/mean: 0.02300036884844303 0.2528228461742401\n",
      "| Loss std:   0.023000 |\n",
      "| Loss mean:   0.252823 |\n",
      "g_step: 21400 loss std/mean: 0.02532694675028324 0.2537446916103363\n",
      "| Loss std:   0.025327 |\n",
      "| Loss mean:   0.253745 |\n",
      "g_step: 21500 loss std/mean: 0.02129371650516987 0.2555554509162903\n",
      "| Loss std:   0.021294 |\n",
      "| Loss mean:   0.255555 |\n",
      "g_step: 21600 loss std/mean: 0.024726614356040955 0.2536616027355194\n",
      "| Loss std:   0.024727 |\n",
      "| Loss mean:   0.253662 |\n",
      "g_step: 21700 loss std/mean: 0.028829917311668396 0.25837627053260803\n",
      "| Loss std:   0.028830 |\n",
      "| Loss mean:   0.258376 |\n",
      "g_step: 21800 loss std/mean: 0.02143113501369953 0.2535252273082733\n",
      "| Loss std:   0.021431 |\n",
      "| Loss mean:   0.253525 |\n",
      "g_step: 21900 loss std/mean: 0.02738102898001671 0.25755539536476135\n",
      "| Loss std:   0.027381 |\n",
      "| Loss mean:   0.257555 |\n",
      "g_step: 22000 loss std/mean: 0.027507400140166283 0.25636571645736694\n",
      "| Loss std:   0.027507 |\n",
      "| Loss mean:   0.256366 |\n",
      "g_step: 22100 loss std/mean: 0.025682060047984123 0.2607627511024475\n",
      "| Loss std:   0.025682 |\n",
      "| Loss mean:   0.260763 |\n",
      "g_step: 22200 loss std/mean: 0.024131257086992264 0.2577338218688965\n",
      "| Loss std:   0.024131 |\n",
      "| Loss mean:   0.257734 |\n",
      "g_step: 22300 loss std/mean: 0.02589466981589794 0.25158393383026123\n",
      "| Loss std:   0.025895 |\n",
      "| Loss mean:   0.251584 |\n",
      "g_step: 22400 loss std/mean: 0.025294024497270584 0.2594599425792694\n",
      "| Loss std:   0.025294 |\n",
      "| Loss mean:   0.259460 |\n",
      "g_step: 22500 loss std/mean: 0.02883097343146801 0.2534935474395752\n",
      "| Loss std:   0.028831 |\n",
      "| Loss mean:   0.253494 |\n",
      "g_step: 22600 loss std/mean: 0.026660585775971413 0.25081565976142883\n",
      "| Loss std:   0.026661 |\n",
      "| Loss mean:   0.250816 |\n",
      "g_step: 22700 loss std/mean: 0.02962671034038067 0.2612312138080597\n",
      "| Loss std:   0.029627 |\n",
      "| Loss mean:   0.261231 |\n",
      "g_step: 22800 loss std/mean: 0.028091398999094963 0.24722257256507874\n",
      "| Loss std:   0.028091 |\n",
      "| Loss mean:   0.247223 |\n",
      "g_step: 22900 loss std/mean: 0.022630849853157997 0.2607324719429016\n",
      "| Loss std:   0.022631 |\n",
      "| Loss mean:   0.260732 |\n",
      "g_step: 23000 loss std/mean: 0.025607416406273842 0.2523641288280487\n",
      "| Loss std:   0.025607 |\n",
      "| Loss mean:   0.252364 |\n",
      "g_step: 23100 loss std/mean: 0.026060445234179497 0.25548356771469116\n",
      "| Loss std:   0.026060 |\n",
      "| Loss mean:   0.255484 |\n",
      "g_step: 23200 loss std/mean: 0.023310914635658264 0.2522601783275604\n",
      "| Loss std:   0.023311 |\n",
      "| Loss mean:   0.252260 |\n",
      "g_step: 23300 loss std/mean: 0.023708980530500412 0.25206467509269714\n",
      "| Loss std:   0.023709 |\n",
      "| Loss mean:   0.252065 |\n",
      "g_step: 23400 loss std/mean: 0.0236000157892704 0.253964364528656\n",
      "| Loss std:   0.023600 |\n",
      "| Loss mean:   0.253964 |\n",
      "g_step: 23500 loss std/mean: 0.0299699530005455 0.256981760263443\n",
      "| Loss std:   0.029970 |\n",
      "| Loss mean:   0.256982 |\n",
      "g_step: 23600 loss std/mean: 0.025774125009775162 0.25243720412254333\n",
      "| Loss std:   0.025774 |\n",
      "| Loss mean:   0.252437 |\n",
      "g_step: 23700 loss std/mean: 0.028026245534420013 0.25616055727005005\n",
      "| Loss std:   0.028026 |\n",
      "| Loss mean:   0.256161 |\n",
      "g_step: 23800 loss std/mean: 0.022357141599059105 0.2493293434381485\n",
      "| Loss std:   0.022357 |\n",
      "| Loss mean:   0.249329 |\n",
      "g_step: 23900 loss std/mean: 0.02372530661523342 0.2576815187931061\n",
      "| Loss std:   0.023725 |\n",
      "| Loss mean:   0.257682 |\n",
      "g_step: 24000 loss std/mean: 0.023666027933359146 0.2592173218727112\n",
      "| Loss std:   0.023666 |\n",
      "| Loss mean:   0.259217 |\n",
      "g_step: 24100 loss std/mean: 0.02661309204995632 0.2595265209674835\n",
      "| Loss std:   0.026613 |\n",
      "| Loss mean:   0.259527 |\n",
      "g_step: 24200 loss std/mean: 0.022271746769547462 0.25489887595176697\n",
      "| Loss std:   0.022272 |\n",
      "| Loss mean:   0.254899 |\n",
      "g_step: 24300 loss std/mean: 0.02785949595272541 0.25453701615333557\n",
      "| Loss std:   0.027859 |\n",
      "| Loss mean:   0.254537 |\n",
      "g_step: 24400 loss std/mean: 0.025943206623196602 0.2592248022556305\n",
      "| Loss std:   0.025943 |\n",
      "| Loss mean:   0.259225 |\n",
      "g_step: 24500 loss std/mean: 0.026580428704619408 0.2560073733329773\n",
      "| Loss std:   0.026580 |\n",
      "| Loss mean:   0.256007 |\n",
      "g_step: 24600 loss std/mean: 0.023443184792995453 0.2539464831352234\n",
      "| Loss std:   0.023443 |\n",
      "| Loss mean:   0.253946 |\n",
      "g_step: 24700 loss std/mean: 0.020310934633016586 0.2514491081237793\n",
      "| Loss std:   0.020311 |\n",
      "| Loss mean:   0.251449 |\n",
      "g_step: 24800 loss std/mean: 0.024170149117708206 0.2576932907104492\n",
      "| Loss std:   0.024170 |\n",
      "| Loss mean:   0.257693 |\n",
      "g_step: 24900 loss std/mean: 0.026597334071993828 0.25542861223220825\n",
      "| Loss std:   0.026597 |\n",
      "| Loss mean:   0.255429 |\n",
      "g_step: 25000 loss std/mean: 0.026897462084889412 0.2604317367076874\n",
      "| Loss std:   0.026897 |\n",
      "| Loss mean:   0.260432 |\n",
      "\tValidation NWRMSLE  : 0.530864136848\n",
      "| Validation NWRMSLE:   0.530864 |\n",
      "\tValidation NWRMSLE_5: 0.524134769868\n",
      "| Validation NWRMSLE_5:   0.524135 |\n",
      "g_step: 25100 loss std/mean: 0.024276601150631905 0.2562287747859955\n",
      "| Loss std:   0.024277 |\n",
      "| Loss mean:   0.256229 |\n",
      "g_step: 25200 loss std/mean: 0.024187346920371056 0.2589505612850189\n",
      "| Loss std:   0.024187 |\n",
      "| Loss mean:   0.258951 |\n",
      "g_step: 25300 loss std/mean: 0.0271705761551857 0.2517918348312378\n",
      "| Loss std:   0.027171 |\n",
      "| Loss mean:   0.251792 |\n",
      "g_step: 25400 loss std/mean: 0.02585737034678459 0.25553837418556213\n",
      "| Loss std:   0.025857 |\n",
      "| Loss mean:   0.255538 |\n",
      "g_step: 25500 loss std/mean: 0.025228925049304962 0.24899528920650482\n",
      "| Loss std:   0.025229 |\n",
      "| Loss mean:   0.248995 |\n",
      "g_step: 25600 loss std/mean: 0.024306517094373703 0.2563570737838745\n",
      "| Loss std:   0.024307 |\n",
      "| Loss mean:   0.256357 |\n",
      "g_step: 25700 loss std/mean: 0.027409696951508522 0.24907077848911285\n",
      "| Loss std:   0.027410 |\n",
      "| Loss mean:   0.249071 |\n",
      "g_step: 25800 loss std/mean: 0.027442691847682 0.2599855065345764\n",
      "| Loss std:   0.027443 |\n",
      "| Loss mean:   0.259986 |\n",
      "g_step: 25900 loss std/mean: 0.028048200532794 0.2587580978870392\n",
      "| Loss std:   0.028048 |\n",
      "| Loss mean:   0.258758 |\n",
      "g_step: 26000 loss std/mean: 0.02584785223007202 0.2531716823577881\n",
      "| Loss std:   0.025848 |\n",
      "| Loss mean:   0.253172 |\n",
      "g_step: 26100 loss std/mean: 0.022637255489826202 0.25383931398391724\n",
      "| Loss std:   0.022637 |\n",
      "| Loss mean:   0.253839 |\n",
      "g_step: 26200 loss std/mean: 0.026002902537584305 0.25677523016929626\n",
      "| Loss std:   0.026003 |\n",
      "| Loss mean:   0.256775 |\n",
      "g_step: 26300 loss std/mean: 0.025088271126151085 0.2530316114425659\n",
      "| Loss std:   0.025088 |\n",
      "| Loss mean:   0.253032 |\n",
      "g_step: 26400 loss std/mean: 0.02812749147415161 0.2530219554901123\n",
      "| Loss std:   0.028127 |\n",
      "| Loss mean:   0.253022 |\n",
      "g_step: 26500 loss std/mean: 0.023771287873387337 0.25064370036125183\n",
      "| Loss std:   0.023771 |\n",
      "| Loss mean:   0.250644 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 26600 loss std/mean: 0.025882622227072716 0.24664218723773956\n",
      "| Loss std:   0.025883 |\n",
      "| Loss mean:   0.246642 |\n",
      "g_step: 26700 loss std/mean: 0.024124804884195328 0.2576996684074402\n",
      "| Loss std:   0.024125 |\n",
      "| Loss mean:   0.257700 |\n",
      "g_step: 26800 loss std/mean: 0.028136951848864555 0.2524099051952362\n",
      "| Loss std:   0.028137 |\n",
      "| Loss mean:   0.252410 |\n",
      "g_step: 26900 loss std/mean: 0.025517644360661507 0.2563152015209198\n",
      "| Loss std:   0.025518 |\n",
      "| Loss mean:   0.256315 |\n",
      "g_step: 27000 loss std/mean: 0.026503723114728928 0.2549471855163574\n",
      "| Loss std:   0.026504 |\n",
      "| Loss mean:   0.254947 |\n",
      "g_step: 27100 loss std/mean: 0.02760527841746807 0.25202009081840515\n",
      "| Loss std:   0.027605 |\n",
      "| Loss mean:   0.252020 |\n",
      "g_step: 27200 loss std/mean: 0.02261299081146717 0.2551206648349762\n",
      "| Loss std:   0.022613 |\n",
      "| Loss mean:   0.255121 |\n",
      "g_step: 27300 loss std/mean: 0.023287879303097725 0.25372493267059326\n",
      "| Loss std:   0.023288 |\n",
      "| Loss mean:   0.253725 |\n",
      "g_step: 27400 loss std/mean: 0.026930445805191994 0.2558753490447998\n",
      "| Loss std:   0.026930 |\n",
      "| Loss mean:   0.255875 |\n",
      "g_step: 27500 loss std/mean: 0.024517390877008438 0.2572631537914276\n",
      "| Loss std:   0.024517 |\n",
      "| Loss mean:   0.257263 |\n",
      "g_step: 27600 loss std/mean: 0.022780507802963257 0.2521975338459015\n",
      "| Loss std:   0.022781 |\n",
      "| Loss mean:   0.252198 |\n",
      "g_step: 27700 loss std/mean: 0.027607770636677742 0.25032055377960205\n",
      "| Loss std:   0.027608 |\n",
      "| Loss mean:   0.250321 |\n",
      "g_step: 27800 loss std/mean: 0.027296653017401695 0.2557137608528137\n",
      "| Loss std:   0.027297 |\n",
      "| Loss mean:   0.255714 |\n",
      "g_step: 27900 loss std/mean: 0.02326628565788269 0.25780877470970154\n",
      "| Loss std:   0.023266 |\n",
      "| Loss mean:   0.257809 |\n",
      "g_step: 28000 loss std/mean: 0.02662070095539093 0.25884807109832764\n",
      "| Loss std:   0.026621 |\n",
      "| Loss mean:   0.258848 |\n",
      "g_step: 28100 loss std/mean: 0.022487252950668335 0.2563132047653198\n",
      "| Loss std:   0.022487 |\n",
      "| Loss mean:   0.256313 |\n",
      "g_step: 28200 loss std/mean: 0.021827133372426033 0.248639315366745\n",
      "| Loss std:   0.021827 |\n",
      "| Loss mean:   0.248639 |\n",
      "g_step: 28300 loss std/mean: 0.02126116305589676 0.2566303014755249\n",
      "| Loss std:   0.021261 |\n",
      "| Loss mean:   0.256630 |\n",
      "g_step: 28400 loss std/mean: 0.024973561987280846 0.2528463900089264\n",
      "| Loss std:   0.024974 |\n",
      "| Loss mean:   0.252846 |\n",
      "g_step: 28500 loss std/mean: 0.025200551375746727 0.25556737184524536\n",
      "| Loss std:   0.025201 |\n",
      "| Loss mean:   0.255567 |\n",
      "g_step: 28600 loss std/mean: 0.02872120775282383 0.2603488266468048\n",
      "| Loss std:   0.028721 |\n",
      "| Loss mean:   0.260349 |\n",
      "g_step: 28700 loss std/mean: 0.0277002714574337 0.2543784976005554\n",
      "| Loss std:   0.027700 |\n",
      "| Loss mean:   0.254378 |\n",
      "g_step: 28800 loss std/mean: 0.025396546348929405 0.24774403870105743\n",
      "| Loss std:   0.025397 |\n",
      "| Loss mean:   0.247744 |\n",
      "g_step: 28900 loss std/mean: 0.02268950827419758 0.25466257333755493\n",
      "| Loss std:   0.022690 |\n",
      "| Loss mean:   0.254663 |\n",
      "g_step: 29000 loss std/mean: 0.024867096915841103 0.253581702709198\n",
      "| Loss std:   0.024867 |\n",
      "| Loss mean:   0.253582 |\n",
      "g_step: 29100 loss std/mean: 0.027638832107186317 0.25601524114608765\n",
      "| Loss std:   0.027639 |\n",
      "| Loss mean:   0.256015 |\n",
      "g_step: 29200 loss std/mean: 0.024124661460518837 0.25926879048347473\n",
      "| Loss std:   0.024125 |\n",
      "| Loss mean:   0.259269 |\n",
      "g_step: 29300 loss std/mean: 0.025494800880551338 0.2554799020290375\n",
      "| Loss std:   0.025495 |\n",
      "| Loss mean:   0.255480 |\n",
      "g_step: 29400 loss std/mean: 0.02585134468972683 0.24826782941818237\n",
      "| Loss std:   0.025851 |\n",
      "| Loss mean:   0.248268 |\n",
      "g_step: 29500 loss std/mean: 0.02226676046848297 0.2558874189853668\n",
      "| Loss std:   0.022267 |\n",
      "| Loss mean:   0.255887 |\n",
      "g_step: 29600 loss std/mean: 0.021272286772727966 0.2516193091869354\n",
      "| Loss std:   0.021272 |\n",
      "| Loss mean:   0.251619 |\n",
      "g_step: 29700 loss std/mean: 0.02522624097764492 0.2589579224586487\n",
      "| Loss std:   0.025226 |\n",
      "| Loss mean:   0.258958 |\n",
      "g_step: 29800 loss std/mean: 0.021383890882134438 0.257602721452713\n",
      "| Loss std:   0.021384 |\n",
      "| Loss mean:   0.257603 |\n",
      "g_step: 29900 loss std/mean: 0.020231682807207108 0.2575875520706177\n",
      "| Loss std:   0.020232 |\n",
      "| Loss mean:   0.257588 |\n",
      "g_step: 30000 loss std/mean: 0.02061569131910801 0.24936369061470032\n",
      "| Loss std:   0.020616 |\n",
      "| Loss mean:   0.249364 |\n",
      "\tValidation NWRMSLE  : 0.530185514432\n",
      "| Validation NWRMSLE:   0.530186 |\n",
      "\tValidation NWRMSLE_5: 0.523141539629\n",
      "| Validation NWRMSLE_5:   0.523142 |\n",
      "g_step: 30100 loss std/mean: 0.023743391036987305 0.26110079884529114\n",
      "| Loss std:   0.023743 |\n",
      "| Loss mean:   0.261101 |\n",
      "g_step: 30200 loss std/mean: 0.02201240509748459 0.2599273920059204\n",
      "| Loss std:   0.022012 |\n",
      "| Loss mean:   0.259927 |\n",
      "g_step: 30300 loss std/mean: 0.024513710290193558 0.250893771648407\n",
      "| Loss std:   0.024514 |\n",
      "| Loss mean:   0.250894 |\n",
      "g_step: 30400 loss std/mean: 0.021811965852975845 0.25608542561531067\n",
      "| Loss std:   0.021812 |\n",
      "| Loss mean:   0.256085 |\n",
      "g_step: 30500 loss std/mean: 0.025130106136202812 0.25184306502342224\n",
      "| Loss std:   0.025130 |\n",
      "| Loss mean:   0.251843 |\n",
      "g_step: 30600 loss std/mean: 0.02688431926071644 0.249607652425766\n",
      "| Loss std:   0.026884 |\n",
      "| Loss mean:   0.249608 |\n",
      "g_step: 30700 loss std/mean: 0.02443096973001957 0.2550419569015503\n",
      "| Loss std:   0.024431 |\n",
      "| Loss mean:   0.255042 |\n",
      "g_step: 30800 loss std/mean: 0.024465670809149742 0.25254419445991516\n",
      "| Loss std:   0.024466 |\n",
      "| Loss mean:   0.252544 |\n",
      "g_step: 30900 loss std/mean: 0.02048002928495407 0.25902295112609863\n",
      "| Loss std:   0.020480 |\n",
      "| Loss mean:   0.259023 |\n",
      "g_step: 31000 loss std/mean: 0.02587496116757393 0.2540147006511688\n",
      "| Loss std:   0.025875 |\n",
      "| Loss mean:   0.254015 |\n",
      "g_step: 31100 loss std/mean: 0.02402859553694725 0.24820919334888458\n",
      "| Loss std:   0.024029 |\n",
      "| Loss mean:   0.248209 |\n",
      "g_step: 31200 loss std/mean: 0.027909506112337112 0.25458991527557373\n",
      "| Loss std:   0.027910 |\n",
      "| Loss mean:   0.254590 |\n",
      "g_step: 31300 loss std/mean: 0.023408513516187668 0.2585058808326721\n",
      "| Loss std:   0.023409 |\n",
      "| Loss mean:   0.258506 |\n",
      "g_step: 31400 loss std/mean: 0.025423947721719742 0.25665274262428284\n",
      "| Loss std:   0.025424 |\n",
      "| Loss mean:   0.256653 |\n",
      "g_step: 31500 loss std/mean: 0.02704557031393051 0.24861854314804077\n",
      "| Loss std:   0.027046 |\n",
      "| Loss mean:   0.248619 |\n",
      "g_step: 31600 loss std/mean: 0.02591973915696144 0.2512122690677643\n",
      "| Loss std:   0.025920 |\n",
      "| Loss mean:   0.251212 |\n",
      "g_step: 31700 loss std/mean: 0.02643788605928421 0.25583311915397644\n",
      "| Loss std:   0.026438 |\n",
      "| Loss mean:   0.255833 |\n",
      "g_step: 31800 loss std/mean: 0.019979339092969894 0.2557879388332367\n",
      "| Loss std:   0.019979 |\n",
      "| Loss mean:   0.255788 |\n",
      "g_step: 31900 loss std/mean: 0.02544206567108631 0.2563657760620117\n",
      "| Loss std:   0.025442 |\n",
      "| Loss mean:   0.256366 |\n",
      "g_step: 32000 loss std/mean: 0.024389147758483887 0.256352961063385\n",
      "| Loss std:   0.024389 |\n",
      "| Loss mean:   0.256353 |\n",
      "g_step: 32100 loss std/mean: 0.026933075860142708 0.2543262541294098\n",
      "| Loss std:   0.026933 |\n",
      "| Loss mean:   0.254326 |\n",
      "g_step: 32200 loss std/mean: 0.029111620038747787 0.2532012164592743\n",
      "| Loss std:   0.029112 |\n",
      "| Loss mean:   0.253201 |\n",
      "g_step: 32300 loss std/mean: 0.025548158213496208 0.25676536560058594\n",
      "| Loss std:   0.025548 |\n",
      "| Loss mean:   0.256765 |\n",
      "g_step: 32400 loss std/mean: 0.024608710780739784 0.2507432997226715\n",
      "| Loss std:   0.024609 |\n",
      "| Loss mean:   0.250743 |\n",
      "g_step: 32500 loss std/mean: 0.0236193910241127 0.26017090678215027\n",
      "| Loss std:   0.023619 |\n",
      "| Loss mean:   0.260171 |\n",
      "g_step: 32600 loss std/mean: 0.026054615154862404 0.251648873090744\n",
      "| Loss std:   0.026055 |\n",
      "| Loss mean:   0.251649 |\n",
      "g_step: 32700 loss std/mean: 0.02401154674589634 0.2553321123123169\n",
      "| Loss std:   0.024012 |\n",
      "| Loss mean:   0.255332 |\n",
      "g_step: 32800 loss std/mean: 0.02768055722117424 0.24997347593307495\n",
      "| Loss std:   0.027681 |\n",
      "| Loss mean:   0.249973 |\n",
      "g_step: 32900 loss std/mean: 0.029162056744098663 0.2540624737739563\n",
      "| Loss std:   0.029162 |\n",
      "| Loss mean:   0.254062 |\n",
      "g_step: 33000 loss std/mean: 0.021434085443615913 0.24854446947574615\n",
      "| Loss std:   0.021434 |\n",
      "| Loss mean:   0.248544 |\n",
      "g_step: 33100 loss std/mean: 0.02195301093161106 0.25206026434898376\n",
      "| Loss std:   0.021953 |\n",
      "| Loss mean:   0.252060 |\n",
      "g_step: 33200 loss std/mean: 0.02896108478307724 0.2540595829486847\n",
      "| Loss std:   0.028961 |\n",
      "| Loss mean:   0.254060 |\n",
      "g_step: 33300 loss std/mean: 0.026621898636221886 0.25166547298431396\n",
      "| Loss std:   0.026622 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.251665 |\n",
      "g_step: 33400 loss std/mean: 0.02534199133515358 0.2575969994068146\n",
      "| Loss std:   0.025342 |\n",
      "| Loss mean:   0.257597 |\n",
      "g_step: 33500 loss std/mean: 0.02331063151359558 0.2482290416955948\n",
      "| Loss std:   0.023311 |\n",
      "| Loss mean:   0.248229 |\n",
      "g_step: 33600 loss std/mean: 0.020680630579590797 0.25032174587249756\n",
      "| Loss std:   0.020681 |\n",
      "| Loss mean:   0.250322 |\n",
      "g_step: 33700 loss std/mean: 0.028685256838798523 0.2533373236656189\n",
      "| Loss std:   0.028685 |\n",
      "| Loss mean:   0.253337 |\n",
      "g_step: 33800 loss std/mean: 0.02306191809475422 0.2593108117580414\n",
      "| Loss std:   0.023062 |\n",
      "| Loss mean:   0.259311 |\n",
      "g_step: 33900 loss std/mean: 0.024264724925160408 0.2503112554550171\n",
      "| Loss std:   0.024265 |\n",
      "| Loss mean:   0.250311 |\n",
      "g_step: 34000 loss std/mean: 0.02445239946246147 0.25311583280563354\n",
      "| Loss std:   0.024452 |\n",
      "| Loss mean:   0.253116 |\n",
      "g_step: 34100 loss std/mean: 0.027046842500567436 0.25233736634254456\n",
      "| Loss std:   0.027047 |\n",
      "| Loss mean:   0.252337 |\n",
      "g_step: 34200 loss std/mean: 0.025418849661946297 0.25381916761398315\n",
      "| Loss std:   0.025419 |\n",
      "| Loss mean:   0.253819 |\n",
      "g_step: 34300 loss std/mean: 0.0229008961468935 0.2583500146865845\n",
      "| Loss std:   0.022901 |\n",
      "| Loss mean:   0.258350 |\n",
      "g_step: 34400 loss std/mean: 0.023814374580979347 0.25522881746292114\n",
      "| Loss std:   0.023814 |\n",
      "| Loss mean:   0.255229 |\n",
      "g_step: 34500 loss std/mean: 0.023377930745482445 0.2581545412540436\n",
      "| Loss std:   0.023378 |\n",
      "| Loss mean:   0.258155 |\n",
      "g_step: 34600 loss std/mean: 0.023494459688663483 0.24908733367919922\n",
      "| Loss std:   0.023494 |\n",
      "| Loss mean:   0.249087 |\n",
      "g_step: 34700 loss std/mean: 0.02611183375120163 0.25589075684547424\n",
      "| Loss std:   0.026112 |\n",
      "| Loss mean:   0.255891 |\n",
      "g_step: 34800 loss std/mean: 0.024122921749949455 0.2544102668762207\n",
      "| Loss std:   0.024123 |\n",
      "| Loss mean:   0.254410 |\n",
      "g_step: 34900 loss std/mean: 0.02418593131005764 0.25447678565979004\n",
      "| Loss std:   0.024186 |\n",
      "| Loss mean:   0.254477 |\n",
      "g_step: 35000 loss std/mean: 0.027261126786470413 0.2538624703884125\n",
      "| Loss std:   0.027261 |\n",
      "| Loss mean:   0.253862 |\n",
      "\tValidation NWRMSLE  : 0.529906779147\n",
      "| Validation NWRMSLE:   0.529907 |\n",
      "\tValidation NWRMSLE_5: 0.523328755804\n",
      "| Validation NWRMSLE_5:   0.523329 |\n",
      "g_step: 35100 loss std/mean: 0.02588709071278572 0.2557942271232605\n",
      "| Loss std:   0.025887 |\n",
      "| Loss mean:   0.255794 |\n",
      "g_step: 35200 loss std/mean: 0.024829264730215073 0.25770920515060425\n",
      "| Loss std:   0.024829 |\n",
      "| Loss mean:   0.257709 |\n",
      "g_step: 35300 loss std/mean: 0.025639114901423454 0.24951398372650146\n",
      "| Loss std:   0.025639 |\n",
      "| Loss mean:   0.249514 |\n",
      "g_step: 35400 loss std/mean: 0.02692713774740696 0.2542703449726105\n",
      "| Loss std:   0.026927 |\n",
      "| Loss mean:   0.254270 |\n",
      "g_step: 35500 loss std/mean: 0.025090811774134636 0.25486916303634644\n",
      "| Loss std:   0.025091 |\n",
      "| Loss mean:   0.254869 |\n",
      "g_step: 35600 loss std/mean: 0.02362961880862713 0.2518264651298523\n",
      "| Loss std:   0.023630 |\n",
      "| Loss mean:   0.251826 |\n",
      "g_step: 35700 loss std/mean: 0.025477230548858643 0.2539629638195038\n",
      "| Loss std:   0.025477 |\n",
      "| Loss mean:   0.253963 |\n",
      "g_step: 35800 loss std/mean: 0.028094321489334106 0.25553619861602783\n",
      "| Loss std:   0.028094 |\n",
      "| Loss mean:   0.255536 |\n",
      "g_step: 35900 loss std/mean: 0.023761479184031487 0.25555121898651123\n",
      "| Loss std:   0.023761 |\n",
      "| Loss mean:   0.255551 |\n",
      "g_step: 36000 loss std/mean: 0.024078939110040665 0.259135365486145\n",
      "| Loss std:   0.024079 |\n",
      "| Loss mean:   0.259135 |\n",
      "g_step: 36100 loss std/mean: 0.021860891953110695 0.2494816929101944\n",
      "| Loss std:   0.021861 |\n",
      "| Loss mean:   0.249482 |\n",
      "g_step: 36200 loss std/mean: 0.027018187567591667 0.25613129138946533\n",
      "| Loss std:   0.027018 |\n",
      "| Loss mean:   0.256131 |\n",
      "g_step: 36300 loss std/mean: 0.02525652013719082 0.24773059785366058\n",
      "| Loss std:   0.025257 |\n",
      "| Loss mean:   0.247731 |\n",
      "g_step: 36400 loss std/mean: 0.025492340326309204 0.2573796808719635\n",
      "| Loss std:   0.025492 |\n",
      "| Loss mean:   0.257380 |\n",
      "g_step: 36500 loss std/mean: 0.02256028540432453 0.2537766695022583\n",
      "| Loss std:   0.022560 |\n",
      "| Loss mean:   0.253777 |\n",
      "g_step: 36600 loss std/mean: 0.02464793622493744 0.2531370520591736\n",
      "| Loss std:   0.024648 |\n",
      "| Loss mean:   0.253137 |\n",
      "g_step: 36700 loss std/mean: 0.022998834028840065 0.2596692442893982\n",
      "| Loss std:   0.022999 |\n",
      "| Loss mean:   0.259669 |\n",
      "g_step: 36800 loss std/mean: 0.025228695943951607 0.2487850785255432\n",
      "| Loss std:   0.025229 |\n",
      "| Loss mean:   0.248785 |\n",
      "g_step: 36900 loss std/mean: 0.026975790038704872 0.2542051672935486\n",
      "| Loss std:   0.026976 |\n",
      "| Loss mean:   0.254205 |\n",
      "g_step: 37000 loss std/mean: 0.02278856560587883 0.2499891072511673\n",
      "| Loss std:   0.022789 |\n",
      "| Loss mean:   0.249989 |\n",
      "g_step: 37100 loss std/mean: 0.026105426251888275 0.24514572322368622\n",
      "| Loss std:   0.026105 |\n",
      "| Loss mean:   0.245146 |\n",
      "g_step: 37200 loss std/mean: 0.029191570356488228 0.25017061829566956\n",
      "| Loss std:   0.029192 |\n",
      "| Loss mean:   0.250171 |\n",
      "g_step: 37300 loss std/mean: 0.023999301716685295 0.25416451692581177\n",
      "| Loss std:   0.023999 |\n",
      "| Loss mean:   0.254165 |\n",
      "g_step: 37400 loss std/mean: 0.024907026439905167 0.25388821959495544\n",
      "| Loss std:   0.024907 |\n",
      "| Loss mean:   0.253888 |\n",
      "g_step: 37500 loss std/mean: 0.02097165212035179 0.25433817505836487\n",
      "| Loss std:   0.020972 |\n",
      "| Loss mean:   0.254338 |\n",
      "g_step: 37600 loss std/mean: 0.0223277285695076 0.2517275810241699\n",
      "| Loss std:   0.022328 |\n",
      "| Loss mean:   0.251728 |\n",
      "g_step: 37700 loss std/mean: 0.02608049102127552 0.2518090307712555\n",
      "| Loss std:   0.026080 |\n",
      "| Loss mean:   0.251809 |\n",
      "g_step: 37800 loss std/mean: 0.023385299369692802 0.25758346915245056\n",
      "| Loss std:   0.023385 |\n",
      "| Loss mean:   0.257583 |\n",
      "g_step: 37900 loss std/mean: 0.02488924190402031 0.25700756907463074\n",
      "| Loss std:   0.024889 |\n",
      "| Loss mean:   0.257008 |\n",
      "g_step: 38000 loss std/mean: 0.02279391512274742 0.25397780537605286\n",
      "| Loss std:   0.022794 |\n",
      "| Loss mean:   0.253978 |\n",
      "g_step: 38100 loss std/mean: 0.023705236613750458 0.2548535466194153\n",
      "| Loss std:   0.023705 |\n",
      "| Loss mean:   0.254854 |\n",
      "g_step: 38200 loss std/mean: 0.024881668388843536 0.25820866227149963\n",
      "| Loss std:   0.024882 |\n",
      "| Loss mean:   0.258209 |\n",
      "g_step: 38300 loss std/mean: 0.02667919173836708 0.2557402551174164\n",
      "| Loss std:   0.026679 |\n",
      "| Loss mean:   0.255740 |\n",
      "g_step: 38400 loss std/mean: 0.02166629023849964 0.2563990652561188\n",
      "| Loss std:   0.021666 |\n",
      "| Loss mean:   0.256399 |\n",
      "g_step: 38500 loss std/mean: 0.023821400478482246 0.25580739974975586\n",
      "| Loss std:   0.023821 |\n",
      "| Loss mean:   0.255807 |\n",
      "g_step: 38600 loss std/mean: 0.02491339109838009 0.25251221656799316\n",
      "| Loss std:   0.024913 |\n",
      "| Loss mean:   0.252512 |\n",
      "g_step: 38700 loss std/mean: 0.02365226112306118 0.24873895943164825\n",
      "| Loss std:   0.023652 |\n",
      "| Loss mean:   0.248739 |\n",
      "g_step: 38800 loss std/mean: 0.027091477066278458 0.2504485845565796\n",
      "| Loss std:   0.027091 |\n",
      "| Loss mean:   0.250449 |\n",
      "g_step: 38900 loss std/mean: 0.026746274903416634 0.250095933675766\n",
      "| Loss std:   0.026746 |\n",
      "| Loss mean:   0.250096 |\n",
      "g_step: 39000 loss std/mean: 0.023063423112034798 0.25631529092788696\n",
      "| Loss std:   0.023063 |\n",
      "| Loss mean:   0.256315 |\n",
      "g_step: 39100 loss std/mean: 0.02618054673075676 0.25154924392700195\n",
      "| Loss std:   0.026181 |\n",
      "| Loss mean:   0.251549 |\n",
      "g_step: 39200 loss std/mean: 0.02465427666902542 0.2512793242931366\n",
      "| Loss std:   0.024654 |\n",
      "| Loss mean:   0.251279 |\n",
      "g_step: 39300 loss std/mean: 0.024545127525925636 0.24999099969863892\n",
      "| Loss std:   0.024545 |\n",
      "| Loss mean:   0.249991 |\n",
      "g_step: 39400 loss std/mean: 0.019445616751909256 0.2540561854839325\n",
      "| Loss std:   0.019446 |\n",
      "| Loss mean:   0.254056 |\n",
      "g_step: 39500 loss std/mean: 0.02476213499903679 0.25291720032691956\n",
      "| Loss std:   0.024762 |\n",
      "| Loss mean:   0.252917 |\n",
      "g_step: 39600 loss std/mean: 0.02178254723548889 0.2551669776439667\n",
      "| Loss std:   0.021783 |\n",
      "| Loss mean:   0.255167 |\n",
      "g_step: 39700 loss std/mean: 0.024633537977933884 0.2451186329126358\n",
      "| Loss std:   0.024634 |\n",
      "| Loss mean:   0.245119 |\n",
      "g_step: 39800 loss std/mean: 0.02499525621533394 0.2499409168958664\n",
      "| Loss std:   0.024995 |\n",
      "| Loss mean:   0.249941 |\n",
      "g_step: 39900 loss std/mean: 0.02034037932753563 0.25174078345298767\n",
      "| Loss std:   0.020340 |\n",
      "| Loss mean:   0.251741 |\n",
      "g_step: 40000 loss std/mean: 0.023059314116835594 0.2518407106399536\n",
      "| Loss std:   0.023059 |\n",
      "| Loss mean:   0.251841 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NWRMSLE  : 0.530075113956\n",
      "| Validation NWRMSLE:   0.530075 |\n",
      "\tValidation NWRMSLE_5: 0.52380067133\n",
      "| Validation NWRMSLE_5:   0.523801 |\n",
      "g_step: 40100 loss std/mean: 0.026062587276101112 0.25317543745040894\n",
      "| Loss std:   0.026063 |\n",
      "| Loss mean:   0.253175 |\n",
      "g_step: 40200 loss std/mean: 0.02664034813642502 0.24997611343860626\n",
      "| Loss std:   0.026640 |\n",
      "| Loss mean:   0.249976 |\n",
      "g_step: 40300 loss std/mean: 0.022538065910339355 0.2558690011501312\n",
      "| Loss std:   0.022538 |\n",
      "| Loss mean:   0.255869 |\n",
      "g_step: 40400 loss std/mean: 0.023015109822154045 0.25057804584503174\n",
      "| Loss std:   0.023015 |\n",
      "| Loss mean:   0.250578 |\n",
      "g_step: 40500 loss std/mean: 0.022171765565872192 0.25676825642585754\n",
      "| Loss std:   0.022172 |\n",
      "| Loss mean:   0.256768 |\n",
      "g_step: 40600 loss std/mean: 0.024117982015013695 0.25808092951774597\n",
      "| Loss std:   0.024118 |\n",
      "| Loss mean:   0.258081 |\n",
      "g_step: 40700 loss std/mean: 0.0240859966725111 0.25300344824790955\n",
      "| Loss std:   0.024086 |\n",
      "| Loss mean:   0.253003 |\n",
      "g_step: 40800 loss std/mean: 0.023116564378142357 0.25392964482307434\n",
      "| Loss std:   0.023117 |\n",
      "| Loss mean:   0.253930 |\n",
      "g_step: 40900 loss std/mean: 0.028316408395767212 0.253583699464798\n",
      "| Loss std:   0.028316 |\n",
      "| Loss mean:   0.253584 |\n",
      "g_step: 41000 loss std/mean: 0.02556745521724224 0.25216034054756165\n",
      "| Loss std:   0.025567 |\n",
      "| Loss mean:   0.252160 |\n",
      "g_step: 41100 loss std/mean: 0.02395300194621086 0.253616601228714\n",
      "| Loss std:   0.023953 |\n",
      "| Loss mean:   0.253617 |\n",
      "g_step: 41200 loss std/mean: 0.02624613605439663 0.24714654684066772\n",
      "| Loss std:   0.026246 |\n",
      "| Loss mean:   0.247147 |\n",
      "g_step: 41300 loss std/mean: 0.02337837778031826 0.24865318834781647\n",
      "| Loss std:   0.023378 |\n",
      "| Loss mean:   0.248653 |\n",
      "g_step: 41400 loss std/mean: 0.023292362689971924 0.249947190284729\n",
      "| Loss std:   0.023292 |\n",
      "| Loss mean:   0.249947 |\n",
      "g_step: 41500 loss std/mean: 0.02450091950595379 0.2525372803211212\n",
      "| Loss std:   0.024501 |\n",
      "| Loss mean:   0.252537 |\n",
      "g_step: 41600 loss std/mean: 0.02077464759349823 0.25192537903785706\n",
      "| Loss std:   0.020775 |\n",
      "| Loss mean:   0.251925 |\n",
      "g_step: 41700 loss std/mean: 0.02692778967320919 0.2498817890882492\n",
      "| Loss std:   0.026928 |\n",
      "| Loss mean:   0.249882 |\n",
      "g_step: 41800 loss std/mean: 0.025870993733406067 0.25276586413383484\n",
      "| Loss std:   0.025871 |\n",
      "| Loss mean:   0.252766 |\n",
      "g_step: 41900 loss std/mean: 0.026572812348604202 0.2504507899284363\n",
      "| Loss std:   0.026573 |\n",
      "| Loss mean:   0.250451 |\n",
      "g_step: 42000 loss std/mean: 0.02501479908823967 0.2518186867237091\n",
      "| Loss std:   0.025015 |\n",
      "| Loss mean:   0.251819 |\n",
      "g_step: 42100 loss std/mean: 0.025445714592933655 0.25299906730651855\n",
      "| Loss std:   0.025446 |\n",
      "| Loss mean:   0.252999 |\n",
      "g_step: 42200 loss std/mean: 0.022167859598994255 0.2519370913505554\n",
      "| Loss std:   0.022168 |\n",
      "| Loss mean:   0.251937 |\n",
      "g_step: 42300 loss std/mean: 0.025067010894417763 0.2521977126598358\n",
      "| Loss std:   0.025067 |\n",
      "| Loss mean:   0.252198 |\n",
      "g_step: 42400 loss std/mean: 0.02293369174003601 0.25375136733055115\n",
      "| Loss std:   0.022934 |\n",
      "| Loss mean:   0.253751 |\n",
      "g_step: 42500 loss std/mean: 0.02317783050239086 0.2472423017024994\n",
      "| Loss std:   0.023178 |\n",
      "| Loss mean:   0.247242 |\n",
      "g_step: 42600 loss std/mean: 0.027843672782182693 0.25594475865364075\n",
      "| Loss std:   0.027844 |\n",
      "| Loss mean:   0.255945 |\n",
      "g_step: 42700 loss std/mean: 0.028988124802708626 0.24873079359531403\n",
      "| Loss std:   0.028988 |\n",
      "| Loss mean:   0.248731 |\n",
      "g_step: 42800 loss std/mean: 0.02422434464097023 0.2500523328781128\n",
      "| Loss std:   0.024224 |\n",
      "| Loss mean:   0.250052 |\n",
      "g_step: 42900 loss std/mean: 0.025562504306435585 0.24927429854869843\n",
      "| Loss std:   0.025563 |\n",
      "| Loss mean:   0.249274 |\n",
      "g_step: 43000 loss std/mean: 0.024319298565387726 0.2550431191921234\n",
      "| Loss std:   0.024319 |\n",
      "| Loss mean:   0.255043 |\n",
      "g_step: 43100 loss std/mean: 0.023173479363322258 0.24863305687904358\n",
      "| Loss std:   0.023173 |\n",
      "| Loss mean:   0.248633 |\n",
      "g_step: 43200 loss std/mean: 0.025362087413668633 0.25232183933258057\n",
      "| Loss std:   0.025362 |\n",
      "| Loss mean:   0.252322 |\n",
      "g_step: 43300 loss std/mean: 0.024566801264882088 0.2580547332763672\n",
      "| Loss std:   0.024567 |\n",
      "| Loss mean:   0.258055 |\n",
      "g_step: 43400 loss std/mean: 0.022062156349420547 0.255939781665802\n",
      "| Loss std:   0.022062 |\n",
      "| Loss mean:   0.255940 |\n",
      "g_step: 43500 loss std/mean: 0.022967441007494926 0.25571611523628235\n",
      "| Loss std:   0.022967 |\n",
      "| Loss mean:   0.255716 |\n",
      "g_step: 43600 loss std/mean: 0.02439781092107296 0.2518664598464966\n",
      "| Loss std:   0.024398 |\n",
      "| Loss mean:   0.251866 |\n",
      "g_step: 43700 loss std/mean: 0.021048786118626595 0.25335636734962463\n",
      "| Loss std:   0.021049 |\n",
      "| Loss mean:   0.253356 |\n",
      "g_step: 43800 loss std/mean: 0.02390904724597931 0.2537834644317627\n",
      "| Loss std:   0.023909 |\n",
      "| Loss mean:   0.253783 |\n",
      "g_step: 43900 loss std/mean: 0.028808848932385445 0.24594011902809143\n",
      "| Loss std:   0.028809 |\n",
      "| Loss mean:   0.245940 |\n",
      "g_step: 44000 loss std/mean: 0.02240721508860588 0.25799351930618286\n",
      "| Loss std:   0.022407 |\n",
      "| Loss mean:   0.257994 |\n",
      "g_step: 44100 loss std/mean: 0.02357259765267372 0.2521005868911743\n",
      "| Loss std:   0.023573 |\n",
      "| Loss mean:   0.252101 |\n",
      "g_step: 44200 loss std/mean: 0.02399689331650734 0.25040265917778015\n",
      "| Loss std:   0.023997 |\n",
      "| Loss mean:   0.250403 |\n",
      "g_step: 44300 loss std/mean: 0.026021134108304977 0.25836730003356934\n",
      "| Loss std:   0.026021 |\n",
      "| Loss mean:   0.258367 |\n",
      "g_step: 44400 loss std/mean: 0.02467270940542221 0.24761876463890076\n",
      "| Loss std:   0.024673 |\n",
      "| Loss mean:   0.247619 |\n",
      "g_step: 44500 loss std/mean: 0.026210078969597816 0.2561448812484741\n",
      "| Loss std:   0.026210 |\n",
      "| Loss mean:   0.256145 |\n",
      "g_step: 44600 loss std/mean: 0.024258164688944817 0.2518056333065033\n",
      "| Loss std:   0.024258 |\n",
      "| Loss mean:   0.251806 |\n",
      "g_step: 44700 loss std/mean: 0.024735523387789726 0.2518934905529022\n",
      "| Loss std:   0.024736 |\n",
      "| Loss mean:   0.251893 |\n",
      "g_step: 44800 loss std/mean: 0.02518491819500923 0.25039711594581604\n",
      "| Loss std:   0.025185 |\n",
      "| Loss mean:   0.250397 |\n",
      "g_step: 44900 loss std/mean: 0.026334071531891823 0.24642638862133026\n",
      "| Loss std:   0.026334 |\n",
      "| Loss mean:   0.246426 |\n",
      "g_step: 45000 loss std/mean: 0.01955096237361431 0.25697818398475647\n",
      "| Loss std:   0.019551 |\n",
      "| Loss mean:   0.256978 |\n",
      "Unable to send heartbeat message\n",
      "\tValidation NWRMSLE  : 0.529915638561\n",
      "| Validation NWRMSLE:   0.529916 |\n",
      "\tValidation NWRMSLE_5: 0.523610421661\n",
      "| Validation NWRMSLE_5:   0.523610 |\n",
      "g_step: 45100 loss std/mean: 0.021662091836333275 0.25569507479667664\n",
      "| Loss std:   0.021662 |\n",
      "| Loss mean:   0.255695 |\n",
      "g_step: 45200 loss std/mean: 0.023161595687270164 0.25563475489616394\n",
      "| Loss std:   0.023162 |\n",
      "| Loss mean:   0.255635 |\n",
      "g_step: 45300 loss std/mean: 0.023430032655596733 0.24674610793590546\n",
      "| Loss std:   0.023430 |\n",
      "| Loss mean:   0.246746 |\n",
      "g_step: 45400 loss std/mean: 0.021762484684586525 0.2506145238876343\n",
      "| Loss std:   0.021762 |\n",
      "| Loss mean:   0.250615 |\n",
      "g_step: 45500 loss std/mean: 0.02400120534002781 0.2553168535232544\n",
      "| Loss std:   0.024001 |\n",
      "| Loss mean:   0.255317 |\n",
      "g_step: 45600 loss std/mean: 0.022447068244218826 0.2438010573387146\n",
      "| Loss std:   0.022447 |\n",
      "| Loss mean:   0.243801 |\n",
      "g_step: 45700 loss std/mean: 0.02972186915576458 0.2555091679096222\n",
      "| Loss std:   0.029722 |\n",
      "| Loss mean:   0.255509 |\n",
      "g_step: 45800 loss std/mean: 0.023233650252223015 0.2511526942253113\n",
      "| Loss std:   0.023234 |\n",
      "| Loss mean:   0.251153 |\n",
      "g_step: 45900 loss std/mean: 0.026482103392481804 0.25282448530197144\n",
      "| Loss std:   0.026482 |\n",
      "| Loss mean:   0.252824 |\n",
      "g_step: 46000 loss std/mean: 0.02609753981232643 0.25677359104156494\n",
      "| Loss std:   0.026098 |\n",
      "| Loss mean:   0.256774 |\n",
      "g_step: 46100 loss std/mean: 0.026716627180576324 0.2532864809036255\n",
      "| Loss std:   0.026717 |\n",
      "| Loss mean:   0.253286 |\n",
      "g_step: 46200 loss std/mean: 0.025386832654476166 0.2457956075668335\n",
      "| Loss std:   0.025387 |\n",
      "| Loss mean:   0.245796 |\n",
      "g_step: 46300 loss std/mean: 0.020985107868909836 0.25726497173309326\n",
      "| Loss std:   0.020985 |\n",
      "| Loss mean:   0.257265 |\n",
      "g_step: 46400 loss std/mean: 0.021707937121391296 0.25466057658195496\n",
      "| Loss std:   0.021708 |\n",
      "| Loss mean:   0.254661 |\n",
      "g_step: 46500 loss std/mean: 0.02305423468351364 0.25352394580841064\n",
      "| Loss std:   0.023054 |\n",
      "| Loss mean:   0.253524 |\n",
      "g_step: 46600 loss std/mean: 0.021306021139025688 0.25162121653556824\n",
      "| Loss std:   0.021306 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.251621 |\n",
      "g_step: 46700 loss std/mean: 0.021038375794887543 0.25452762842178345\n",
      "| Loss std:   0.021038 |\n",
      "| Loss mean:   0.254528 |\n",
      "g_step: 46800 loss std/mean: 0.023625513538718224 0.2557239830493927\n",
      "| Loss std:   0.023626 |\n",
      "| Loss mean:   0.255724 |\n",
      "g_step: 46900 loss std/mean: 0.020467324182391167 0.25802624225616455\n",
      "| Loss std:   0.020467 |\n",
      "| Loss mean:   0.258026 |\n",
      "g_step: 47000 loss std/mean: 0.025104191154241562 0.25462740659713745\n",
      "| Loss std:   0.025104 |\n",
      "| Loss mean:   0.254627 |\n",
      "g_step: 47100 loss std/mean: 0.02593192458152771 0.2577325105667114\n",
      "| Loss std:   0.025932 |\n",
      "| Loss mean:   0.257733 |\n",
      "g_step: 47200 loss std/mean: 0.024249451234936714 0.2543759047985077\n",
      "| Loss std:   0.024249 |\n",
      "| Loss mean:   0.254376 |\n",
      "g_step: 47300 loss std/mean: 0.02295958250761032 0.2567659616470337\n",
      "| Loss std:   0.022960 |\n",
      "| Loss mean:   0.256766 |\n",
      "g_step: 47400 loss std/mean: 0.021491294726729393 0.25092747807502747\n",
      "| Loss std:   0.021491 |\n",
      "| Loss mean:   0.250927 |\n",
      "g_step: 47500 loss std/mean: 0.02434939332306385 0.2539650797843933\n",
      "| Loss std:   0.024349 |\n",
      "| Loss mean:   0.253965 |\n",
      "g_step: 47600 loss std/mean: 0.025518430396914482 0.2467254251241684\n",
      "| Loss std:   0.025518 |\n",
      "| Loss mean:   0.246725 |\n",
      "g_step: 47700 loss std/mean: 0.02172882854938507 0.2597368359565735\n",
      "| Loss std:   0.021729 |\n",
      "| Loss mean:   0.259737 |\n",
      "g_step: 47800 loss std/mean: 0.0207148976624012 0.25004661083221436\n",
      "| Loss std:   0.020715 |\n",
      "| Loss mean:   0.250047 |\n",
      "g_step: 47900 loss std/mean: 0.024141039699316025 0.2532132863998413\n",
      "| Loss std:   0.024141 |\n",
      "| Loss mean:   0.253213 |\n",
      "g_step: 48000 loss std/mean: 0.023125620558857918 0.25236794352531433\n",
      "| Loss std:   0.023126 |\n",
      "| Loss mean:   0.252368 |\n",
      "g_step: 48100 loss std/mean: 0.025316927582025528 0.25133442878723145\n",
      "| Loss std:   0.025317 |\n",
      "| Loss mean:   0.251334 |\n",
      "g_step: 48200 loss std/mean: 0.0235259048640728 0.2522159814834595\n",
      "| Loss std:   0.023526 |\n",
      "| Loss mean:   0.252216 |\n",
      "g_step: 48300 loss std/mean: 0.025128094479441643 0.2493891566991806\n",
      "| Loss std:   0.025128 |\n",
      "| Loss mean:   0.249389 |\n",
      "g_step: 48400 loss std/mean: 0.027006911113858223 0.25378739833831787\n",
      "| Loss std:   0.027007 |\n",
      "| Loss mean:   0.253787 |\n",
      "g_step: 48500 loss std/mean: 0.022014731541275978 0.258034348487854\n",
      "| Loss std:   0.022015 |\n",
      "| Loss mean:   0.258034 |\n",
      "g_step: 48600 loss std/mean: 0.025667177513241768 0.24806682765483856\n",
      "| Loss std:   0.025667 |\n",
      "| Loss mean:   0.248067 |\n",
      "g_step: 48700 loss std/mean: 0.020749272778630257 0.25210338830947876\n",
      "| Loss std:   0.020749 |\n",
      "| Loss mean:   0.252103 |\n",
      "g_step: 48800 loss std/mean: 0.0218508280813694 0.2528918981552124\n",
      "| Loss std:   0.021851 |\n",
      "| Loss mean:   0.252892 |\n",
      "g_step: 48900 loss std/mean: 0.02410096675157547 0.2470739781856537\n",
      "| Loss std:   0.024101 |\n",
      "| Loss mean:   0.247074 |\n",
      "g_step: 49000 loss std/mean: 0.023993343114852905 0.24946847558021545\n",
      "| Loss std:   0.023993 |\n",
      "| Loss mean:   0.249468 |\n",
      "g_step: 49100 loss std/mean: 0.025232994928956032 0.2500334680080414\n",
      "| Loss std:   0.025233 |\n",
      "| Loss mean:   0.250033 |\n",
      "g_step: 49200 loss std/mean: 0.021237624809145927 0.24823065102100372\n",
      "| Loss std:   0.021238 |\n",
      "| Loss mean:   0.248231 |\n",
      "g_step: 49300 loss std/mean: 0.026199884712696075 0.25189587473869324\n",
      "| Loss std:   0.026200 |\n",
      "| Loss mean:   0.251896 |\n",
      "g_step: 49400 loss std/mean: 0.02750704064965248 0.24199499189853668\n",
      "| Loss std:   0.027507 |\n",
      "| Loss mean:   0.241995 |\n",
      "g_step: 49500 loss std/mean: 0.026504170149564743 0.24671095609664917\n",
      "| Loss std:   0.026504 |\n",
      "| Loss mean:   0.246711 |\n",
      "g_step: 49600 loss std/mean: 0.023921236395835876 0.2500748336315155\n",
      "| Loss std:   0.023921 |\n",
      "| Loss mean:   0.250075 |\n",
      "g_step: 49700 loss std/mean: 0.024405675008893013 0.2589013874530792\n",
      "| Loss std:   0.024406 |\n",
      "| Loss mean:   0.258901 |\n",
      "g_step: 49800 loss std/mean: 0.027295107021927834 0.2497783601284027\n",
      "| Loss std:   0.027295 |\n",
      "| Loss mean:   0.249778 |\n",
      "g_step: 49900 loss std/mean: 0.019675731658935547 0.25094693899154663\n",
      "| Loss std:   0.019676 |\n",
      "| Loss mean:   0.250947 |\n",
      "g_step: 50000 loss std/mean: 0.021054547280073166 0.2536318302154541\n",
      "| Loss std:   0.021055 |\n",
      "| Loss mean:   0.253632 |\n",
      "\tValidation NWRMSLE  : 0.529534089504\n",
      "| Validation NWRMSLE:   0.529534 |\n",
      "\tValidation NWRMSLE_5: 0.522694746607\n",
      "| Validation NWRMSLE_5:   0.522695 |\n",
      "g_step: 50100 loss std/mean: 0.026857152581214905 0.2538377046585083\n",
      "| Loss std:   0.026857 |\n",
      "| Loss mean:   0.253838 |\n",
      "g_step: 50200 loss std/mean: 0.02543863095343113 0.25323572754859924\n",
      "| Loss std:   0.025439 |\n",
      "| Loss mean:   0.253236 |\n",
      "g_step: 50300 loss std/mean: 0.023001376539468765 0.25230836868286133\n",
      "| Loss std:   0.023001 |\n",
      "| Loss mean:   0.252308 |\n",
      "g_step: 50400 loss std/mean: 0.024553628638386726 0.24876077473163605\n",
      "| Loss std:   0.024554 |\n",
      "| Loss mean:   0.248761 |\n",
      "g_step: 50500 loss std/mean: 0.02288532629609108 0.2582116723060608\n",
      "| Loss std:   0.022885 |\n",
      "| Loss mean:   0.258212 |\n",
      "g_step: 50600 loss std/mean: 0.02297285571694374 0.2528339922428131\n",
      "| Loss std:   0.022973 |\n",
      "| Loss mean:   0.252834 |\n",
      "g_step: 50700 loss std/mean: 0.019763009622693062 0.2555178999900818\n",
      "| Loss std:   0.019763 |\n",
      "| Loss mean:   0.255518 |\n",
      "g_step: 50800 loss std/mean: 0.02518395148217678 0.2504228353500366\n",
      "| Loss std:   0.025184 |\n",
      "| Loss mean:   0.250423 |\n",
      "g_step: 50900 loss std/mean: 0.027776846662163734 0.2512546479701996\n",
      "| Loss std:   0.027777 |\n",
      "| Loss mean:   0.251255 |\n",
      "g_step: 51000 loss std/mean: 0.02345959283411503 0.2509068548679352\n",
      "| Loss std:   0.023460 |\n",
      "| Loss mean:   0.250907 |\n",
      "g_step: 51100 loss std/mean: 0.025494569912552834 0.25283583998680115\n",
      "| Loss std:   0.025495 |\n",
      "| Loss mean:   0.252836 |\n",
      "g_step: 51200 loss std/mean: 0.023495743051171303 0.2523970603942871\n",
      "| Loss std:   0.023496 |\n",
      "| Loss mean:   0.252397 |\n",
      "g_step: 51300 loss std/mean: 0.02092537097632885 0.25499817728996277\n",
      "| Loss std:   0.020925 |\n",
      "| Loss mean:   0.254998 |\n",
      "g_step: 51400 loss std/mean: 0.028856497257947922 0.2543976902961731\n",
      "| Loss std:   0.028856 |\n",
      "| Loss mean:   0.254398 |\n",
      "g_step: 51500 loss std/mean: 0.02796778827905655 0.2530560791492462\n",
      "| Loss std:   0.027968 |\n",
      "| Loss mean:   0.253056 |\n",
      "g_step: 51600 loss std/mean: 0.024235086515545845 0.25430554151535034\n",
      "| Loss std:   0.024235 |\n",
      "| Loss mean:   0.254306 |\n",
      "g_step: 51700 loss std/mean: 0.02549014799296856 0.25385355949401855\n",
      "| Loss std:   0.025490 |\n",
      "| Loss mean:   0.253854 |\n",
      "g_step: 51800 loss std/mean: 0.026838645339012146 0.24686697125434875\n",
      "| Loss std:   0.026839 |\n",
      "| Loss mean:   0.246867 |\n",
      "g_step: 51900 loss std/mean: 0.02771691232919693 0.2526375353336334\n",
      "| Loss std:   0.027717 |\n",
      "| Loss mean:   0.252638 |\n",
      "g_step: 52000 loss std/mean: 0.01880730129778385 0.2556994557380676\n",
      "| Loss std:   0.018807 |\n",
      "| Loss mean:   0.255699 |\n",
      "g_step: 52100 loss std/mean: 0.02306104078888893 0.2554827034473419\n",
      "| Loss std:   0.023061 |\n",
      "| Loss mean:   0.255483 |\n",
      "g_step: 52200 loss std/mean: 0.02794940397143364 0.2562604248523712\n",
      "| Loss std:   0.027949 |\n",
      "| Loss mean:   0.256260 |\n",
      "g_step: 52300 loss std/mean: 0.023417511954903603 0.25115543603897095\n",
      "| Loss std:   0.023418 |\n",
      "| Loss mean:   0.251155 |\n",
      "g_step: 52400 loss std/mean: 0.0285944901406765 0.25170063972473145\n",
      "| Loss std:   0.028594 |\n",
      "| Loss mean:   0.251701 |\n",
      "g_step: 52500 loss std/mean: 0.02503364160656929 0.25224021077156067\n",
      "| Loss std:   0.025034 |\n",
      "| Loss mean:   0.252240 |\n",
      "g_step: 52600 loss std/mean: 0.02265970967710018 0.2554720640182495\n",
      "| Loss std:   0.022660 |\n",
      "| Loss mean:   0.255472 |\n",
      "g_step: 52700 loss std/mean: 0.02587309665977955 0.24894917011260986\n",
      "| Loss std:   0.025873 |\n",
      "| Loss mean:   0.248949 |\n",
      "g_step: 52800 loss std/mean: 0.01981491409242153 0.25353431701660156\n",
      "| Loss std:   0.019815 |\n",
      "| Loss mean:   0.253534 |\n",
      "g_step: 52900 loss std/mean: 0.022431755438447 0.24216537177562714\n",
      "| Loss std:   0.022432 |\n",
      "| Loss mean:   0.242165 |\n",
      "g_step: 53000 loss std/mean: 0.02878330647945404 0.2482554316520691\n",
      "| Loss std:   0.028783 |\n",
      "| Loss mean:   0.248255 |\n",
      "g_step: 53100 loss std/mean: 0.021700283512473106 0.25143012404441833\n",
      "| Loss std:   0.021700 |\n",
      "| Loss mean:   0.251430 |\n",
      "g_step: 53200 loss std/mean: 0.028184078633785248 0.25207483768463135\n",
      "| Loss std:   0.028184 |\n",
      "| Loss mean:   0.252075 |\n",
      "g_step: 53300 loss std/mean: 0.02344628795981407 0.24805043637752533\n",
      "| Loss std:   0.023446 |\n",
      "| Loss mean:   0.248050 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 53400 loss std/mean: 0.0262470543384552 0.25015994906425476\n",
      "| Loss std:   0.026247 |\n",
      "| Loss mean:   0.250160 |\n",
      "g_step: 53500 loss std/mean: 0.020961543545126915 0.25078240036964417\n",
      "| Loss std:   0.020962 |\n",
      "| Loss mean:   0.250782 |\n",
      "g_step: 53600 loss std/mean: 0.027335215359926224 0.25263237953186035\n",
      "| Loss std:   0.027335 |\n",
      "| Loss mean:   0.252632 |\n",
      "g_step: 53700 loss std/mean: 0.0227176696062088 0.25193557143211365\n",
      "| Loss std:   0.022718 |\n",
      "| Loss mean:   0.251936 |\n",
      "g_step: 53800 loss std/mean: 0.022593991830945015 0.24963515996932983\n",
      "| Loss std:   0.022594 |\n",
      "| Loss mean:   0.249635 |\n",
      "g_step: 53900 loss std/mean: 0.027164718136191368 0.257296621799469\n",
      "| Loss std:   0.027165 |\n",
      "| Loss mean:   0.257297 |\n",
      "g_step: 54000 loss std/mean: 0.021746546030044556 0.2524465322494507\n",
      "| Loss std:   0.021747 |\n",
      "| Loss mean:   0.252447 |\n",
      "g_step: 54100 loss std/mean: 0.02616732381284237 0.24856549501419067\n",
      "| Loss std:   0.026167 |\n",
      "| Loss mean:   0.248565 |\n",
      "g_step: 54200 loss std/mean: 0.02151384763419628 0.2537640929222107\n",
      "| Loss std:   0.021514 |\n",
      "| Loss mean:   0.253764 |\n",
      "g_step: 54300 loss std/mean: 0.022665953263640404 0.2489074170589447\n",
      "| Loss std:   0.022666 |\n",
      "| Loss mean:   0.248907 |\n",
      "g_step: 54400 loss std/mean: 0.02407211624085903 0.25103995203971863\n",
      "| Loss std:   0.024072 |\n",
      "| Loss mean:   0.251040 |\n",
      "g_step: 54500 loss std/mean: 0.024768833070993423 0.24902494251728058\n",
      "| Loss std:   0.024769 |\n",
      "| Loss mean:   0.249025 |\n",
      "g_step: 54600 loss std/mean: 0.027284860610961914 0.24706745147705078\n",
      "| Loss std:   0.027285 |\n",
      "| Loss mean:   0.247067 |\n",
      "g_step: 54700 loss std/mean: 0.021955424919724464 0.2530202865600586\n",
      "| Loss std:   0.021955 |\n",
      "| Loss mean:   0.253020 |\n",
      "g_step: 54800 loss std/mean: 0.024344705045223236 0.2508409321308136\n",
      "| Loss std:   0.024345 |\n",
      "| Loss mean:   0.250841 |\n",
      "g_step: 54900 loss std/mean: 0.026786139234900475 0.25254198908805847\n",
      "| Loss std:   0.026786 |\n",
      "| Loss mean:   0.252542 |\n",
      "g_step: 55000 loss std/mean: 0.024379253387451172 0.24757669866085052\n",
      "| Loss std:   0.024379 |\n",
      "| Loss mean:   0.247577 |\n",
      "\tValidation NWRMSLE  : 0.529597368286\n",
      "| Validation NWRMSLE:   0.529597 |\n",
      "\tValidation NWRMSLE_5: 0.523773893541\n",
      "| Validation NWRMSLE_5:   0.523774 |\n",
      "g_step: 55100 loss std/mean: 0.02357671596109867 0.251720666885376\n",
      "| Loss std:   0.023577 |\n",
      "| Loss mean:   0.251721 |\n",
      "g_step: 55200 loss std/mean: 0.028813811019062996 0.2568715810775757\n",
      "| Loss std:   0.028814 |\n",
      "| Loss mean:   0.256872 |\n",
      "g_step: 55300 loss std/mean: 0.023544443771243095 0.25046658515930176\n",
      "| Loss std:   0.023544 |\n",
      "| Loss mean:   0.250467 |\n",
      "g_step: 55400 loss std/mean: 0.024270161986351013 0.2585206925868988\n",
      "| Loss std:   0.024270 |\n",
      "| Loss mean:   0.258521 |\n",
      "g_step: 55500 loss std/mean: 0.02724863402545452 0.2540198266506195\n",
      "| Loss std:   0.027249 |\n",
      "| Loss mean:   0.254020 |\n",
      "g_step: 55600 loss std/mean: 0.02198181487619877 0.24839673936367035\n",
      "| Loss std:   0.021982 |\n",
      "| Loss mean:   0.248397 |\n",
      "g_step: 55700 loss std/mean: 0.028337402269244194 0.246276393532753\n",
      "| Loss std:   0.028337 |\n",
      "| Loss mean:   0.246276 |\n",
      "g_step: 55800 loss std/mean: 0.028590507805347443 0.2530573904514313\n",
      "| Loss std:   0.028591 |\n",
      "| Loss mean:   0.253057 |\n",
      "g_step: 55900 loss std/mean: 0.02698928862810135 0.24622921645641327\n",
      "| Loss std:   0.026989 |\n",
      "| Loss mean:   0.246229 |\n",
      "g_step: 56000 loss std/mean: 0.02363928221166134 0.24972349405288696\n",
      "| Loss std:   0.023639 |\n",
      "| Loss mean:   0.249723 |\n",
      "g_step: 56100 loss std/mean: 0.02557389624416828 0.25350919365882874\n",
      "| Loss std:   0.025574 |\n",
      "| Loss mean:   0.253509 |\n",
      "g_step: 56200 loss std/mean: 0.026215998455882072 0.25400131940841675\n",
      "| Loss std:   0.026216 |\n",
      "| Loss mean:   0.254001 |\n",
      "g_step: 56300 loss std/mean: 0.02137446403503418 0.25404882431030273\n",
      "| Loss std:   0.021374 |\n",
      "| Loss mean:   0.254049 |\n",
      "g_step: 56400 loss std/mean: 0.024398822337388992 0.24967041611671448\n",
      "| Loss std:   0.024399 |\n",
      "| Loss mean:   0.249670 |\n",
      "g_step: 56500 loss std/mean: 0.025013457983732224 0.25209397077560425\n",
      "| Loss std:   0.025013 |\n",
      "| Loss mean:   0.252094 |\n",
      "g_step: 56600 loss std/mean: 0.020680338144302368 0.2565411329269409\n",
      "| Loss std:   0.020680 |\n",
      "| Loss mean:   0.256541 |\n",
      "g_step: 56700 loss std/mean: 0.02410421334207058 0.2543066143989563\n",
      "| Loss std:   0.024104 |\n",
      "| Loss mean:   0.254307 |\n",
      "g_step: 56800 loss std/mean: 0.02390197291970253 0.243398517370224\n",
      "| Loss std:   0.023902 |\n",
      "| Loss mean:   0.243399 |\n",
      "g_step: 56900 loss std/mean: 0.019803432747721672 0.2515506148338318\n",
      "| Loss std:   0.019803 |\n",
      "| Loss mean:   0.251551 |\n",
      "g_step: 57000 loss std/mean: 0.022505760192871094 0.25439733266830444\n",
      "| Loss std:   0.022506 |\n",
      "| Loss mean:   0.254397 |\n",
      "g_step: 57100 loss std/mean: 0.024877425283193588 0.25093939900398254\n",
      "| Loss std:   0.024877 |\n",
      "| Loss mean:   0.250939 |\n",
      "g_step: 57200 loss std/mean: 0.027023155242204666 0.25081801414489746\n",
      "| Loss std:   0.027023 |\n",
      "| Loss mean:   0.250818 |\n",
      "g_step: 57300 loss std/mean: 0.028053494170308113 0.24924468994140625\n",
      "| Loss std:   0.028053 |\n",
      "| Loss mean:   0.249245 |\n",
      "g_step: 57400 loss std/mean: 0.02457265742123127 0.2490547001361847\n",
      "| Loss std:   0.024573 |\n",
      "| Loss mean:   0.249055 |\n",
      "g_step: 57500 loss std/mean: 0.023541398346424103 0.2527273893356323\n",
      "| Loss std:   0.023541 |\n",
      "| Loss mean:   0.252727 |\n",
      "g_step: 57600 loss std/mean: 0.02646084874868393 0.24766398966312408\n",
      "| Loss std:   0.026461 |\n",
      "| Loss mean:   0.247664 |\n",
      "g_step: 57700 loss std/mean: 0.022483831271529198 0.25056353211402893\n",
      "| Loss std:   0.022484 |\n",
      "| Loss mean:   0.250564 |\n",
      "g_step: 57800 loss std/mean: 0.02413218468427658 0.247115820646286\n",
      "| Loss std:   0.024132 |\n",
      "| Loss mean:   0.247116 |\n",
      "g_step: 57900 loss std/mean: 0.02320353500545025 0.25120246410369873\n",
      "| Loss std:   0.023204 |\n",
      "| Loss mean:   0.251202 |\n",
      "g_step: 58000 loss std/mean: 0.02330929785966873 0.25340762734413147\n",
      "| Loss std:   0.023309 |\n",
      "| Loss mean:   0.253408 |\n",
      "g_step: 58100 loss std/mean: 0.021869882941246033 0.2568318247795105\n",
      "| Loss std:   0.021870 |\n",
      "| Loss mean:   0.256832 |\n",
      "g_step: 58200 loss std/mean: 0.02777201682329178 0.2492741048336029\n",
      "| Loss std:   0.027772 |\n",
      "| Loss mean:   0.249274 |\n",
      "g_step: 58300 loss std/mean: 0.02612672746181488 0.25438326597213745\n",
      "| Loss std:   0.026127 |\n",
      "| Loss mean:   0.254383 |\n",
      "g_step: 58400 loss std/mean: 0.02199198678135872 0.24659523367881775\n",
      "| Loss std:   0.021992 |\n",
      "| Loss mean:   0.246595 |\n",
      "g_step: 58500 loss std/mean: 0.020519373938441277 0.24531535804271698\n",
      "| Loss std:   0.020519 |\n",
      "| Loss mean:   0.245315 |\n",
      "g_step: 58600 loss std/mean: 0.03165265545248985 0.25102558732032776\n",
      "| Loss std:   0.031653 |\n",
      "| Loss mean:   0.251026 |\n",
      "g_step: 58700 loss std/mean: 0.02527696266770363 0.25139492750167847\n",
      "| Loss std:   0.025277 |\n",
      "| Loss mean:   0.251395 |\n",
      "g_step: 58800 loss std/mean: 0.02537112683057785 0.25407999753952026\n",
      "| Loss std:   0.025371 |\n",
      "| Loss mean:   0.254080 |\n",
      "g_step: 58900 loss std/mean: 0.021166330203413963 0.25568830966949463\n",
      "| Loss std:   0.021166 |\n",
      "| Loss mean:   0.255688 |\n",
      "g_step: 59000 loss std/mean: 0.02352137304842472 0.2557098865509033\n",
      "| Loss std:   0.023521 |\n",
      "| Loss mean:   0.255710 |\n",
      "g_step: 59100 loss std/mean: 0.023882949724793434 0.2561160922050476\n",
      "| Loss std:   0.023883 |\n",
      "| Loss mean:   0.256116 |\n",
      "g_step: 59200 loss std/mean: 0.023233702406287193 0.2572042942047119\n",
      "| Loss std:   0.023234 |\n",
      "| Loss mean:   0.257204 |\n",
      "g_step: 59300 loss std/mean: 0.024528756737709045 0.2496640533208847\n",
      "| Loss std:   0.024529 |\n",
      "| Loss mean:   0.249664 |\n",
      "g_step: 59400 loss std/mean: 0.025622570887207985 0.24759113788604736\n",
      "| Loss std:   0.025623 |\n",
      "| Loss mean:   0.247591 |\n",
      "g_step: 59500 loss std/mean: 0.025353994220495224 0.25089967250823975\n",
      "| Loss std:   0.025354 |\n",
      "| Loss mean:   0.250900 |\n",
      "g_step: 59600 loss std/mean: 0.022716950625181198 0.2545890510082245\n",
      "| Loss std:   0.022717 |\n",
      "| Loss mean:   0.254589 |\n",
      "g_step: 59700 loss std/mean: 0.020786169916391373 0.2499275952577591\n",
      "| Loss std:   0.020786 |\n",
      "| Loss mean:   0.249928 |\n",
      "g_step: 59800 loss std/mean: 0.027789874002337456 0.2500527501106262\n",
      "| Loss std:   0.027790 |\n",
      "| Loss mean:   0.250053 |\n",
      "g_step: 59900 loss std/mean: 0.02330818772315979 0.25282254815101624\n",
      "| Loss std:   0.023308 |\n",
      "| Loss mean:   0.252823 |\n",
      "g_step: 60000 loss std/mean: 0.02504471130669117 0.25703853368759155\n",
      "| Loss std:   0.025045 |\n",
      "| Loss mean:   0.257039 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NWRMSLE  : 0.530039105911\n",
      "| Validation NWRMSLE:   0.530039 |\n",
      "\tValidation NWRMSLE_5: 0.524543318551\n",
      "| Validation NWRMSLE_5:   0.524543 |\n",
      "g_step: 60100 loss std/mean: 0.026219502091407776 0.25146016478538513\n",
      "| Loss std:   0.026220 |\n",
      "| Loss mean:   0.251460 |\n",
      "g_step: 60200 loss std/mean: 0.020909879356622696 0.2562668025493622\n",
      "| Loss std:   0.020910 |\n",
      "| Loss mean:   0.256267 |\n",
      "g_step: 60300 loss std/mean: 0.025175604969263077 0.2577967643737793\n",
      "| Loss std:   0.025176 |\n",
      "| Loss mean:   0.257797 |\n",
      "g_step: 60400 loss std/mean: 0.02296043373644352 0.2503468096256256\n",
      "| Loss std:   0.022960 |\n",
      "| Loss mean:   0.250347 |\n",
      "g_step: 60500 loss std/mean: 0.02046113647520542 0.2485845983028412\n",
      "| Loss std:   0.020461 |\n",
      "| Loss mean:   0.248585 |\n",
      "g_step: 60600 loss std/mean: 0.02881862223148346 0.2492980808019638\n",
      "| Loss std:   0.028819 |\n",
      "| Loss mean:   0.249298 |\n",
      "g_step: 60700 loss std/mean: 0.021314486861228943 0.2556174695491791\n",
      "| Loss std:   0.021314 |\n",
      "| Loss mean:   0.255617 |\n",
      "g_step: 60800 loss std/mean: 0.021460294723510742 0.2541970908641815\n",
      "| Loss std:   0.021460 |\n",
      "| Loss mean:   0.254197 |\n",
      "g_step: 60900 loss std/mean: 0.022907838225364685 0.24860729277133942\n",
      "| Loss std:   0.022908 |\n",
      "| Loss mean:   0.248607 |\n",
      "g_step: 61000 loss std/mean: 0.02358436770737171 0.25484997034072876\n",
      "| Loss std:   0.023584 |\n",
      "| Loss mean:   0.254850 |\n",
      "g_step: 61100 loss std/mean: 0.025149662047624588 0.25166094303131104\n",
      "| Loss std:   0.025150 |\n",
      "| Loss mean:   0.251661 |\n",
      "g_step: 61200 loss std/mean: 0.02701818011701107 0.2488652616739273\n",
      "| Loss std:   0.027018 |\n",
      "| Loss mean:   0.248865 |\n",
      "g_step: 61300 loss std/mean: 0.021415160968899727 0.2568950355052948\n",
      "| Loss std:   0.021415 |\n",
      "| Loss mean:   0.256895 |\n",
      "g_step: 61400 loss std/mean: 0.0249733068048954 0.2545957863330841\n",
      "| Loss std:   0.024973 |\n",
      "| Loss mean:   0.254596 |\n",
      "g_step: 61500 loss std/mean: 0.027052363380789757 0.2517889440059662\n",
      "| Loss std:   0.027052 |\n",
      "| Loss mean:   0.251789 |\n",
      "g_step: 61600 loss std/mean: 0.022999510169029236 0.25810879468917847\n",
      "| Loss std:   0.023000 |\n",
      "| Loss mean:   0.258109 |\n",
      "g_step: 61700 loss std/mean: 0.023612385615706444 0.2523897588253021\n",
      "| Loss std:   0.023612 |\n",
      "| Loss mean:   0.252390 |\n",
      "g_step: 61800 loss std/mean: 0.02620173990726471 0.2481032758951187\n",
      "| Loss std:   0.026202 |\n",
      "| Loss mean:   0.248103 |\n",
      "g_step: 61900 loss std/mean: 0.022758765146136284 0.24918411672115326\n",
      "| Loss std:   0.022759 |\n",
      "| Loss mean:   0.249184 |\n",
      "g_step: 62000 loss std/mean: 0.028109850361943245 0.2542648911476135\n",
      "| Loss std:   0.028110 |\n",
      "| Loss mean:   0.254265 |\n",
      "g_step: 62100 loss std/mean: 0.02519223652780056 0.2491370141506195\n",
      "| Loss std:   0.025192 |\n",
      "| Loss mean:   0.249137 |\n",
      "g_step: 62200 loss std/mean: 0.024240216240286827 0.24928386509418488\n",
      "| Loss std:   0.024240 |\n",
      "| Loss mean:   0.249284 |\n",
      "g_step: 62300 loss std/mean: 0.02641098015010357 0.24944084882736206\n",
      "| Loss std:   0.026411 |\n",
      "| Loss mean:   0.249441 |\n",
      "g_step: 62400 loss std/mean: 0.02583910897374153 0.25032567977905273\n",
      "| Loss std:   0.025839 |\n",
      "| Loss mean:   0.250326 |\n",
      "g_step: 62500 loss std/mean: 0.021222693845629692 0.2508350610733032\n",
      "| Loss std:   0.021223 |\n",
      "| Loss mean:   0.250835 |\n",
      "g_step: 62600 loss std/mean: 0.026686271652579308 0.2505255937576294\n",
      "| Loss std:   0.026686 |\n",
      "| Loss mean:   0.250526 |\n",
      "g_step: 62700 loss std/mean: 0.023454660549759865 0.2534305155277252\n",
      "| Loss std:   0.023455 |\n",
      "| Loss mean:   0.253431 |\n",
      "g_step: 62800 loss std/mean: 0.027386873960494995 0.2531920373439789\n",
      "| Loss std:   0.027387 |\n",
      "| Loss mean:   0.253192 |\n",
      "g_step: 62900 loss std/mean: 0.024205103516578674 0.25551125407218933\n",
      "| Loss std:   0.024205 |\n",
      "| Loss mean:   0.255511 |\n",
      "g_step: 63000 loss std/mean: 0.023606300354003906 0.25247496366500854\n",
      "| Loss std:   0.023606 |\n",
      "| Loss mean:   0.252475 |\n",
      "g_step: 63100 loss std/mean: 0.022993208840489388 0.24917839467525482\n",
      "| Loss std:   0.022993 |\n",
      "| Loss mean:   0.249178 |\n",
      "g_step: 63200 loss std/mean: 0.02318931184709072 0.25367969274520874\n",
      "| Loss std:   0.023189 |\n",
      "| Loss mean:   0.253680 |\n",
      "g_step: 63300 loss std/mean: 0.02594982273876667 0.24802614748477936\n",
      "| Loss std:   0.025950 |\n",
      "| Loss mean:   0.248026 |\n",
      "g_step: 63400 loss std/mean: 0.02523626945912838 0.25552189350128174\n",
      "| Loss std:   0.025236 |\n",
      "| Loss mean:   0.255522 |\n",
      "g_step: 63500 loss std/mean: 0.0236771609634161 0.25280067324638367\n",
      "| Loss std:   0.023677 |\n",
      "| Loss mean:   0.252801 |\n",
      "g_step: 63600 loss std/mean: 0.025148114189505577 0.2495093196630478\n",
      "| Loss std:   0.025148 |\n",
      "| Loss mean:   0.249509 |\n",
      "g_step: 63700 loss std/mean: 0.02148601785302162 0.2489115595817566\n",
      "| Loss std:   0.021486 |\n",
      "| Loss mean:   0.248912 |\n",
      "g_step: 63800 loss std/mean: 0.02593139186501503 0.25212571024894714\n",
      "| Loss std:   0.025931 |\n",
      "| Loss mean:   0.252126 |\n",
      "g_step: 63900 loss std/mean: 0.025727350264787674 0.2517765760421753\n",
      "| Loss std:   0.025727 |\n",
      "| Loss mean:   0.251777 |\n",
      "g_step: 64000 loss std/mean: 0.026175422593951225 0.2526296079158783\n",
      "| Loss std:   0.026175 |\n",
      "| Loss mean:   0.252630 |\n",
      "g_step: 64100 loss std/mean: 0.020918171852827072 0.25608187913894653\n",
      "| Loss std:   0.020918 |\n",
      "| Loss mean:   0.256082 |\n",
      "g_step: 64200 loss std/mean: 0.023126255720853806 0.2520659267902374\n",
      "| Loss std:   0.023126 |\n",
      "| Loss mean:   0.252066 |\n",
      "g_step: 64300 loss std/mean: 0.02472756616771221 0.25004056096076965\n",
      "| Loss std:   0.024728 |\n",
      "| Loss mean:   0.250041 |\n",
      "g_step: 64400 loss std/mean: 0.02588082104921341 0.2504519522190094\n",
      "| Loss std:   0.025881 |\n",
      "| Loss mean:   0.250452 |\n",
      "g_step: 64500 loss std/mean: 0.023385154083371162 0.2534252405166626\n",
      "| Loss std:   0.023385 |\n",
      "| Loss mean:   0.253425 |\n",
      "g_step: 64600 loss std/mean: 0.02044876106083393 0.2529158890247345\n",
      "| Loss std:   0.020449 |\n",
      "| Loss mean:   0.252916 |\n",
      "g_step: 64700 loss std/mean: 0.022350633516907692 0.2501276135444641\n",
      "| Loss std:   0.022351 |\n",
      "| Loss mean:   0.250128 |\n",
      "g_step: 64800 loss std/mean: 0.02557029016315937 0.2529595196247101\n",
      "| Loss std:   0.025570 |\n",
      "| Loss mean:   0.252960 |\n",
      "g_step: 64900 loss std/mean: 0.02650001458823681 0.25084546208381653\n",
      "| Loss std:   0.026500 |\n",
      "| Loss mean:   0.250845 |\n",
      "g_step: 65000 loss std/mean: 0.026891430839896202 0.24905872344970703\n",
      "| Loss std:   0.026891 |\n",
      "| Loss mean:   0.249059 |\n",
      "\tValidation NWRMSLE  : 0.52947611146\n",
      "| Validation NWRMSLE:   0.529476 |\n",
      "\tValidation NWRMSLE_5: 0.523496509129\n",
      "| Validation NWRMSLE_5:   0.523497 |\n",
      "g_step: 65100 loss std/mean: 0.021070150658488274 0.2553807199001312\n",
      "| Loss std:   0.021070 |\n",
      "| Loss mean:   0.255381 |\n",
      "g_step: 65200 loss std/mean: 0.02137470245361328 0.24831262230873108\n",
      "| Loss std:   0.021375 |\n",
      "| Loss mean:   0.248313 |\n",
      "g_step: 65300 loss std/mean: 0.024377254769206047 0.24880892038345337\n",
      "| Loss std:   0.024377 |\n",
      "| Loss mean:   0.248809 |\n",
      "g_step: 65400 loss std/mean: 0.02592712640762329 0.2547471821308136\n",
      "| Loss std:   0.025927 |\n",
      "| Loss mean:   0.254747 |\n",
      "g_step: 65500 loss std/mean: 0.025853091850876808 0.2518135607242584\n",
      "| Loss std:   0.025853 |\n",
      "| Loss mean:   0.251814 |\n",
      "g_step: 65600 loss std/mean: 0.026338350027799606 0.25216683745384216\n",
      "| Loss std:   0.026338 |\n",
      "| Loss mean:   0.252167 |\n",
      "g_step: 65700 loss std/mean: 0.023219790309667587 0.25266003608703613\n",
      "| Loss std:   0.023220 |\n",
      "| Loss mean:   0.252660 |\n",
      "g_step: 65800 loss std/mean: 0.025099975988268852 0.25010058283805847\n",
      "| Loss std:   0.025100 |\n",
      "| Loss mean:   0.250101 |\n",
      "g_step: 65900 loss std/mean: 0.02443750575184822 0.2477601170539856\n",
      "| Loss std:   0.024438 |\n",
      "| Loss mean:   0.247760 |\n",
      "g_step: 66000 loss std/mean: 0.025265663862228394 0.24837394058704376\n",
      "| Loss std:   0.025266 |\n",
      "| Loss mean:   0.248374 |\n",
      "g_step: 66100 loss std/mean: 0.02120502106845379 0.25235268473625183\n",
      "| Loss std:   0.021205 |\n",
      "| Loss mean:   0.252353 |\n",
      "g_step: 66200 loss std/mean: 0.017816584557294846 0.25522974133491516\n",
      "| Loss std:   0.017817 |\n",
      "| Loss mean:   0.255230 |\n",
      "g_step: 66300 loss std/mean: 0.025474920868873596 0.25477147102355957\n",
      "| Loss std:   0.025475 |\n",
      "| Loss mean:   0.254771 |\n",
      "g_step: 66400 loss std/mean: 0.021100718528032303 0.253101646900177\n",
      "| Loss std:   0.021101 |\n",
      "| Loss mean:   0.253102 |\n",
      "g_step: 66500 loss std/mean: 0.02364487014710903 0.24950598180294037\n",
      "| Loss std:   0.023645 |\n",
      "| Loss mean:   0.249506 |\n",
      "g_step: 66600 loss std/mean: 0.027785710990428925 0.2506137192249298\n",
      "| Loss std:   0.027786 |\n",
      "| Loss mean:   0.250614 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 66700 loss std/mean: 0.02154172584414482 0.2500375211238861\n",
      "| Loss std:   0.021542 |\n",
      "| Loss mean:   0.250038 |\n",
      "g_step: 66800 loss std/mean: 0.02042596973478794 0.24964767694473267\n",
      "| Loss std:   0.020426 |\n",
      "| Loss mean:   0.249648 |\n",
      "g_step: 66900 loss std/mean: 0.025827603414654732 0.2461906373500824\n",
      "| Loss std:   0.025828 |\n",
      "| Loss mean:   0.246191 |\n",
      "g_step: 67000 loss std/mean: 0.024887938052415848 0.24513158202171326\n",
      "| Loss std:   0.024888 |\n",
      "| Loss mean:   0.245132 |\n",
      "g_step: 67100 loss std/mean: 0.022903846576809883 0.2497907429933548\n",
      "| Loss std:   0.022904 |\n",
      "| Loss mean:   0.249791 |\n",
      "g_step: 67200 loss std/mean: 0.022419452667236328 0.2540939450263977\n",
      "| Loss std:   0.022419 |\n",
      "| Loss mean:   0.254094 |\n",
      "g_step: 67300 loss std/mean: 0.026234524324536324 0.24561342597007751\n",
      "| Loss std:   0.026235 |\n",
      "| Loss mean:   0.245613 |\n",
      "g_step: 67400 loss std/mean: 0.022882843390107155 0.2533265948295593\n",
      "| Loss std:   0.022883 |\n",
      "| Loss mean:   0.253327 |\n",
      "g_step: 67500 loss std/mean: 0.02503925934433937 0.25388303399086\n",
      "| Loss std:   0.025039 |\n",
      "| Loss mean:   0.253883 |\n",
      "g_step: 67600 loss std/mean: 0.028840230777859688 0.24591411650180817\n",
      "| Loss std:   0.028840 |\n",
      "| Loss mean:   0.245914 |\n",
      "g_step: 67700 loss std/mean: 0.02164456807076931 0.2602245509624481\n",
      "| Loss std:   0.021645 |\n",
      "| Loss mean:   0.260225 |\n",
      "g_step: 67800 loss std/mean: 0.02511216513812542 0.2532641887664795\n",
      "| Loss std:   0.025112 |\n",
      "| Loss mean:   0.253264 |\n",
      "g_step: 67900 loss std/mean: 0.025650059804320335 0.24904346466064453\n",
      "| Loss std:   0.025650 |\n",
      "| Loss mean:   0.249043 |\n",
      "g_step: 68000 loss std/mean: 0.022427361458539963 0.2507557272911072\n",
      "| Loss std:   0.022427 |\n",
      "| Loss mean:   0.250756 |\n",
      "g_step: 68100 loss std/mean: 0.024355202913284302 0.2470094859600067\n",
      "| Loss std:   0.024355 |\n",
      "| Loss mean:   0.247009 |\n",
      "g_step: 68200 loss std/mean: 0.02622990496456623 0.24829578399658203\n",
      "| Loss std:   0.026230 |\n",
      "| Loss mean:   0.248296 |\n",
      "g_step: 68300 loss std/mean: 0.02238140068948269 0.24786818027496338\n",
      "| Loss std:   0.022381 |\n",
      "| Loss mean:   0.247868 |\n",
      "g_step: 68400 loss std/mean: 0.02473038248717785 0.25346603989601135\n",
      "| Loss std:   0.024730 |\n",
      "| Loss mean:   0.253466 |\n",
      "g_step: 68500 loss std/mean: 0.0259390939027071 0.24616481363773346\n",
      "| Loss std:   0.025939 |\n",
      "| Loss mean:   0.246165 |\n",
      "g_step: 68600 loss std/mean: 0.022689878940582275 0.25576546788215637\n",
      "| Loss std:   0.022690 |\n",
      "| Loss mean:   0.255765 |\n",
      "g_step: 68700 loss std/mean: 0.022420715540647507 0.25570574402809143\n",
      "| Loss std:   0.022421 |\n",
      "| Loss mean:   0.255706 |\n",
      "g_step: 68800 loss std/mean: 0.02382703311741352 0.24524003267288208\n",
      "| Loss std:   0.023827 |\n",
      "| Loss mean:   0.245240 |\n",
      "g_step: 68900 loss std/mean: 0.023173848167061806 0.25488805770874023\n",
      "| Loss std:   0.023174 |\n",
      "| Loss mean:   0.254888 |\n",
      "g_step: 69000 loss std/mean: 0.024026287719607353 0.2512681782245636\n",
      "| Loss std:   0.024026 |\n",
      "| Loss mean:   0.251268 |\n",
      "g_step: 69100 loss std/mean: 0.023961195722222328 0.24469679594039917\n",
      "| Loss std:   0.023961 |\n",
      "| Loss mean:   0.244697 |\n",
      "g_step: 69200 loss std/mean: 0.022789759561419487 0.2524793744087219\n",
      "| Loss std:   0.022790 |\n",
      "| Loss mean:   0.252479 |\n",
      "g_step: 69300 loss std/mean: 0.02352507971227169 0.25181031227111816\n",
      "| Loss std:   0.023525 |\n",
      "| Loss mean:   0.251810 |\n",
      "g_step: 69400 loss std/mean: 0.027536090463399887 0.24454878270626068\n",
      "| Loss std:   0.027536 |\n",
      "| Loss mean:   0.244549 |\n",
      "g_step: 69500 loss std/mean: 0.024413982406258583 0.24889490008354187\n",
      "| Loss std:   0.024414 |\n",
      "| Loss mean:   0.248895 |\n",
      "g_step: 69600 loss std/mean: 0.023960616439580917 0.2510493993759155\n",
      "| Loss std:   0.023961 |\n",
      "| Loss mean:   0.251049 |\n",
      "g_step: 69700 loss std/mean: 0.022855816408991814 0.2526840269565582\n",
      "| Loss std:   0.022856 |\n",
      "| Loss mean:   0.252684 |\n",
      "g_step: 69800 loss std/mean: 0.02518056146800518 0.25295552611351013\n",
      "| Loss std:   0.025181 |\n",
      "| Loss mean:   0.252956 |\n",
      "g_step: 69900 loss std/mean: 0.020306596532464027 0.2528657019138336\n",
      "| Loss std:   0.020307 |\n",
      "| Loss mean:   0.252866 |\n",
      "g_step: 70000 loss std/mean: 0.02360479347407818 0.2464195042848587\n",
      "| Loss std:   0.023605 |\n",
      "| Loss mean:   0.246420 |\n",
      "\tValidation NWRMSLE  : 0.52941613296\n",
      "| Validation NWRMSLE:   0.529416 |\n",
      "\tValidation NWRMSLE_5: 0.523752923481\n",
      "| Validation NWRMSLE_5:   0.523753 |\n",
      "g_step: 70100 loss std/mean: 0.022633086889982224 0.25266143679618835\n",
      "| Loss std:   0.022633 |\n",
      "| Loss mean:   0.252661 |\n",
      "g_step: 70200 loss std/mean: 0.025026455521583557 0.24741879105567932\n",
      "| Loss std:   0.025026 |\n",
      "| Loss mean:   0.247419 |\n",
      "g_step: 70300 loss std/mean: 0.021230021491646767 0.2441329061985016\n",
      "| Loss std:   0.021230 |\n",
      "| Loss mean:   0.244133 |\n",
      "g_step: 70400 loss std/mean: 0.026138581335544586 0.25118640065193176\n",
      "| Loss std:   0.026139 |\n",
      "| Loss mean:   0.251186 |\n",
      "g_step: 70500 loss std/mean: 0.023926550522446632 0.2540513575077057\n",
      "| Loss std:   0.023927 |\n",
      "| Loss mean:   0.254051 |\n",
      "g_step: 70600 loss std/mean: 0.025338485836982727 0.2504333257675171\n",
      "| Loss std:   0.025338 |\n",
      "| Loss mean:   0.250433 |\n",
      "g_step: 70700 loss std/mean: 0.021748220548033714 0.24744544923305511\n",
      "| Loss std:   0.021748 |\n",
      "| Loss mean:   0.247445 |\n",
      "g_step: 70800 loss std/mean: 0.022941945120692253 0.24979709088802338\n",
      "| Loss std:   0.022942 |\n",
      "| Loss mean:   0.249797 |\n",
      "g_step: 70900 loss std/mean: 0.024697529152035713 0.2566777169704437\n",
      "| Loss std:   0.024698 |\n",
      "| Loss mean:   0.256678 |\n",
      "g_step: 71000 loss std/mean: 0.024765020236372948 0.24930612742900848\n",
      "| Loss std:   0.024765 |\n",
      "| Loss mean:   0.249306 |\n",
      "g_step: 71100 loss std/mean: 0.024043895304203033 0.2485414445400238\n",
      "| Loss std:   0.024044 |\n",
      "| Loss mean:   0.248541 |\n",
      "g_step: 71200 loss std/mean: 0.023955749347805977 0.2513575851917267\n",
      "| Loss std:   0.023956 |\n",
      "| Loss mean:   0.251358 |\n",
      "g_step: 71300 loss std/mean: 0.025191379711031914 0.2531505525112152\n",
      "| Loss std:   0.025191 |\n",
      "| Loss mean:   0.253151 |\n",
      "g_step: 71400 loss std/mean: 0.023356327787041664 0.24956688284873962\n",
      "| Loss std:   0.023356 |\n",
      "| Loss mean:   0.249567 |\n",
      "g_step: 71500 loss std/mean: 0.022360434755682945 0.2520885765552521\n",
      "| Loss std:   0.022360 |\n",
      "| Loss mean:   0.252089 |\n",
      "g_step: 71600 loss std/mean: 0.02593052200973034 0.2505626976490021\n",
      "| Loss std:   0.025931 |\n",
      "| Loss mean:   0.250563 |\n",
      "g_step: 71700 loss std/mean: 0.021164366975426674 0.2511937618255615\n",
      "| Loss std:   0.021164 |\n",
      "| Loss mean:   0.251194 |\n",
      "g_step: 71800 loss std/mean: 0.02598240226507187 0.24980537593364716\n",
      "| Loss std:   0.025982 |\n",
      "| Loss mean:   0.249805 |\n",
      "g_step: 71900 loss std/mean: 0.024988781660795212 0.25284305214881897\n",
      "| Loss std:   0.024989 |\n",
      "| Loss mean:   0.252843 |\n",
      "g_step: 72000 loss std/mean: 0.02167646214365959 0.25307631492614746\n",
      "| Loss std:   0.021676 |\n",
      "| Loss mean:   0.253076 |\n",
      "g_step: 72100 loss std/mean: 0.02418324537575245 0.25458821654319763\n",
      "| Loss std:   0.024183 |\n",
      "| Loss mean:   0.254588 |\n",
      "g_step: 72200 loss std/mean: 0.02473611943423748 0.2503472864627838\n",
      "| Loss std:   0.024736 |\n",
      "| Loss mean:   0.250347 |\n",
      "g_step: 72300 loss std/mean: 0.025461433455348015 0.25190314650535583\n",
      "| Loss std:   0.025461 |\n",
      "| Loss mean:   0.251903 |\n",
      "g_step: 72400 loss std/mean: 0.02262944169342518 0.24793685972690582\n",
      "| Loss std:   0.022629 |\n",
      "| Loss mean:   0.247937 |\n",
      "g_step: 72500 loss std/mean: 0.022924350574612617 0.2547978162765503\n",
      "| Loss std:   0.022924 |\n",
      "| Loss mean:   0.254798 |\n",
      "g_step: 72600 loss std/mean: 0.024821119382977486 0.25052404403686523\n",
      "| Loss std:   0.024821 |\n",
      "| Loss mean:   0.250524 |\n",
      "g_step: 72700 loss std/mean: 0.025701113045215607 0.24555149674415588\n",
      "| Loss std:   0.025701 |\n",
      "| Loss mean:   0.245551 |\n",
      "g_step: 72800 loss std/mean: 0.021089568734169006 0.2575487792491913\n",
      "| Loss std:   0.021090 |\n",
      "| Loss mean:   0.257549 |\n",
      "g_step: 72900 loss std/mean: 0.023752018809318542 0.25200390815734863\n",
      "| Loss std:   0.023752 |\n",
      "| Loss mean:   0.252004 |\n",
      "g_step: 73000 loss std/mean: 0.02435300685465336 0.24973145127296448\n",
      "| Loss std:   0.024353 |\n",
      "| Loss mean:   0.249731 |\n",
      "g_step: 73100 loss std/mean: 0.023582980036735535 0.24651984870433807\n",
      "| Loss std:   0.023583 |\n",
      "| Loss mean:   0.246520 |\n",
      "g_step: 73200 loss std/mean: 0.02402602508664131 0.25125840306282043\n",
      "| Loss std:   0.024026 |\n",
      "| Loss mean:   0.251258 |\n",
      "g_step: 73300 loss std/mean: 0.024118121713399887 0.2502943277359009\n",
      "| Loss std:   0.024118 |\n",
      "| Loss mean:   0.250294 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_step: 73400 loss std/mean: 0.021789170801639557 0.2529124617576599\n",
      "| Loss std:   0.021789 |\n",
      "| Loss mean:   0.252912 |\n",
      "g_step: 73500 loss std/mean: 0.024475954473018646 0.25587233901023865\n",
      "| Loss std:   0.024476 |\n",
      "| Loss mean:   0.255872 |\n",
      "g_step: 73600 loss std/mean: 0.025400906801223755 0.24891433119773865\n",
      "| Loss std:   0.025401 |\n",
      "| Loss mean:   0.248914 |\n",
      "g_step: 73700 loss std/mean: 0.020431270822882652 0.2470746487379074\n",
      "| Loss std:   0.020431 |\n",
      "| Loss mean:   0.247075 |\n",
      "g_step: 73800 loss std/mean: 0.022937290370464325 0.2504267394542694\n",
      "| Loss std:   0.022937 |\n",
      "| Loss mean:   0.250427 |\n",
      "g_step: 73900 loss std/mean: 0.024051383137702942 0.24903792142868042\n",
      "| Loss std:   0.024051 |\n",
      "| Loss mean:   0.249038 |\n",
      "g_step: 74000 loss std/mean: 0.028399091213941574 0.25184765458106995\n",
      "| Loss std:   0.028399 |\n",
      "| Loss mean:   0.251848 |\n",
      "g_step: 74100 loss std/mean: 0.02974245697259903 0.24804405868053436\n",
      "| Loss std:   0.029742 |\n",
      "| Loss mean:   0.248044 |\n",
      "g_step: 74200 loss std/mean: 0.023842472583055496 0.25390902161598206\n",
      "| Loss std:   0.023842 |\n",
      "| Loss mean:   0.253909 |\n",
      "g_step: 74300 loss std/mean: 0.030117051675915718 0.25364360213279724\n",
      "| Loss std:   0.030117 |\n",
      "| Loss mean:   0.253644 |\n",
      "g_step: 74400 loss std/mean: 0.01957792043685913 0.2514859139919281\n",
      "| Loss std:   0.019578 |\n",
      "| Loss mean:   0.251486 |\n",
      "g_step: 74500 loss std/mean: 0.02466832846403122 0.2543003559112549\n",
      "| Loss std:   0.024668 |\n",
      "| Loss mean:   0.254300 |\n",
      "g_step: 74600 loss std/mean: 0.025296349078416824 0.24626415967941284\n",
      "| Loss std:   0.025296 |\n",
      "| Loss mean:   0.246264 |\n",
      "g_step: 74700 loss std/mean: 0.023484230041503906 0.2524763345718384\n",
      "| Loss std:   0.023484 |\n",
      "| Loss mean:   0.252476 |\n",
      "g_step: 74800 loss std/mean: 0.023797446861863136 0.2540196478366852\n",
      "| Loss std:   0.023797 |\n",
      "| Loss mean:   0.254020 |\n",
      "g_step: 74900 loss std/mean: 0.024040402844548225 0.25079163908958435\n",
      "| Loss std:   0.024040 |\n",
      "| Loss mean:   0.250792 |\n",
      "g_step: 75000 loss std/mean: 0.020180849358439445 0.2542293965816498\n",
      "| Loss std:   0.020181 |\n",
      "| Loss mean:   0.254229 |\n",
      "\tValidation NWRMSLE  : 0.529657184052\n",
      "| Validation NWRMSLE:   0.529657 |\n",
      "\tValidation NWRMSLE_5: 0.524151508981\n",
      "| Validation NWRMSLE_5:   0.524152 |\n",
      "g_step: 75100 loss std/mean: 0.023618429899215698 0.24860447645187378\n",
      "| Loss std:   0.023618 |\n",
      "| Loss mean:   0.248604 |\n",
      "g_step: 75200 loss std/mean: 0.02298061177134514 0.2502949833869934\n",
      "| Loss std:   0.022981 |\n",
      "| Loss mean:   0.250295 |\n",
      "g_step: 75300 loss std/mean: 0.023210089653730392 0.2545309066772461\n",
      "| Loss std:   0.023210 |\n",
      "| Loss mean:   0.254531 |\n",
      "g_step: 75400 loss std/mean: 0.023389147594571114 0.25549429655075073\n",
      "| Loss std:   0.023389 |\n",
      "| Loss mean:   0.255494 |\n",
      "g_step: 75500 loss std/mean: 0.027230840176343918 0.2532874345779419\n",
      "| Loss std:   0.027231 |\n",
      "| Loss mean:   0.253287 |\n",
      "g_step: 75600 loss std/mean: 0.021700361743569374 0.24886810779571533\n",
      "| Loss std:   0.021700 |\n",
      "| Loss mean:   0.248868 |\n",
      "g_step: 75700 loss std/mean: 0.023817768320441246 0.25698143243789673\n",
      "| Loss std:   0.023818 |\n",
      "| Loss mean:   0.256981 |\n",
      "g_step: 75800 loss std/mean: 0.022184714674949646 0.25052157044410706\n",
      "| Loss std:   0.022185 |\n",
      "| Loss mean:   0.250522 |\n",
      "g_step: 75900 loss std/mean: 0.02535097301006317 0.24903808534145355\n",
      "| Loss std:   0.025351 |\n",
      "| Loss mean:   0.249038 |\n",
      "g_step: 76000 loss std/mean: 0.023908689618110657 0.25366896390914917\n",
      "| Loss std:   0.023909 |\n",
      "| Loss mean:   0.253669 |\n",
      "g_step: 76100 loss std/mean: 0.02304767444729805 0.255667120218277\n",
      "| Loss std:   0.023048 |\n",
      "| Loss mean:   0.255667 |\n",
      "g_step: 76200 loss std/mean: 0.021591098979115486 0.25428763031959534\n",
      "| Loss std:   0.021591 |\n",
      "| Loss mean:   0.254288 |\n",
      "g_step: 76300 loss std/mean: 0.026516586542129517 0.25028756260871887\n",
      "| Loss std:   0.026517 |\n",
      "| Loss mean:   0.250288 |\n",
      "g_step: 76400 loss std/mean: 0.0257575586438179 0.2550821900367737\n",
      "| Loss std:   0.025758 |\n",
      "| Loss mean:   0.255082 |\n",
      "g_step: 76500 loss std/mean: 0.02645275369286537 0.25567561388015747\n",
      "| Loss std:   0.026453 |\n",
      "| Loss mean:   0.255676 |\n",
      "g_step: 76600 loss std/mean: 0.021531689912080765 0.25443243980407715\n",
      "| Loss std:   0.021532 |\n",
      "| Loss mean:   0.254432 |\n",
      "g_step: 76700 loss std/mean: 0.026513250544667244 0.2435806691646576\n",
      "| Loss std:   0.026513 |\n",
      "| Loss mean:   0.243581 |\n",
      "g_step: 76800 loss std/mean: 0.029013970866799355 0.24688225984573364\n",
      "| Loss std:   0.029014 |\n",
      "| Loss mean:   0.246882 |\n",
      "g_step: 76900 loss std/mean: 0.022181658074259758 0.2540385127067566\n",
      "| Loss std:   0.022182 |\n",
      "| Loss mean:   0.254039 |\n",
      "g_step: 77000 loss std/mean: 0.022972246631979942 0.25204452872276306\n",
      "| Loss std:   0.022972 |\n",
      "| Loss mean:   0.252045 |\n",
      "g_step: 77100 loss std/mean: 0.02701210230588913 0.2515808939933777\n",
      "| Loss std:   0.027012 |\n",
      "| Loss mean:   0.251581 |\n",
      "g_step: 77200 loss std/mean: 0.024681122973561287 0.24600578844547272\n",
      "| Loss std:   0.024681 |\n",
      "| Loss mean:   0.246006 |\n",
      "g_step: 77300 loss std/mean: 0.023335501551628113 0.25060999393463135\n",
      "| Loss std:   0.023336 |\n",
      "| Loss mean:   0.250610 |\n",
      "g_step: 77400 loss std/mean: 0.0199376679956913 0.25056201219558716\n",
      "| Loss std:   0.019938 |\n",
      "| Loss mean:   0.250562 |\n",
      "g_step: 77500 loss std/mean: 0.02500050887465477 0.2496069371700287\n",
      "| Loss std:   0.025001 |\n",
      "| Loss mean:   0.249607 |\n",
      "g_step: 77600 loss std/mean: 0.021680651232600212 0.2536143362522125\n",
      "| Loss std:   0.021681 |\n",
      "| Loss mean:   0.253614 |\n",
      "g_step: 77700 loss std/mean: 0.024753393605351448 0.25467702746391296\n",
      "| Loss std:   0.024753 |\n",
      "| Loss mean:   0.254677 |\n",
      "g_step: 77800 loss std/mean: 0.02430667169392109 0.2513182759284973\n",
      "| Loss std:   0.024307 |\n",
      "| Loss mean:   0.251318 |\n",
      "g_step: 77900 loss std/mean: 0.026733223348855972 0.2479134052991867\n",
      "| Loss std:   0.026733 |\n",
      "| Loss mean:   0.247913 |\n",
      "g_step: 78000 loss std/mean: 0.02332032285630703 0.2546277344226837\n",
      "| Loss std:   0.023320 |\n",
      "| Loss mean:   0.254628 |\n",
      "g_step: 78100 loss std/mean: 0.02286640554666519 0.25697487592697144\n",
      "| Loss std:   0.022866 |\n",
      "| Loss mean:   0.256975 |\n",
      "g_step: 78200 loss std/mean: 0.02638537622988224 0.24668455123901367\n",
      "| Loss std:   0.026385 |\n",
      "| Loss mean:   0.246685 |\n",
      "g_step: 78300 loss std/mean: 0.0254846028983593 0.25149333477020264\n",
      "| Loss std:   0.025485 |\n",
      "| Loss mean:   0.251493 |\n",
      "g_step: 78400 loss std/mean: 0.02562014013528824 0.2523937523365021\n",
      "| Loss std:   0.025620 |\n",
      "| Loss mean:   0.252394 |\n",
      "g_step: 78500 loss std/mean: 0.02571920119225979 0.2525698244571686\n",
      "| Loss std:   0.025719 |\n",
      "| Loss mean:   0.252570 |\n",
      "g_step: 78600 loss std/mean: 0.025777826085686684 0.2522834241390228\n",
      "| Loss std:   0.025778 |\n",
      "| Loss mean:   0.252283 |\n",
      "g_step: 78700 loss std/mean: 0.021960215643048286 0.24905717372894287\n",
      "| Loss std:   0.021960 |\n",
      "| Loss mean:   0.249057 |\n",
      "g_step: 78800 loss std/mean: 0.024627050384879112 0.25321894884109497\n",
      "| Loss std:   0.024627 |\n",
      "| Loss mean:   0.253219 |\n",
      "g_step: 78900 loss std/mean: 0.026602568104863167 0.24556834995746613\n",
      "| Loss std:   0.026603 |\n",
      "| Loss mean:   0.245568 |\n",
      "g_step: 79000 loss std/mean: 0.021614614874124527 0.24564571678638458\n",
      "| Loss std:   0.021615 |\n",
      "| Loss mean:   0.245646 |\n",
      "g_step: 79100 loss std/mean: 0.024829158559441566 0.2513168454170227\n",
      "| Loss std:   0.024829 |\n",
      "| Loss mean:   0.251317 |\n",
      "g_step: 79200 loss std/mean: 0.021603120490908623 0.2507665157318115\n",
      "| Loss std:   0.021603 |\n",
      "| Loss mean:   0.250767 |\n",
      "g_step: 79300 loss std/mean: 0.023845266550779343 0.24633051455020905\n",
      "| Loss std:   0.023845 |\n",
      "| Loss mean:   0.246331 |\n",
      "g_step: 79400 loss std/mean: 0.025632470846176147 0.24704860150814056\n",
      "| Loss std:   0.025632 |\n",
      "| Loss mean:   0.247049 |\n",
      "g_step: 79500 loss std/mean: 0.01999756135046482 0.2541735768318176\n",
      "| Loss std:   0.019998 |\n",
      "| Loss mean:   0.254174 |\n",
      "g_step: 79600 loss std/mean: 0.024038098752498627 0.24719110131263733\n",
      "| Loss std:   0.024038 |\n",
      "| Loss mean:   0.247191 |\n",
      "g_step: 79700 loss std/mean: 0.023304160684347153 0.2493140548467636\n",
      "| Loss std:   0.023304 |\n",
      "| Loss mean:   0.249314 |\n",
      "g_step: 79800 loss std/mean: 0.027979224920272827 0.24881528317928314\n",
      "| Loss std:   0.027979 |\n",
      "| Loss mean:   0.248815 |\n",
      "g_step: 79900 loss std/mean: 0.026180297136306763 0.24899011850357056\n",
      "| Loss std:   0.026180 |\n",
      "| Loss mean:   0.248990 |\n",
      "g_step: 80000 loss std/mean: 0.025000080466270447 0.24640098214149475\n",
      "| Loss std:   0.025000 |\n",
      "| Loss mean:   0.246401 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NWRMSLE  : 0.529416793628\n",
      "| Validation NWRMSLE:   0.529417 |\n",
      "\tValidation NWRMSLE_5: 0.523491194692\n",
      "| Validation NWRMSLE_5:   0.523491 |\n",
      "g_step: 80100 loss std/mean: 0.022306036204099655 0.2494547814130783\n",
      "| Loss std:   0.022306 |\n",
      "| Loss mean:   0.249455 |\n",
      "g_step: 80200 loss std/mean: 0.023917226120829582 0.25340694189071655\n",
      "| Loss std:   0.023917 |\n",
      "| Loss mean:   0.253407 |\n",
      "g_step: 80300 loss std/mean: 0.022553790360689163 0.2448974996805191\n",
      "| Loss std:   0.022554 |\n",
      "| Loss mean:   0.244897 |\n",
      "g_step: 80400 loss std/mean: 0.023822568356990814 0.24967649579048157\n",
      "| Loss std:   0.023823 |\n",
      "| Loss mean:   0.249676 |\n",
      "g_step: 80500 loss std/mean: 0.02704465016722679 0.24409198760986328\n",
      "| Loss std:   0.027045 |\n",
      "| Loss mean:   0.244092 |\n",
      "g_step: 80600 loss std/mean: 0.02467367611825466 0.24342837929725647\n",
      "| Loss std:   0.024674 |\n",
      "| Loss mean:   0.243428 |\n",
      "g_step: 80700 loss std/mean: 0.02126428671181202 0.2554239332675934\n",
      "| Loss std:   0.021264 |\n",
      "| Loss mean:   0.255424 |\n",
      "g_step: 80800 loss std/mean: 0.020027073100209236 0.2531803846359253\n",
      "| Loss std:   0.020027 |\n",
      "| Loss mean:   0.253180 |\n",
      "g_step: 80900 loss std/mean: 0.0223137978464365 0.25373589992523193\n",
      "| Loss std:   0.022314 |\n",
      "| Loss mean:   0.253736 |\n",
      "g_step: 81000 loss std/mean: 0.02347649447619915 0.24786506593227386\n",
      "| Loss std:   0.023476 |\n",
      "| Loss mean:   0.247865 |\n",
      "g_step: 81100 loss std/mean: 0.027714310213923454 0.25672125816345215\n",
      "| Loss std:   0.027714 |\n",
      "| Loss mean:   0.256721 |\n",
      "g_step: 81200 loss std/mean: 0.02337685041129589 0.25136616826057434\n",
      "| Loss std:   0.023377 |\n",
      "| Loss mean:   0.251366 |\n",
      "g_step: 81300 loss std/mean: 0.022113120183348656 0.2562071681022644\n",
      "| Loss std:   0.022113 |\n",
      "| Loss mean:   0.256207 |\n",
      "g_step: 81400 loss std/mean: 0.02668290212750435 0.2501768171787262\n",
      "| Loss std:   0.026683 |\n",
      "| Loss mean:   0.250177 |\n",
      "g_step: 81500 loss std/mean: 0.02496664598584175 0.24732564389705658\n",
      "| Loss std:   0.024967 |\n",
      "| Loss mean:   0.247326 |\n",
      "g_step: 81600 loss std/mean: 0.02403397113084793 0.2509691119194031\n",
      "| Loss std:   0.024034 |\n",
      "| Loss mean:   0.250969 |\n",
      "g_step: 81700 loss std/mean: 0.02123725228011608 0.25271207094192505\n",
      "| Loss std:   0.021237 |\n",
      "| Loss mean:   0.252712 |\n",
      "g_step: 81800 loss std/mean: 0.021866638213396072 0.2509269118309021\n",
      "| Loss std:   0.021867 |\n",
      "| Loss mean:   0.250927 |\n",
      "g_step: 81900 loss std/mean: 0.02537151239812374 0.24934378266334534\n",
      "| Loss std:   0.025372 |\n",
      "| Loss mean:   0.249344 |\n",
      "g_step: 82000 loss std/mean: 0.025157133117318153 0.24752509593963623\n",
      "| Loss std:   0.025157 |\n",
      "| Loss mean:   0.247525 |\n",
      "g_step: 82100 loss std/mean: 0.022062569856643677 0.251741498708725\n",
      "| Loss std:   0.022063 |\n",
      "| Loss mean:   0.251741 |\n",
      "g_step: 82200 loss std/mean: 0.025807850062847137 0.25009769201278687\n",
      "| Loss std:   0.025808 |\n",
      "| Loss mean:   0.250098 |\n",
      "g_step: 82300 loss std/mean: 0.022880155593156815 0.24877731502056122\n",
      "| Loss std:   0.022880 |\n",
      "| Loss mean:   0.248777 |\n",
      "g_step: 82400 loss std/mean: 0.02552555501461029 0.25207284092903137\n",
      "| Loss std:   0.025526 |\n",
      "| Loss mean:   0.252073 |\n",
      "g_step: 82500 loss std/mean: 0.0242917500436306 0.24955154955387115\n",
      "| Loss std:   0.024292 |\n",
      "| Loss mean:   0.249552 |\n",
      "g_step: 82600 loss std/mean: 0.02250278741121292 0.2577461898326874\n",
      "| Loss std:   0.022503 |\n",
      "| Loss mean:   0.257746 |\n",
      "g_step: 82700 loss std/mean: 0.023744886741042137 0.2545052766799927\n",
      "| Loss std:   0.023745 |\n",
      "| Loss mean:   0.254505 |\n",
      "g_step: 82800 loss std/mean: 0.023619582876563072 0.25159701704978943\n",
      "| Loss std:   0.023620 |\n",
      "| Loss mean:   0.251597 |\n",
      "g_step: 82900 loss std/mean: 0.02400525100529194 0.25125449895858765\n",
      "| Loss std:   0.024005 |\n",
      "| Loss mean:   0.251254 |\n",
      "g_step: 83000 loss std/mean: 0.02142120711505413 0.2515648603439331\n",
      "| Loss std:   0.021421 |\n",
      "| Loss mean:   0.251565 |\n",
      "g_step: 83100 loss std/mean: 0.023135634139180183 0.25276684761047363\n",
      "| Loss std:   0.023136 |\n",
      "| Loss mean:   0.252767 |\n",
      "g_step: 83200 loss std/mean: 0.027268126606941223 0.25195005536079407\n",
      "| Loss std:   0.027268 |\n",
      "| Loss mean:   0.251950 |\n",
      "g_step: 83300 loss std/mean: 0.025060979649424553 0.24773330986499786\n",
      "| Loss std:   0.025061 |\n",
      "| Loss mean:   0.247733 |\n",
      "g_step: 83400 loss std/mean: 0.020388590171933174 0.25587835907936096\n",
      "| Loss std:   0.020389 |\n",
      "| Loss mean:   0.255878 |\n",
      "g_step: 83500 loss std/mean: 0.027250831946730614 0.24761395156383514\n",
      "| Loss std:   0.027251 |\n",
      "| Loss mean:   0.247614 |\n",
      "g_step: 83600 loss std/mean: 0.025053905323147774 0.2482362538576126\n",
      "| Loss std:   0.025054 |\n",
      "| Loss mean:   0.248236 |\n",
      "g_step: 83700 loss std/mean: 0.023423735052347183 0.25083449482917786\n",
      "| Loss std:   0.023424 |\n",
      "| Loss mean:   0.250834 |\n",
      "g_step: 83800 loss std/mean: 0.02175278775393963 0.25828856229782104\n",
      "| Loss std:   0.021753 |\n",
      "| Loss mean:   0.258289 |\n",
      "g_step: 83900 loss std/mean: 0.02691762149333954 0.2529638111591339\n",
      "| Loss std:   0.026918 |\n",
      "| Loss mean:   0.252964 |\n",
      "g_step: 84000 loss std/mean: 0.019452277570962906 0.24973136186599731\n",
      "| Loss std:   0.019452 |\n",
      "| Loss mean:   0.249731 |\n",
      "g_step: 84100 loss std/mean: 0.027305947616696358 0.2503686845302582\n",
      "| Loss std:   0.027306 |\n",
      "| Loss mean:   0.250369 |\n",
      "g_step: 84200 loss std/mean: 0.020938776433467865 0.25749489665031433\n",
      "| Loss std:   0.020939 |\n",
      "| Loss mean:   0.257495 |\n",
      "g_step: 84300 loss std/mean: 0.02453976310789585 0.25104576349258423\n",
      "| Loss std:   0.024540 |\n",
      "| Loss mean:   0.251046 |\n",
      "g_step: 84400 loss std/mean: 0.027023278176784515 0.2545144557952881\n",
      "| Loss std:   0.027023 |\n",
      "| Loss mean:   0.254514 |\n",
      "g_step: 84500 loss std/mean: 0.02460925281047821 0.2440788894891739\n",
      "| Loss std:   0.024609 |\n",
      "| Loss mean:   0.244079 |\n",
      "g_step: 84600 loss std/mean: 0.020537573844194412 0.24962620437145233\n",
      "| Loss std:   0.020538 |\n",
      "| Loss mean:   0.249626 |\n",
      "g_step: 84700 loss std/mean: 0.024078646674752235 0.25353801250457764\n",
      "| Loss std:   0.024079 |\n",
      "| Loss mean:   0.253538 |\n",
      "g_step: 84800 loss std/mean: 0.027810068801045418 0.25098955631256104\n",
      "| Loss std:   0.027810 |\n",
      "| Loss mean:   0.250990 |\n",
      "g_step: 84900 loss std/mean: 0.026124080643057823 0.25505900382995605\n",
      "| Loss std:   0.026124 |\n",
      "| Loss mean:   0.255059 |\n",
      "g_step: 85000 loss std/mean: 0.02655935101211071 0.25375479459762573\n",
      "| Loss std:   0.026559 |\n",
      "| Loss mean:   0.253755 |\n",
      "\tValidation NWRMSLE  : 0.529434345315\n",
      "| Validation NWRMSLE:   0.529434 |\n",
      "\tValidation NWRMSLE_5: 0.523828147879\n",
      "| Validation NWRMSLE_5:   0.523828 |\n",
      "g_step: 85100 loss std/mean: 0.02506551519036293 0.2498628944158554\n",
      "| Loss std:   0.025066 |\n",
      "| Loss mean:   0.249863 |\n",
      "g_step: 85200 loss std/mean: 0.02264592982828617 0.25623613595962524\n",
      "| Loss std:   0.022646 |\n",
      "| Loss mean:   0.256236 |\n",
      "g_step: 85300 loss std/mean: 0.02052234299480915 0.257493257522583\n",
      "| Loss std:   0.020522 |\n",
      "| Loss mean:   0.257493 |\n",
      "g_step: 85400 loss std/mean: 0.025977473706007004 0.24913230538368225\n",
      "| Loss std:   0.025977 |\n",
      "| Loss mean:   0.249132 |\n",
      "g_step: 85500 loss std/mean: 0.02029171772301197 0.2574878931045532\n",
      "| Loss std:   0.020292 |\n",
      "| Loss mean:   0.257488 |\n",
      "g_step: 85600 loss std/mean: 0.02210804633796215 0.2506544888019562\n",
      "| Loss std:   0.022108 |\n",
      "| Loss mean:   0.250654 |\n",
      "g_step: 85700 loss std/mean: 0.026802461594343185 0.24497388303279877\n",
      "| Loss std:   0.026802 |\n",
      "| Loss mean:   0.244974 |\n",
      "g_step: 85800 loss std/mean: 0.02045205608010292 0.24847036600112915\n",
      "| Loss std:   0.020452 |\n",
      "| Loss mean:   0.248470 |\n",
      "g_step: 85900 loss std/mean: 0.023364150896668434 0.24897541105747223\n",
      "| Loss std:   0.023364 |\n",
      "| Loss mean:   0.248975 |\n",
      "g_step: 86000 loss std/mean: 0.025050988420844078 0.24327658116817474\n",
      "| Loss std:   0.025051 |\n",
      "| Loss mean:   0.243277 |\n",
      "g_step: 86100 loss std/mean: 0.02137061581015587 0.25772541761398315\n",
      "| Loss std:   0.021371 |\n",
      "| Loss mean:   0.257725 |\n",
      "g_step: 86200 loss std/mean: 0.02627849206328392 0.2511011064052582\n",
      "| Loss std:   0.026278 |\n",
      "| Loss mean:   0.251101 |\n",
      "g_step: 86300 loss std/mean: 0.026594048365950584 0.25766506791114807\n",
      "| Loss std:   0.026594 |\n",
      "| Loss mean:   0.257665 |\n",
      "g_step: 86400 loss std/mean: 0.025734918192029 0.25008127093315125\n",
      "| Loss std:   0.025735 |\n",
      "| Loss mean:   0.250081 |\n",
      "g_step: 86500 loss std/mean: 0.024131327867507935 0.24743616580963135\n",
      "| Loss std:   0.024131 |\n",
      "| Loss mean:   0.247436 |\n",
      "g_step: 86600 loss std/mean: 0.02354506403207779 0.25408071279525757\n",
      "| Loss std:   0.023545 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.254081 |\n",
      "g_step: 86700 loss std/mean: 0.01995071955025196 0.25402212142944336\n",
      "| Loss std:   0.019951 |\n",
      "| Loss mean:   0.254022 |\n",
      "g_step: 86800 loss std/mean: 0.027252938598394394 0.2564069926738739\n",
      "| Loss std:   0.027253 |\n",
      "| Loss mean:   0.256407 |\n",
      "g_step: 86900 loss std/mean: 0.021259967237710953 0.25084078311920166\n",
      "| Loss std:   0.021260 |\n",
      "| Loss mean:   0.250841 |\n",
      "g_step: 87000 loss std/mean: 0.026380516588687897 0.2512950599193573\n",
      "| Loss std:   0.026381 |\n",
      "| Loss mean:   0.251295 |\n",
      "g_step: 87100 loss std/mean: 0.025337805971503258 0.2513958811759949\n",
      "| Loss std:   0.025338 |\n",
      "| Loss mean:   0.251396 |\n",
      "g_step: 87200 loss std/mean: 0.025482237339019775 0.256461501121521\n",
      "| Loss std:   0.025482 |\n",
      "| Loss mean:   0.256462 |\n",
      "g_step: 87300 loss std/mean: 0.021205488592386246 0.2489703893661499\n",
      "| Loss std:   0.021205 |\n",
      "| Loss mean:   0.248970 |\n",
      "g_step: 87400 loss std/mean: 0.024178529158234596 0.24942512810230255\n",
      "| Loss std:   0.024179 |\n",
      "| Loss mean:   0.249425 |\n",
      "g_step: 87500 loss std/mean: 0.02630484290421009 0.2532082796096802\n",
      "| Loss std:   0.026305 |\n",
      "| Loss mean:   0.253208 |\n",
      "g_step: 87600 loss std/mean: 0.026057226583361626 0.25294438004493713\n",
      "| Loss std:   0.026057 |\n",
      "| Loss mean:   0.252944 |\n",
      "g_step: 87700 loss std/mean: 0.02152678184211254 0.25183266401290894\n",
      "| Loss std:   0.021527 |\n",
      "| Loss mean:   0.251833 |\n",
      "g_step: 87800 loss std/mean: 0.024950455874204636 0.2510586977005005\n",
      "| Loss std:   0.024950 |\n",
      "| Loss mean:   0.251059 |\n",
      "g_step: 87900 loss std/mean: 0.02598481811583042 0.24914532899856567\n",
      "| Loss std:   0.025985 |\n",
      "| Loss mean:   0.249145 |\n",
      "g_step: 88000 loss std/mean: 0.02590523660182953 0.241071879863739\n",
      "| Loss std:   0.025905 |\n",
      "| Loss mean:   0.241072 |\n",
      "g_step: 88100 loss std/mean: 0.025829855352640152 0.25455665588378906\n",
      "| Loss std:   0.025830 |\n",
      "| Loss mean:   0.254557 |\n",
      "g_step: 88200 loss std/mean: 0.02190508507192135 0.24766799807548523\n",
      "| Loss std:   0.021905 |\n",
      "| Loss mean:   0.247668 |\n",
      "g_step: 88300 loss std/mean: 0.020692382007837296 0.25401490926742554\n",
      "| Loss std:   0.020692 |\n",
      "| Loss mean:   0.254015 |\n",
      "g_step: 88400 loss std/mean: 0.023671424016356468 0.24956603348255157\n",
      "| Loss std:   0.023671 |\n",
      "| Loss mean:   0.249566 |\n",
      "g_step: 88500 loss std/mean: 0.022175250574946404 0.25408878922462463\n",
      "| Loss std:   0.022175 |\n",
      "| Loss mean:   0.254089 |\n",
      "g_step: 88600 loss std/mean: 0.021718446165323257 0.2591956555843353\n",
      "| Loss std:   0.021718 |\n",
      "| Loss mean:   0.259196 |\n",
      "g_step: 88700 loss std/mean: 0.02252252586185932 0.2504056990146637\n",
      "| Loss std:   0.022523 |\n",
      "| Loss mean:   0.250406 |\n",
      "g_step: 88800 loss std/mean: 0.022481875494122505 0.2499583214521408\n",
      "| Loss std:   0.022482 |\n",
      "| Loss mean:   0.249958 |\n",
      "g_step: 88900 loss std/mean: 0.024881334975361824 0.24851806461811066\n",
      "| Loss std:   0.024881 |\n",
      "| Loss mean:   0.248518 |\n",
      "g_step: 89000 loss std/mean: 0.02522392012178898 0.24869373440742493\n",
      "| Loss std:   0.025224 |\n",
      "| Loss mean:   0.248694 |\n",
      "g_step: 89100 loss std/mean: 0.02005559764802456 0.25619640946388245\n",
      "| Loss std:   0.020056 |\n",
      "| Loss mean:   0.256196 |\n",
      "g_step: 89200 loss std/mean: 0.021933015435934067 0.2547471821308136\n",
      "| Loss std:   0.021933 |\n",
      "| Loss mean:   0.254747 |\n",
      "g_step: 89300 loss std/mean: 0.024632751941680908 0.24776238203048706\n",
      "| Loss std:   0.024633 |\n",
      "| Loss mean:   0.247762 |\n",
      "g_step: 89400 loss std/mean: 0.021789761260151863 0.250911682844162\n",
      "| Loss std:   0.021790 |\n",
      "| Loss mean:   0.250912 |\n",
      "g_step: 89500 loss std/mean: 0.024314535781741142 0.25337153673171997\n",
      "| Loss std:   0.024315 |\n",
      "| Loss mean:   0.253372 |\n",
      "g_step: 89600 loss std/mean: 0.020888101309537888 0.24865591526031494\n",
      "| Loss std:   0.020888 |\n",
      "| Loss mean:   0.248656 |\n",
      "g_step: 89700 loss std/mean: 0.023780282586812973 0.25217652320861816\n",
      "| Loss std:   0.023780 |\n",
      "| Loss mean:   0.252177 |\n",
      "g_step: 89800 loss std/mean: 0.02170397713780403 0.25385844707489014\n",
      "| Loss std:   0.021704 |\n",
      "| Loss mean:   0.253858 |\n",
      "g_step: 89900 loss std/mean: 0.020368216559290886 0.2514260411262512\n",
      "| Loss std:   0.020368 |\n",
      "| Loss mean:   0.251426 |\n",
      "g_step: 90000 loss std/mean: 0.025543896481394768 0.25612276792526245\n",
      "| Loss std:   0.025544 |\n",
      "| Loss mean:   0.256123 |\n",
      "\tValidation NWRMSLE  : 0.529587373343\n",
      "| Validation NWRMSLE:   0.529587 |\n",
      "\tValidation NWRMSLE_5: 0.523848336064\n",
      "| Validation NWRMSLE_5:   0.523848 |\n",
      "g_step: 90100 loss std/mean: 0.023121407255530357 0.2531552016735077\n",
      "| Loss std:   0.023121 |\n",
      "| Loss mean:   0.253155 |\n",
      "g_step: 90200 loss std/mean: 0.02494487725198269 0.24953269958496094\n",
      "| Loss std:   0.024945 |\n",
      "| Loss mean:   0.249533 |\n",
      "g_step: 90300 loss std/mean: 0.02235490456223488 0.25755220651626587\n",
      "| Loss std:   0.022355 |\n",
      "| Loss mean:   0.257552 |\n",
      "g_step: 90400 loss std/mean: 0.021736828610301018 0.2536761164665222\n",
      "| Loss std:   0.021737 |\n",
      "| Loss mean:   0.253676 |\n",
      "g_step: 90500 loss std/mean: 0.02287214808166027 0.25520607829093933\n",
      "| Loss std:   0.022872 |\n",
      "| Loss mean:   0.255206 |\n",
      "g_step: 90600 loss std/mean: 0.024439478293061256 0.24987134337425232\n",
      "| Loss std:   0.024439 |\n",
      "| Loss mean:   0.249871 |\n",
      "g_step: 90700 loss std/mean: 0.025406047701835632 0.24418817460536957\n",
      "| Loss std:   0.025406 |\n",
      "| Loss mean:   0.244188 |\n",
      "g_step: 90800 loss std/mean: 0.0232157651335001 0.2517600655555725\n",
      "| Loss std:   0.023216 |\n",
      "| Loss mean:   0.251760 |\n",
      "g_step: 90900 loss std/mean: 0.02678699791431427 0.25257351994514465\n",
      "| Loss std:   0.026787 |\n",
      "| Loss mean:   0.252574 |\n",
      "g_step: 91000 loss std/mean: 0.022680142894387245 0.24950136244297028\n",
      "| Loss std:   0.022680 |\n",
      "| Loss mean:   0.249501 |\n",
      "g_step: 91100 loss std/mean: 0.02207348495721817 0.2516898214817047\n",
      "| Loss std:   0.022073 |\n",
      "| Loss mean:   0.251690 |\n",
      "g_step: 91200 loss std/mean: 0.02768242545425892 0.2479567974805832\n",
      "| Loss std:   0.027682 |\n",
      "| Loss mean:   0.247957 |\n",
      "g_step: 91300 loss std/mean: 0.02214163728058338 0.25505372881889343\n",
      "| Loss std:   0.022142 |\n",
      "| Loss mean:   0.255054 |\n",
      "g_step: 91400 loss std/mean: 0.01925867795944214 0.25210970640182495\n",
      "| Loss std:   0.019259 |\n",
      "| Loss mean:   0.252110 |\n",
      "g_step: 91500 loss std/mean: 0.029582129791378975 0.25104498863220215\n",
      "| Loss std:   0.029582 |\n",
      "| Loss mean:   0.251045 |\n",
      "g_step: 91600 loss std/mean: 0.024494854733347893 0.2561972141265869\n",
      "| Loss std:   0.024495 |\n",
      "| Loss mean:   0.256197 |\n",
      "g_step: 91700 loss std/mean: 0.027824509888887405 0.24868673086166382\n",
      "| Loss std:   0.027825 |\n",
      "| Loss mean:   0.248687 |\n",
      "g_step: 91800 loss std/mean: 0.023706240579485893 0.2547833025455475\n",
      "| Loss std:   0.023706 |\n",
      "| Loss mean:   0.254783 |\n",
      "g_step: 91900 loss std/mean: 0.025036944076418877 0.25530561804771423\n",
      "| Loss std:   0.025037 |\n",
      "| Loss mean:   0.255306 |\n",
      "g_step: 92000 loss std/mean: 0.026739712804555893 0.25336867570877075\n",
      "| Loss std:   0.026740 |\n",
      "| Loss mean:   0.253369 |\n",
      "g_step: 92100 loss std/mean: 0.02625403366982937 0.2535310983657837\n",
      "| Loss std:   0.026254 |\n",
      "| Loss mean:   0.253531 |\n",
      "g_step: 92200 loss std/mean: 0.023239661008119583 0.2471994012594223\n",
      "| Loss std:   0.023240 |\n",
      "| Loss mean:   0.247199 |\n",
      "g_step: 92300 loss std/mean: 0.02514825202524662 0.2477620244026184\n",
      "| Loss std:   0.025148 |\n",
      "| Loss mean:   0.247762 |\n",
      "g_step: 92400 loss std/mean: 0.024990109726786613 0.24639080464839935\n",
      "| Loss std:   0.024990 |\n",
      "| Loss mean:   0.246391 |\n",
      "g_step: 92500 loss std/mean: 0.023364203050732613 0.2494155466556549\n",
      "| Loss std:   0.023364 |\n",
      "| Loss mean:   0.249416 |\n",
      "g_step: 92600 loss std/mean: 0.022697944194078445 0.25371861457824707\n",
      "| Loss std:   0.022698 |\n",
      "| Loss mean:   0.253719 |\n",
      "g_step: 92700 loss std/mean: 0.026612667366862297 0.24820779263973236\n",
      "| Loss std:   0.026613 |\n",
      "| Loss mean:   0.248208 |\n",
      "g_step: 92800 loss std/mean: 0.02605460025370121 0.25048747658729553\n",
      "| Loss std:   0.026055 |\n",
      "| Loss mean:   0.250487 |\n",
      "g_step: 92900 loss std/mean: 0.021899431943893433 0.25517043471336365\n",
      "| Loss std:   0.021899 |\n",
      "| Loss mean:   0.255170 |\n",
      "g_step: 93000 loss std/mean: 0.02336038462817669 0.2569043040275574\n",
      "| Loss std:   0.023360 |\n",
      "| Loss mean:   0.256904 |\n",
      "g_step: 93100 loss std/mean: 0.021658439189195633 0.24510401487350464\n",
      "| Loss std:   0.021658 |\n",
      "| Loss mean:   0.245104 |\n",
      "g_step: 93200 loss std/mean: 0.02173604816198349 0.24834446609020233\n",
      "| Loss std:   0.021736 |\n",
      "| Loss mean:   0.248344 |\n",
      "g_step: 93300 loss std/mean: 0.024075133726000786 0.2540469765663147\n",
      "| Loss std:   0.024075 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.254047 |\n",
      "g_step: 93400 loss std/mean: 0.024459155276417732 0.2579696774482727\n",
      "| Loss std:   0.024459 |\n",
      "| Loss mean:   0.257970 |\n",
      "g_step: 93500 loss std/mean: 0.022435927763581276 0.24780669808387756\n",
      "| Loss std:   0.022436 |\n",
      "| Loss mean:   0.247807 |\n",
      "g_step: 93600 loss std/mean: 0.024571087211370468 0.2495572715997696\n",
      "| Loss std:   0.024571 |\n",
      "| Loss mean:   0.249557 |\n",
      "g_step: 93700 loss std/mean: 0.021389134228229523 0.24993625283241272\n",
      "| Loss std:   0.021389 |\n",
      "| Loss mean:   0.249936 |\n",
      "g_step: 93800 loss std/mean: 0.025005506351590157 0.2537928819656372\n",
      "| Loss std:   0.025006 |\n",
      "| Loss mean:   0.253793 |\n",
      "g_step: 93900 loss std/mean: 0.024866560474038124 0.25524741411209106\n",
      "| Loss std:   0.024867 |\n",
      "| Loss mean:   0.255247 |\n",
      "g_step: 94000 loss std/mean: 0.020660294219851494 0.24937331676483154\n",
      "| Loss std:   0.020660 |\n",
      "| Loss mean:   0.249373 |\n",
      "g_step: 94100 loss std/mean: 0.025471478700637817 0.2543089985847473\n",
      "| Loss std:   0.025471 |\n",
      "| Loss mean:   0.254309 |\n",
      "g_step: 94200 loss std/mean: 0.02518335171043873 0.2516959309577942\n",
      "| Loss std:   0.025183 |\n",
      "| Loss mean:   0.251696 |\n",
      "g_step: 94300 loss std/mean: 0.021610191091895103 0.2543199360370636\n",
      "| Loss std:   0.021610 |\n",
      "| Loss mean:   0.254320 |\n",
      "g_step: 94400 loss std/mean: 0.021753381937742233 0.2540547549724579\n",
      "| Loss std:   0.021753 |\n",
      "| Loss mean:   0.254055 |\n",
      "g_step: 94500 loss std/mean: 0.021285617724061012 0.24841170012950897\n",
      "| Loss std:   0.021286 |\n",
      "| Loss mean:   0.248412 |\n",
      "g_step: 94600 loss std/mean: 0.01895749755203724 0.2490493655204773\n",
      "| Loss std:   0.018957 |\n",
      "| Loss mean:   0.249049 |\n",
      "g_step: 94700 loss std/mean: 0.023777015507221222 0.24694865942001343\n",
      "| Loss std:   0.023777 |\n",
      "| Loss mean:   0.246949 |\n",
      "g_step: 94800 loss std/mean: 0.024865781888365746 0.25319939851760864\n",
      "| Loss std:   0.024866 |\n",
      "| Loss mean:   0.253199 |\n",
      "g_step: 94900 loss std/mean: 0.025893477723002434 0.25204724073410034\n",
      "| Loss std:   0.025893 |\n",
      "| Loss mean:   0.252047 |\n",
      "g_step: 95000 loss std/mean: 0.02189297415316105 0.2510453760623932\n",
      "| Loss std:   0.021893 |\n",
      "| Loss mean:   0.251045 |\n",
      "\tValidation NWRMSLE  : 0.529348626295\n",
      "| Validation NWRMSLE:   0.529349 |\n",
      "\tValidation NWRMSLE_5: 0.523517184735\n",
      "| Validation NWRMSLE_5:   0.523517 |\n",
      "g_step: 95100 loss std/mean: 0.024843202903866768 0.25198689103126526\n",
      "| Loss std:   0.024843 |\n",
      "| Loss mean:   0.251987 |\n",
      "g_step: 95200 loss std/mean: 0.022468440234661102 0.24837546050548553\n",
      "| Loss std:   0.022468 |\n",
      "| Loss mean:   0.248375 |\n",
      "g_step: 95300 loss std/mean: 0.02201860025525093 0.24985530972480774\n",
      "| Loss std:   0.022019 |\n",
      "| Loss mean:   0.249855 |\n",
      "g_step: 95400 loss std/mean: 0.019768506288528442 0.25154122710227966\n",
      "| Loss std:   0.019769 |\n",
      "| Loss mean:   0.251541 |\n",
      "g_step: 95500 loss std/mean: 0.02464171126484871 0.2532501220703125\n",
      "| Loss std:   0.024642 |\n",
      "| Loss mean:   0.253250 |\n",
      "g_step: 95600 loss std/mean: 0.02529347687959671 0.24918556213378906\n",
      "| Loss std:   0.025293 |\n",
      "| Loss mean:   0.249186 |\n",
      "g_step: 95700 loss std/mean: 0.02779962494969368 0.25138160586357117\n",
      "| Loss std:   0.027800 |\n",
      "| Loss mean:   0.251382 |\n",
      "g_step: 95800 loss std/mean: 0.021869264543056488 0.24818065762519836\n",
      "| Loss std:   0.021869 |\n",
      "| Loss mean:   0.248181 |\n",
      "g_step: 95900 loss std/mean: 0.02139565534889698 0.251015841960907\n",
      "| Loss std:   0.021396 |\n",
      "| Loss mean:   0.251016 |\n",
      "g_step: 96000 loss std/mean: 0.025854656472802162 0.24835598468780518\n",
      "| Loss std:   0.025855 |\n",
      "| Loss mean:   0.248356 |\n",
      "g_step: 96100 loss std/mean: 0.026130802929401398 0.251358300447464\n",
      "| Loss std:   0.026131 |\n",
      "| Loss mean:   0.251358 |\n",
      "g_step: 96200 loss std/mean: 0.021890373900532722 0.2494841367006302\n",
      "| Loss std:   0.021890 |\n",
      "| Loss mean:   0.249484 |\n",
      "g_step: 96300 loss std/mean: 0.023873163387179375 0.252084344625473\n",
      "| Loss std:   0.023873 |\n",
      "| Loss mean:   0.252084 |\n",
      "g_step: 96400 loss std/mean: 0.02117074467241764 0.24500402808189392\n",
      "| Loss std:   0.021171 |\n",
      "| Loss mean:   0.245004 |\n",
      "g_step: 96500 loss std/mean: 0.023217448964715004 0.2480970323085785\n",
      "| Loss std:   0.023217 |\n",
      "| Loss mean:   0.248097 |\n",
      "g_step: 96600 loss std/mean: 0.02366461418569088 0.2536892592906952\n",
      "| Loss std:   0.023665 |\n",
      "| Loss mean:   0.253689 |\n",
      "g_step: 96700 loss std/mean: 0.024699514731764793 0.2521613836288452\n",
      "| Loss std:   0.024700 |\n",
      "| Loss mean:   0.252161 |\n",
      "g_step: 96800 loss std/mean: 0.022204389795660973 0.2570746839046478\n",
      "| Loss std:   0.022204 |\n",
      "| Loss mean:   0.257075 |\n",
      "g_step: 96900 loss std/mean: 0.027111411094665527 0.24392905831336975\n",
      "| Loss std:   0.027111 |\n",
      "| Loss mean:   0.243929 |\n",
      "g_step: 97000 loss std/mean: 0.02440386638045311 0.251315712928772\n",
      "| Loss std:   0.024404 |\n",
      "| Loss mean:   0.251316 |\n",
      "g_step: 97100 loss std/mean: 0.02394859306514263 0.2469351887702942\n",
      "| Loss std:   0.023949 |\n",
      "| Loss mean:   0.246935 |\n",
      "g_step: 97200 loss std/mean: 0.02862049639225006 0.250098317861557\n",
      "| Loss std:   0.028620 |\n",
      "| Loss mean:   0.250098 |\n",
      "g_step: 97300 loss std/mean: 0.023672934621572495 0.2483697384595871\n",
      "| Loss std:   0.023673 |\n",
      "| Loss mean:   0.248370 |\n",
      "g_step: 97400 loss std/mean: 0.02398701012134552 0.24976186454296112\n",
      "| Loss std:   0.023987 |\n",
      "| Loss mean:   0.249762 |\n",
      "g_step: 97500 loss std/mean: 0.022631041705608368 0.255372017621994\n",
      "| Loss std:   0.022631 |\n",
      "| Loss mean:   0.255372 |\n",
      "g_step: 97600 loss std/mean: 0.02148272655904293 0.24775895476341248\n",
      "| Loss std:   0.021483 |\n",
      "| Loss mean:   0.247759 |\n",
      "g_step: 97700 loss std/mean: 0.024621732532978058 0.25452911853790283\n",
      "| Loss std:   0.024622 |\n",
      "| Loss mean:   0.254529 |\n",
      "g_step: 97800 loss std/mean: 0.02250155247747898 0.24621418118476868\n",
      "| Loss std:   0.022502 |\n",
      "| Loss mean:   0.246214 |\n",
      "g_step: 97900 loss std/mean: 0.02537180669605732 0.2513101398944855\n",
      "| Loss std:   0.025372 |\n",
      "| Loss mean:   0.251310 |\n",
      "g_step: 98000 loss std/mean: 0.023826908320188522 0.2502520680427551\n",
      "| Loss std:   0.023827 |\n",
      "| Loss mean:   0.250252 |\n",
      "g_step: 98100 loss std/mean: 0.023006156086921692 0.25333625078201294\n",
      "| Loss std:   0.023006 |\n",
      "| Loss mean:   0.253336 |\n",
      "g_step: 98200 loss std/mean: 0.02859274484217167 0.2513188421726227\n",
      "| Loss std:   0.028593 |\n",
      "| Loss mean:   0.251319 |\n",
      "g_step: 98300 loss std/mean: 0.023714499548077583 0.25326937437057495\n",
      "| Loss std:   0.023714 |\n",
      "| Loss mean:   0.253269 |\n",
      "g_step: 98400 loss std/mean: 0.021303556859493256 0.24850817024707794\n",
      "| Loss std:   0.021304 |\n",
      "| Loss mean:   0.248508 |\n",
      "g_step: 98500 loss std/mean: 0.0196140818297863 0.2530282139778137\n",
      "| Loss std:   0.019614 |\n",
      "| Loss mean:   0.253028 |\n",
      "g_step: 98600 loss std/mean: 0.021257193759083748 0.2545187771320343\n",
      "| Loss std:   0.021257 |\n",
      "| Loss mean:   0.254519 |\n",
      "g_step: 98700 loss std/mean: 0.02506088837981224 0.243407741189003\n",
      "| Loss std:   0.025061 |\n",
      "| Loss mean:   0.243408 |\n",
      "g_step: 98800 loss std/mean: 0.02392137050628662 0.25289207696914673\n",
      "| Loss std:   0.023921 |\n",
      "| Loss mean:   0.252892 |\n",
      "g_step: 98900 loss std/mean: 0.027252355590462685 0.24407681822776794\n",
      "| Loss std:   0.027252 |\n",
      "| Loss mean:   0.244077 |\n",
      "g_step: 99000 loss std/mean: 0.02238922007381916 0.2486022710800171\n",
      "| Loss std:   0.022389 |\n",
      "| Loss mean:   0.248602 |\n",
      "g_step: 99100 loss std/mean: 0.0266127772629261 0.24065609276294708\n",
      "| Loss std:   0.026613 |\n",
      "| Loss mean:   0.240656 |\n",
      "g_step: 99200 loss std/mean: 0.027173342183232307 0.25153523683547974\n",
      "| Loss std:   0.027173 |\n",
      "| Loss mean:   0.251535 |\n",
      "g_step: 99300 loss std/mean: 0.026215538382530212 0.2500201463699341\n",
      "| Loss std:   0.026216 |\n",
      "| Loss mean:   0.250020 |\n",
      "g_step: 99400 loss std/mean: 0.022879986092448235 0.25220221281051636\n",
      "| Loss std:   0.022880 |\n",
      "| Loss mean:   0.252202 |\n",
      "g_step: 99500 loss std/mean: 0.02202625386416912 0.2524060904979706\n",
      "| Loss std:   0.022026 |\n",
      "| Loss mean:   0.252406 |\n",
      "g_step: 99600 loss std/mean: 0.025818176567554474 0.25343528389930725\n",
      "| Loss std:   0.025818 |\n",
      "| Loss mean:   0.253435 |\n",
      "g_step: 99700 loss std/mean: 0.02705569379031658 0.24869005382061005\n",
      "| Loss std:   0.027056 |\n",
      "| Loss mean:   0.248690 |\n",
      "g_step: 99800 loss std/mean: 0.01842593029141426 0.2586105763912201\n",
      "| Loss std:   0.018426 |\n",
      "| Loss mean:   0.258611 |\n",
      "g_step: 99900 loss std/mean: 0.020994020625948906 0.25238752365112305\n",
      "| Loss std:   0.020994 |\n",
      "| Loss mean:   0.252388 |\n",
      "g_step: 100000 loss std/mean: 0.02399493381381035 0.25364723801612854\n",
      "| Loss std:   0.023995 |\n",
      "| Loss mean:   0.253647 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NWRMSLE  : 0.529352206375\n",
      "| Validation NWRMSLE:   0.529352 |\n",
      "\tValidation NWRMSLE_5: 0.523689273415\n",
      "| Validation NWRMSLE_5:   0.523689 |\n",
      "g_step: 100100 loss std/mean: 0.021566787734627724 0.25157320499420166\n",
      "| Loss std:   0.021567 |\n",
      "| Loss mean:   0.251573 |\n",
      "g_step: 100200 loss std/mean: 0.023948626592755318 0.24661043286323547\n",
      "| Loss std:   0.023949 |\n",
      "| Loss mean:   0.246610 |\n",
      "g_step: 100300 loss std/mean: 0.023883674293756485 0.24974052608013153\n",
      "| Loss std:   0.023884 |\n",
      "| Loss mean:   0.249741 |\n",
      "g_step: 100400 loss std/mean: 0.02341749332845211 0.25601282715797424\n",
      "| Loss std:   0.023417 |\n",
      "| Loss mean:   0.256013 |\n",
      "g_step: 100500 loss std/mean: 0.02006395533680916 0.25887733697891235\n",
      "| Loss std:   0.020064 |\n",
      "| Loss mean:   0.258877 |\n",
      "g_step: 100600 loss std/mean: 0.023910269141197205 0.2510247528553009\n",
      "| Loss std:   0.023910 |\n",
      "| Loss mean:   0.251025 |\n",
      "g_step: 100700 loss std/mean: 0.025125427171587944 0.2477564960718155\n",
      "| Loss std:   0.025125 |\n",
      "| Loss mean:   0.247756 |\n",
      "g_step: 100800 loss std/mean: 0.019849734380841255 0.24616849422454834\n",
      "| Loss std:   0.019850 |\n",
      "| Loss mean:   0.246168 |\n",
      "g_step: 100900 loss std/mean: 0.02168440632522106 0.24859026074409485\n",
      "| Loss std:   0.021684 |\n",
      "| Loss mean:   0.248590 |\n",
      "g_step: 101000 loss std/mean: 0.024082999676465988 0.25482189655303955\n",
      "| Loss std:   0.024083 |\n",
      "| Loss mean:   0.254822 |\n",
      "g_step: 101100 loss std/mean: 0.02417372539639473 0.24771343171596527\n",
      "| Loss std:   0.024174 |\n",
      "| Loss mean:   0.247713 |\n",
      "g_step: 101200 loss std/mean: 0.02176308073103428 0.24872815608978271\n",
      "| Loss std:   0.021763 |\n",
      "| Loss mean:   0.248728 |\n",
      "g_step: 101300 loss std/mean: 0.025913821533322334 0.2473619431257248\n",
      "| Loss std:   0.025914 |\n",
      "| Loss mean:   0.247362 |\n",
      "g_step: 101400 loss std/mean: 0.02681722491979599 0.24845407903194427\n",
      "| Loss std:   0.026817 |\n",
      "| Loss mean:   0.248454 |\n",
      "g_step: 101500 loss std/mean: 0.019889090210199356 0.2597283124923706\n",
      "| Loss std:   0.019889 |\n",
      "| Loss mean:   0.259728 |\n",
      "g_step: 101600 loss std/mean: 0.027897590771317482 0.25263845920562744\n",
      "| Loss std:   0.027898 |\n",
      "| Loss mean:   0.252638 |\n",
      "g_step: 101700 loss std/mean: 0.02291671559214592 0.25266316533088684\n",
      "| Loss std:   0.022917 |\n",
      "| Loss mean:   0.252663 |\n",
      "g_step: 101800 loss std/mean: 0.0234648659825325 0.24927577376365662\n",
      "| Loss std:   0.023465 |\n",
      "| Loss mean:   0.249276 |\n",
      "g_step: 101900 loss std/mean: 0.023550355806946754 0.2525760531425476\n",
      "| Loss std:   0.023550 |\n",
      "| Loss mean:   0.252576 |\n",
      "g_step: 102000 loss std/mean: 0.025594869628548622 0.25059691071510315\n",
      "| Loss std:   0.025595 |\n",
      "| Loss mean:   0.250597 |\n",
      "g_step: 102100 loss std/mean: 0.022312641143798828 0.2462383210659027\n",
      "| Loss std:   0.022313 |\n",
      "| Loss mean:   0.246238 |\n",
      "g_step: 102200 loss std/mean: 0.02081999182701111 0.25019511580467224\n",
      "| Loss std:   0.020820 |\n",
      "| Loss mean:   0.250195 |\n",
      "g_step: 102300 loss std/mean: 0.025170695036649704 0.2491140514612198\n",
      "| Loss std:   0.025171 |\n",
      "| Loss mean:   0.249114 |\n",
      "g_step: 102400 loss std/mean: 0.023581145331263542 0.2512590289115906\n",
      "| Loss std:   0.023581 |\n",
      "| Loss mean:   0.251259 |\n",
      "g_step: 102500 loss std/mean: 0.022648626938462257 0.2531571686267853\n",
      "| Loss std:   0.022649 |\n",
      "| Loss mean:   0.253157 |\n",
      "g_step: 102600 loss std/mean: 0.021393239498138428 0.25326719880104065\n",
      "| Loss std:   0.021393 |\n",
      "| Loss mean:   0.253267 |\n",
      "g_step: 102700 loss std/mean: 0.02070334181189537 0.2488190233707428\n",
      "| Loss std:   0.020703 |\n",
      "| Loss mean:   0.248819 |\n",
      "g_step: 102800 loss std/mean: 0.020911967381834984 0.2552880048751831\n",
      "| Loss std:   0.020912 |\n",
      "| Loss mean:   0.255288 |\n",
      "g_step: 102900 loss std/mean: 0.02486666850745678 0.2487315684556961\n",
      "| Loss std:   0.024867 |\n",
      "| Loss mean:   0.248732 |\n",
      "g_step: 103000 loss std/mean: 0.02421673573553562 0.24752549827098846\n",
      "| Loss std:   0.024217 |\n",
      "| Loss mean:   0.247525 |\n",
      "g_step: 103100 loss std/mean: 0.029945239424705505 0.2526995837688446\n",
      "| Loss std:   0.029945 |\n",
      "| Loss mean:   0.252700 |\n",
      "g_step: 103200 loss std/mean: 0.028175393119454384 0.24495510756969452\n",
      "| Loss std:   0.028175 |\n",
      "| Loss mean:   0.244955 |\n",
      "g_step: 103300 loss std/mean: 0.026060299947857857 0.2485634982585907\n",
      "| Loss std:   0.026060 |\n",
      "| Loss mean:   0.248563 |\n",
      "g_step: 103400 loss std/mean: 0.023445975035429 0.25182414054870605\n",
      "| Loss std:   0.023446 |\n",
      "| Loss mean:   0.251824 |\n",
      "g_step: 103500 loss std/mean: 0.024067386984825134 0.255982905626297\n",
      "| Loss std:   0.024067 |\n",
      "| Loss mean:   0.255983 |\n",
      "g_step: 103600 loss std/mean: 0.02647680975496769 0.2565207779407501\n",
      "| Loss std:   0.026477 |\n",
      "| Loss mean:   0.256521 |\n",
      "g_step: 103700 loss std/mean: 0.024467559531331062 0.250126451253891\n",
      "| Loss std:   0.024468 |\n",
      "| Loss mean:   0.250126 |\n",
      "g_step: 103800 loss std/mean: 0.024404698982834816 0.24822011590003967\n",
      "| Loss std:   0.024405 |\n",
      "| Loss mean:   0.248220 |\n",
      "g_step: 103900 loss std/mean: 0.021779630333185196 0.24768571555614471\n",
      "| Loss std:   0.021780 |\n",
      "| Loss mean:   0.247686 |\n",
      "g_step: 104000 loss std/mean: 0.024301787838339806 0.24928006529808044\n",
      "| Loss std:   0.024302 |\n",
      "| Loss mean:   0.249280 |\n",
      "g_step: 104100 loss std/mean: 0.02172440104186535 0.24503082036972046\n",
      "| Loss std:   0.021724 |\n",
      "| Loss mean:   0.245031 |\n",
      "g_step: 104200 loss std/mean: 0.023763781413435936 0.25594884157180786\n",
      "| Loss std:   0.023764 |\n",
      "| Loss mean:   0.255949 |\n",
      "g_step: 104300 loss std/mean: 0.0235434677451849 0.2537732422351837\n",
      "| Loss std:   0.023543 |\n",
      "| Loss mean:   0.253773 |\n",
      "g_step: 104400 loss std/mean: 0.021032389253377914 0.2507668733596802\n",
      "| Loss std:   0.021032 |\n",
      "| Loss mean:   0.250767 |\n",
      "g_step: 104500 loss std/mean: 0.02757442183792591 0.25580376386642456\n",
      "| Loss std:   0.027574 |\n",
      "| Loss mean:   0.255804 |\n",
      "g_step: 104600 loss std/mean: 0.020986657589673996 0.24572595953941345\n",
      "| Loss std:   0.020987 |\n",
      "| Loss mean:   0.245726 |\n",
      "g_step: 104700 loss std/mean: 0.02249799482524395 0.25065895915031433\n",
      "| Loss std:   0.022498 |\n",
      "| Loss mean:   0.250659 |\n",
      "g_step: 104800 loss std/mean: 0.02517588809132576 0.2466639131307602\n",
      "| Loss std:   0.025176 |\n",
      "| Loss mean:   0.246664 |\n",
      "g_step: 104900 loss std/mean: 0.02397623099386692 0.2538934051990509\n",
      "| Loss std:   0.023976 |\n",
      "| Loss mean:   0.253893 |\n",
      "g_step: 105000 loss std/mean: 0.03262295573949814 0.25158289074897766\n",
      "| Loss std:   0.032623 |\n",
      "| Loss mean:   0.251583 |\n",
      "\tValidation NWRMSLE  : 0.52943100767\n",
      "| Validation NWRMSLE:   0.529431 |\n",
      "\tValidation NWRMSLE_5: 0.523815317253\n",
      "| Validation NWRMSLE_5:   0.523815 |\n",
      "g_step: 105100 loss std/mean: 0.019335582852363586 0.2519100606441498\n",
      "| Loss std:   0.019336 |\n",
      "| Loss mean:   0.251910 |\n",
      "g_step: 105200 loss std/mean: 0.022302698343992233 0.2533189654350281\n",
      "| Loss std:   0.022303 |\n",
      "| Loss mean:   0.253319 |\n",
      "g_step: 105300 loss std/mean: 0.022957630455493927 0.24639376997947693\n",
      "| Loss std:   0.022958 |\n",
      "| Loss mean:   0.246394 |\n",
      "g_step: 105400 loss std/mean: 0.024309173226356506 0.24882416427135468\n",
      "| Loss std:   0.024309 |\n",
      "| Loss mean:   0.248824 |\n",
      "g_step: 105500 loss std/mean: 0.022924764081835747 0.2539120018482208\n",
      "| Loss std:   0.022925 |\n",
      "| Loss mean:   0.253912 |\n",
      "g_step: 105600 loss std/mean: 0.022451115772128105 0.2516387104988098\n",
      "| Loss std:   0.022451 |\n",
      "| Loss mean:   0.251639 |\n",
      "g_step: 105700 loss std/mean: 0.02566441148519516 0.2466259002685547\n",
      "| Loss std:   0.025664 |\n",
      "| Loss mean:   0.246626 |\n",
      "g_step: 105800 loss std/mean: 0.02293810248374939 0.25128525495529175\n",
      "| Loss std:   0.022938 |\n",
      "| Loss mean:   0.251285 |\n",
      "g_step: 105900 loss std/mean: 0.026067733764648438 0.2534066438674927\n",
      "| Loss std:   0.026068 |\n",
      "| Loss mean:   0.253407 |\n",
      "g_step: 106000 loss std/mean: 0.023972736671566963 0.24619236588478088\n",
      "| Loss std:   0.023973 |\n",
      "| Loss mean:   0.246192 |\n",
      "g_step: 106100 loss std/mean: 0.025004612281918526 0.2452852874994278\n",
      "| Loss std:   0.025005 |\n",
      "| Loss mean:   0.245285 |\n",
      "g_step: 106200 loss std/mean: 0.02748321369290352 0.24804826080799103\n",
      "| Loss std:   0.027483 |\n",
      "| Loss mean:   0.248048 |\n",
      "g_step: 106300 loss std/mean: 0.02192360907793045 0.2514258325099945\n",
      "| Loss std:   0.021924 |\n",
      "| Loss mean:   0.251426 |\n",
      "g_step: 106400 loss std/mean: 0.02469916269183159 0.24670061469078064\n",
      "| Loss std:   0.024699 |\n",
      "| Loss mean:   0.246701 |\n",
      "g_step: 106500 loss std/mean: 0.02398110367357731 0.2507025897502899\n",
      "| Loss std:   0.023981 |\n",
      "| Loss mean:   0.250703 |\n",
      "g_step: 106600 loss std/mean: 0.023568248376250267 0.2509376108646393\n",
      "| Loss std:   0.023568 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss mean:   0.250938 |\n",
      "g_step: 106700 loss std/mean: 0.021789003163576126 0.25502753257751465\n",
      "| Loss std:   0.021789 |\n",
      "| Loss mean:   0.255028 |\n",
      "g_step: 106800 loss std/mean: 0.02033606544137001 0.2528955638408661\n",
      "| Loss std:   0.020336 |\n",
      "| Loss mean:   0.252896 |\n",
      "g_step: 106900 loss std/mean: 0.025689905509352684 0.24953113496303558\n",
      "| Loss std:   0.025690 |\n",
      "| Loss mean:   0.249531 |\n",
      "g_step: 107000 loss std/mean: 0.026551781222224236 0.24674884974956512\n",
      "| Loss std:   0.026552 |\n",
      "| Loss mean:   0.246749 |\n",
      "g_step: 107100 loss std/mean: 0.023300088942050934 0.25213801860809326\n",
      "| Loss std:   0.023300 |\n",
      "| Loss mean:   0.252138 |\n",
      "g_step: 107200 loss std/mean: 0.025883972644805908 0.25308334827423096\n",
      "| Loss std:   0.025884 |\n",
      "| Loss mean:   0.253083 |\n",
      "g_step: 107300 loss std/mean: 0.02372504211962223 0.2534681558609009\n",
      "| Loss std:   0.023725 |\n",
      "| Loss mean:   0.253468 |\n",
      "g_step: 107400 loss std/mean: 0.02885463275015354 0.24865800142288208\n",
      "| Loss std:   0.028855 |\n",
      "| Loss mean:   0.248658 |\n",
      "g_step: 107500 loss std/mean: 0.025654641911387444 0.2516622245311737\n",
      "| Loss std:   0.025655 |\n",
      "| Loss mean:   0.251662 |\n",
      "g_step: 107600 loss std/mean: 0.023111481219530106 0.24798940122127533\n",
      "| Loss std:   0.023111 |\n",
      "| Loss mean:   0.247989 |\n",
      "g_step: 107700 loss std/mean: 0.02480989322066307 0.2513648271560669\n",
      "| Loss std:   0.024810 |\n",
      "| Loss mean:   0.251365 |\n",
      "g_step: 107800 loss std/mean: 0.026664230972528458 0.25049179792404175\n",
      "| Loss std:   0.026664 |\n",
      "| Loss mean:   0.250492 |\n",
      "g_step: 107900 loss std/mean: 0.025588879361748695 0.24621498584747314\n",
      "| Loss std:   0.025589 |\n",
      "| Loss mean:   0.246215 |\n",
      "g_step: 108000 loss std/mean: 0.02270767278969288 0.25150424242019653\n",
      "| Loss std:   0.022708 |\n",
      "| Loss mean:   0.251504 |\n",
      "g_step: 108100 loss std/mean: 0.02198106236755848 0.2524799406528473\n",
      "| Loss std:   0.021981 |\n",
      "| Loss mean:   0.252480 |\n",
      "g_step: 108200 loss std/mean: 0.024283846840262413 0.2490575760602951\n",
      "| Loss std:   0.024284 |\n",
      "| Loss mean:   0.249058 |\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "history = 400\n",
    "time_to_predict = 16\n",
    "freq=1\n",
    "\n",
    "last_day_train = '2017-07-14'\n",
    "window=300\n",
    "epochs = 100\n",
    "validation_day = pd.to_datetime(last_day_train) + pd.Timedelta('{} days'.format(time_to_predict))\n",
    "batch_size = 1000\n",
    "sum_W = 3574368.0/16\n",
    "skip=0\n",
    "\n",
    "print(validation_day)\n",
    "\n",
    "batch_gen = get_random_train_test(\n",
    "    df_pivot,\n",
    "    last_day_train,\n",
    "    window=window,\n",
    "    history=history,\n",
    "    size=batch_size,\n",
    "    predict_days=time_to_predict,\n",
    "    epochs=epochs,\n",
    "    skip=skip,\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "val_set = get_validation(df_pivot, validation_day, history=history,\n",
    "                        predict_days=time_to_predict, skip=skip)\n",
    "\n",
    "from model import RNNModel\n",
    "\n",
    "m = RNNModel(\n",
    "    history=history,\n",
    "    n_days_predict=time_to_predict,\n",
    "    clip_gradients=1.,\n",
    "    starter_learning_rate=0.0001,\n",
    "    #starter_learning_rate=0.0005,\n",
    "    n_layers_rnn=1,\n",
    "    rnn_size_encoder=200,\n",
    "    rnn_size_decoder=200,\n",
    "    #output_droupouts_kp=[.9, .9, .9, .95, 1.]\n",
    ")\n",
    "print(1)\n",
    "m.build_graph(batch_gen)\n",
    "\n",
    "\n",
    "try:\n",
    "    hd_exp.end()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "hd_exp = hd.Experiment('RNN fav 3')\n",
    "\n",
    "m.train(val_set, coef=unit_std, sum_W=sum_W,\n",
    "        report_every=100, validate_every=5000,\n",
    "        hd_exp=hd_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = df[\n",
    "    (df['item_nbr'] == 1503844) &\n",
    "    (df['store_nbr'] == 44) \n",
    "    \n",
    "]['unit_sales_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aaf2878cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sm.graphics.tsa.plot_pacf(sales, lags=450)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aad0004ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales2, tmp = stats.boxcox((sales+unit_mean))\n",
    "sm.graphics.tsa.plot_pacf(sales2, lags=450)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
